<!DOCTYPE HTML>
<html lang="zh-CN">


<head>
    <meta charset="utf-8">
    <meta name="keywords" content="Kafka笔记, HyxiaoGe">
    <meta name="description" content="Kafka 复习什么是KafkaApache Kafka是一个高性能的分布式流处理平台，最初由LinkedIn公司内部开发用于处理大规模实时数据流，后来于2011年成为Apache基金会的开源项目。它作为一个强大的消息中间件，专门设计用于处">
    <meta http-equiv="X-UA-Compatible" content="IE=edge">
    <meta name="viewport" content="width=device-width, initial-scale=1.0, user-scalable=no">
    <meta name="renderer" content="webkit|ie-stand|ie-comp">
    <meta name="mobile-web-app-capable" content="yes">
    <meta name="format-detection" content="telephone=no">
    <meta name="apple-mobile-web-app-capable" content="yes">
    <meta name="apple-mobile-web-app-status-bar-style" content="black-translucent">
    <meta name="referrer" content="no-referrer-when-downgrade">
    <!-- Global site tag (gtag.js) - Google Analytics -->


    <title>Kafka笔记 | HyxiaoGe</title>
    <link rel="icon" type="image/png" href="/favicon.png">
    
    <style>
        body{
            background-image: url(http://sv6693ki5.hn-bkt.clouddn.com/background/bg.jpg);
            background-repeat:no-repeat;
            background-size: 100% 100%;
            background-attachment:fixed;
        }
    </style>



    <!-- bg-cover style     -->



<link rel="stylesheet" type="text/css" href="/libs/awesome/css/all.min.css">
<link rel="stylesheet" type="text/css" href="/libs/materialize/materialize.min.css">
<link rel="stylesheet" type="text/css" href="/libs/aos/aos.css">
<link rel="stylesheet" type="text/css" href="/libs/animate/animate.min.css">
<link rel="stylesheet" type="text/css" href="/libs/lightGallery/css/lightgallery.min.css">
<link rel="stylesheet" type="text/css" href="/css/matery.css">
<link rel="stylesheet" type="text/css" href="/css/my.css">
<link rel="stylesheet" type="text/css" href="/css/dark.css" media="none" onload="if(media!='all')media='all'">




    <link rel="stylesheet" href="/libs/tocbot/tocbot.css">
    <link rel="stylesheet" href="/css/post.css">




    



    <script src="/libs/jquery/jquery-3.6.0.min.js"></script>

<!-- hexo injector head_end start -->
<link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/katex@0.12.0/dist/katex.min.css">
<!-- hexo injector head_end end --><meta name="generator" content="Hexo 7.3.0"><link rel="alternate" href="/atom.xml" title="HyxiaoGe" type="application/atom+xml">
<link rel="stylesheet" href="/css/prism-tomorrow.css" type="text/css">
<link rel="stylesheet" href="/css/prism-line-numbers.css" type="text/css"><script src="/js/prism.js"></script>
<script src="/js/prism-line-numbers.min.js"></script></head>


<body>
    <header class="navbar-fixed">
    <nav id="headNav" class="bg-color nav-transparent">
        <div id="navContainer" class="nav-wrapper container">
            <div class="brand-logo">
                <a href="/" class="waves-effect waves-light">
                    
                    <img src="/medias/logo.png" class="logo-img" alt="LOGO">
                    
                    <span class="logo-span">HyxiaoGe</span>
                </a>
            </div>
            

<a href="#" data-target="mobile-nav" class="sidenav-trigger button-collapse"><i class="fas fa-bars"></i></a>
<ul class="right nav-menu">
  
  <li class="hide-on-med-and-down nav-item">
    
    <a href="/" class="waves-effect waves-light">
      
      <i class="fas fa-home" style="zoom: 0.6;"></i>
      
      <span>首页</span>
    </a>
    
  </li>
  
  <li class="hide-on-med-and-down nav-item">
    
    <a href="/tags" class="waves-effect waves-light">
      
      <i class="fas fa-tags" style="zoom: 0.6;"></i>
      
      <span>标签</span>
    </a>
    
  </li>
  
  <li class="hide-on-med-and-down nav-item">
    
    <a href="/categories" class="waves-effect waves-light">
      
      <i class="fas fa-bookmark" style="zoom: 0.6;"></i>
      
      <span>分类</span>
    </a>
    
  </li>
  
  <li class="hide-on-med-and-down nav-item">
    
    <a href="/archives" class="waves-effect waves-light">
      
      <i class="fas fa-archive" style="zoom: 0.6;"></i>
      
      <span>归档</span>
    </a>
    
  </li>
  
  <li class="hide-on-med-and-down nav-item">
    
    <a href="/about" class="waves-effect waves-light">
      
      <i class="fas fa-user-circle" style="zoom: 0.6;"></i>
      
      <span>关于</span>
    </a>
    
  </li>
  
  <li class="hide-on-med-and-down nav-item">
    
    <a href="/contact" class="waves-effect waves-light">
      
      <i class="fas fa-comments" style="zoom: 0.6;"></i>
      
      <span>留言板</span>
    </a>
    
  </li>
  
  <li class="hide-on-med-and-down nav-item">
    
    <a href="/friends" class="waves-effect waves-light">
      
      <i class="fas fa-address-book" style="zoom: 0.6;"></i>
      
      <span>友情链接</span>
    </a>
    
  </li>
  
  <li>
    <a href="#searchModal" class="modal-trigger waves-effect waves-light">
      <i id="searchIcon" class="fas fa-search" title="搜索" style="zoom: 0.85;"></i>
    </a>
  </li>
  <li>
    <a href="javascript:;" class="waves-effect waves-light" onclick="switchNightMode()" title="深色/浅色模式" >
      <i id="sum-moon-icon" class="fas fa-sun" style="zoom: 0.85;"></i>
    </a>
  </li>
</ul>


<div id="mobile-nav" class="side-nav sidenav">

    <div class="mobile-head bg-color">
        
        <img src="/medias/logo.png" class="logo-img circle responsive-img">
        
        <div class="logo-name">HyxiaoGe</div>
        <div class="logo-desc">
            
            Never really desperate, only the lost of the soul.
            
        </div>
    </div>

    <ul class="menu-list mobile-menu-list">
        
        <li class="m-nav-item">
	  
		<a href="/" class="waves-effect waves-light">
			
			    <i class="fa-fw fas fa-home"></i>
			
			首页
		</a>
          
        </li>
        
        <li class="m-nav-item">
	  
		<a href="/tags" class="waves-effect waves-light">
			
			    <i class="fa-fw fas fa-tags"></i>
			
			标签
		</a>
          
        </li>
        
        <li class="m-nav-item">
	  
		<a href="/categories" class="waves-effect waves-light">
			
			    <i class="fa-fw fas fa-bookmark"></i>
			
			分类
		</a>
          
        </li>
        
        <li class="m-nav-item">
	  
		<a href="/archives" class="waves-effect waves-light">
			
			    <i class="fa-fw fas fa-archive"></i>
			
			归档
		</a>
          
        </li>
        
        <li class="m-nav-item">
	  
		<a href="/about" class="waves-effect waves-light">
			
			    <i class="fa-fw fas fa-user-circle"></i>
			
			关于
		</a>
          
        </li>
        
        <li class="m-nav-item">
	  
		<a href="/contact" class="waves-effect waves-light">
			
			    <i class="fa-fw fas fa-comments"></i>
			
			留言板
		</a>
          
        </li>
        
        <li class="m-nav-item">
	  
		<a href="/friends" class="waves-effect waves-light">
			
			    <i class="fa-fw fas fa-address-book"></i>
			
			友情链接
		</a>
          
        </li>
        
        
    </ul>
</div>


        </div>

        
    </nav>

</header>

    



<div class="bg-cover pd-header post-cover" style="background-image: url('/medias/featureimages/2.jpg')">
    <div class="container" style="right: 0px;left: 0px;">
        <div class="row">
            <div class="col s12 m12 l12">
                <div class="brand">
                    <h1 class="description center-align post-title">Kafka笔记</h1>
                </div>
            </div>
        </div>
    </div>
</div>




<main class="post-container content">

    
    <div class="row">
    <div id="main-content" class="col s12 m12 l9">
        <!-- 文章内容详情 -->
<div id="artDetail">
    <div class="card">
        <div class="card-content article-info">
            <div class="row tag-cate">
                <div class="col s7">
                    
                    <div class="article-tag">
                        
                            <a href="/tags/Kafka/">
                                <span class="chip bg-color">Kafka</span>
                            </a>
                        
                    </div>
                    
                </div>
                <div class="col s5 right-align">
                    
                    <div class="post-cate">
                        <i class="fas fa-bookmark fa-fw icon-category"></i>
                        
                            <a href="/categories/%E4%B8%AD%E9%97%B4%E4%BB%B6/" class="post-category">
                                中间件
                            </a>
                        
                    </div>
                    
                </div>
            </div>

            <div class="post-info">
                
                <div class="post-date info-break-policy">
                    <i class="far fa-calendar-minus fa-fw"></i>发布日期:&nbsp;&nbsp;
                    2024-09-08
                </div>
                

                
                <div class="post-date info-break-policy">
                    <i class="far fa-calendar-check fa-fw"></i>更新日期:&nbsp;&nbsp;
                    2025-08-03
                </div>
                

                
                <div class="info-break-policy">
                    <i class="far fa-file-word fa-fw"></i>文章字数:&nbsp;&nbsp;
                    11.5k
                </div>
                

                
                <div class="info-break-policy">
                    <i class="far fa-clock fa-fw"></i>阅读时长:&nbsp;&nbsp;
                    41 分
                </div>
                

                
                    <div id="busuanzi_container_page_pv" class="info-break-policy">
                        <i class="far fa-eye fa-fw"></i>阅读次数:&nbsp;&nbsp;
                        <span id="busuanzi_value_page_pv"></span>
                    </div>
				
            </div>
        </div>
        <hr class="clearfix">

        
        <!-- 是否加载使用自带的 prismjs. -->
        <link rel="stylesheet" href="/libs/prism/prism.min.css">
        

        

        <div class="card-content article-card-content">
            <div id="articleContent">
                <h1 id="Kafka-复习"><a href="#Kafka-复习" class="headerlink" title="Kafka 复习"></a>Kafka 复习</h1><h2 id="什么是Kafka"><a href="#什么是Kafka" class="headerlink" title="什么是Kafka"></a>什么是Kafka</h2><p>Apache Kafka是一个高性能的分布式流处理平台，最初由LinkedIn公司内部开发用于处理大规模实时数据流，后来于2011年成为Apache基金会的开源项目。它作为一个强大的消息中间件，专门设计用于处理高容量、低延迟的实时数据流处理场景。Kafka架构优雅且可扩展，能够无缝地处理数百万条消息，同时保持毫秒级的传输延迟。它具有分布式、可分区、可复制的特性，不仅提供了极高的吞吐量和可靠性，还支持数据持久化和容错能力，使其成为现代数据管道和流处理应用的基础组件。</p>
<h2 id="Kafka的核心概念"><a href="#Kafka的核心概念" class="headerlink" title="Kafka的核心概念"></a>Kafka的核心概念</h2><ul>
<li><strong>Producer（生产者）</strong>：发布消息到Kafka的客户端应用程序</li>
<li><strong>Consumer（消费者）</strong>：订阅并处理来自Kafka的消息流的客户端应用程序</li>
<li><strong>Topic（主题）</strong>：Topic 是 Kafka 中对消息进行逻辑分类的单元。所有发布到 Kafka 集群的消息都必须归属于某一个 Topic。</li>
<li><strong>Partition（分区）</strong>：每个topic可以分为多个分区，允许并行处理，提高吞吐量</li>
<li><strong>Broker（代理）</strong>：一个独立的 Kafka 服务器实例被称为一个 Broker。多个 Broker 组合在一起构成一个 Kafka 集群。</li>
<li><strong>Consumer Group（消费者组）</strong>：一组协同工作的消费者，共同消费主题中的消息</li>
<li><strong>Offset（偏移量）</strong>：分区内每条消息的唯一标识符</li>
<li><strong>Zookeeper</strong>：管理和协调Kafka broker的服务</li>
</ul>
<h2 id="Kafka的特点"><a href="#Kafka的特点" class="headerlink" title="Kafka的特点"></a>Kafka的特点</h2><ul>
<li><strong>高吞吐量</strong>：能够处理数百万条消息</li>
<li><strong>低延迟</strong>：消息传递的延迟可以控制在毫秒级</li>
<li><strong>可扩展性</strong>：可以无缝扩展为处理更多数据</li>
<li><strong>持久性</strong>：消息被持久化到磁盘，防止数据丢失</li>
<li><strong>容错性</strong>：在节点失败的情况下继续运行</li>
<li><strong>高并发</strong>：支持数千个客户端同时读写</li>
<li><strong>实时处理</strong>：能够实时处理流数据</li>
</ul>
<h2 id="Kafka的应用场景"><a href="#Kafka的应用场景" class="headerlink" title="Kafka的应用场景"></a>Kafka的应用场景</h2><ul>
<li><strong>消息队列</strong>：作为传统消息中间件的替代</li>
<li><strong>日志收集</strong>：收集分布式系统中的日志</li>
<li><strong>流处理</strong>：实时处理数据流</li>
<li><strong>事件溯源</strong>：记录状态变更事件</li>
<li><strong>活动跟踪</strong>：跟踪用户行为和活动</li>
<li><strong>指标监控</strong>：收集和监控运营数据</li>
</ul>
<h2 id="一个服务器只能有一个-Broker-吗？"><a href="#一个服务器只能有一个-Broker-吗？" class="headerlink" title="一个服务器只能有一个 Broker 吗？"></a>一个服务器只能有一个 Broker 吗？</h2><p>这是一个关于“理论”与“最佳实践”的问题。</p>
<ul>
<li><strong>从理论上讲：不是。</strong><br>你完全可以在一台物理或虚拟服务器上，启动多个不同的 Broker 进程。只要你为每个 Broker 进程配置不同的端口号（例如 9092, 9093, 9094）、不同的 <code>broker.id</code> 和不同的数据存储目录，它们就可以在同一台机器上共存。</li>
<li><strong>从生产实践上讲：是的，最佳实践是一台服务器只运行一个 Broker 实例。</strong><br>为什么呢？<ol>
<li><strong>资源隔离：</strong> Kafka 是一个重度依赖磁盘 I&#x2F;O 和内存的系统。将一个服务器的全部资源（CPU、内存、磁盘、网络带宽）都分配给一个 Broker 实例，可以避免多个 Broker 实例之间争抢资源，从而获得最稳定和可预测的性能。</li>
<li><strong>简化运维：</strong> 一台服务器对应一个 Broker，使得监控、管理和故障排查都变得非常简单明了。如果一台服务器上的某个 Broker 出了问题，你立刻就能定位到是哪台机器。</li>
<li><strong>故障隔离：</strong> 如果一台服务器因为硬件故障宕机了，你只会损失一个 Broker。如果你在一台服务器上运行了三个 Broker，那一次宕机就会同时损失三个 Broker，对集群的冲击更大。</li>
</ol>
</li>
</ul>
<p>小结：在生产环境中，标准的最佳实践是一台服务器只部署和运行一个 Broker 实例，以确保资源隔离和简化运维。虽然技术上可以在一台服务器上运行多个 Broker，但这是一种不被推荐的做法。</p>
<h2 id="Topic-只能存在于多-Broker-组合中的其中一个是吗？"><a href="#Topic-只能存在于多-Broker-组合中的其中一个是吗？" class="headerlink" title="Topic 只能存在于多 Broker 组合中的其中一个是吗？"></a>Topic 只能存在于多 Broker 组合中的其中一个是吗？</h2><ul>
<li>**准确地说：一个 Topic 的数据，不仅可以，而且通常就应该分布在集群中的多个 Broker 上。**这是通过 Topic 的 <strong>分区（Partition）机制</strong> 来实现的，这也是 Kafka 得以实现高吞吐量的关键。</li>
</ul>
<p>我们用一个具体的例子来说明：<br>假设你有一个由 3 个 Broker 组成的 Kafka 集群（Broker 1, Broker 2, Broker 3）。</p>
<p>现在，你创建了一个名为 <code>order-topic</code> 的主题，并设定它有 <strong>3 个分区</strong>（我们称之为 P0, P1, P2）。</p>
<p>Kafka 在创建这个 Topic 时，会自动将这些分区尽可能均匀地分布到集群的所有 Broker 上，以实现负载均衡。一个可能的结果是：</p>
<ul>
<li><code>order-topic</code> 的分区 <code>P0</code> 被存放在 <strong>Broker 1</strong> 上。</li>
<li><code>order-topic</code> 的分区 <code>P1</code> 被存放在 <strong>Broker 2</strong> 上。</li>
<li><code>order-topic</code> 的分区 <code>P2</code> 被存放在 <strong>Broker 3</strong> 上。</li>
</ul>
<p><strong>这样做的好处是：</strong><br>当生产者往 <code>order-topic</code> 发送大量消息时，这些消息可以被同时发往三个不同的分区（P0, P1, P2），也就是同时写入了三台不同的服务器（Broker 1, 2, 3）。消费者也可以同时从这三个分区读取数据。这样一来，读写的压力就被分摊到了整个集群，而不是集中在一台机器上，从而极大地提升了性能。</p>
<p>所以，<strong>Topic 是一个逻辑概念，它的物理存储（即它的所有分区）是分散在整个集群的多个 Broker 上的。</strong></p>
<h2 id="一个生产Broker的最佳实践是一个Partition吗？"><a href="#一个生产Broker的最佳实践是一个Partition吗？" class="headerlink" title="一个生产Broker的最佳实践是一个Partition吗？"></a>一个生产Broker的最佳实践是一个Partition吗？</h2><p>先说结论：一个 Broker 只承载一个 Partition”在生产环境中是<strong>不现实且低效的</strong>。</p>
<p>正确的生产实践恰恰相反：<strong>一个 Broker 通常会、也应该会承载成百上千个分区。</strong></p>
<p><strong>为什么会是这样？</strong></p>
<ol>
<li><strong>资源利用率问题：</strong><br>一个分区（本质上就是磁盘上的几个日志文件）远不足以利用满一台现代服务器的强大资源（多核CPU、几十G内存、高吞吐磁盘阵列、万兆网卡）。如果一台强大的服务器（Broker）只为一个分区服务，那将是极大的资源浪费，就像用一辆大卡车只运送一封信。</li>
<li><strong>成本和可扩展性问题：</strong><br>为了获得高吞吐量，一个 Topic 可能需要几十甚至几百个分区。如果一个 Broker 只能放一个分区，那么一个拥有 100 个分区的 Topic 就需要 100 个 Broker，也就是 100 台服务器！这在成本和运维上都是不可行的。<br>而现实中，我们可以用一个 10 台 Broker 的集群，轻松承载起成百上千个分区（这些分区可以来自不同的 Topic）。</li>
</ol>
<h3 id="重新理解“方便管理”和“故障隔离”"><a href="#重新理解“方便管理”和“故障隔离”" class="headerlink" title="重新理解“方便管理”和“故障隔离”"></a><strong>重新理解“方便管理”和“故障隔离”</strong></h3><ul>
<li><strong>方便管理和定位问题：</strong> 这正是“<strong>一台服务器一个Broker</strong>”这个原则解决的。如果监控系统显示 Broker 5 的CPU使用率100%，你不需要思考是哪个进程导致的，直接登录到承载 Broker 5 的那台服务器去排查问题即可。</li>
<li><strong>故障隔离：</strong> 这不是通过减少 Broker 上的分区数来实现的，而是通过我们之前深入讨论的<strong>副本机制 (Replication)</strong> 来实现的。<ul>
<li>假设一个 Broker 上承载了 100 个分区的 Leader。当这台 Broker 宕机时，Kafka 的高可用机制会启动，将这 100 个 Leader 的角色<strong>自动、快速地转移</strong>到它们各自的副本（Follower）所在的、其他健康的 Broker 上。</li>
<li>系统虽然会经历一次短暂的“重平衡”抖动，但数据不会丢失，服务也会迅速恢复。这才是 Kafka 在分区层面实现故障隔离的方式。</li>
</ul>
</li>
</ul>
<h3 id="结论"><a href="#结论" class="headerlink" title="结论"></a><strong>结论</strong></h3><p>所以，我们需要建立一个清晰的、分层的生产架构认知：</p>
<ol>
<li><strong>物理层：</strong> 一台服务器 → 运行一个 Broker 进程。（为了资源隔离和管理）</li>
<li><strong>逻辑层：</strong> 一个 Broker → 同时管理<strong>多个</strong>分区。（为了资源利用率和成本效益）</li>
<li><strong>高可用层：</strong> 一个分区的多个副本（Leader 和 Followers）→ 必须分布在<strong>不同的</strong> Broker 上。（为了故障转移和数据安全）</li>
</ol>
<h2 id="分区-Partition-Kafka-高性能的基石"><a href="#分区-Partition-Kafka-高性能的基石" class="headerlink" title="分区 (Partition) - Kafka 高性能的基石"></a>分区 (Partition) - Kafka 高性能的基石</h2><p><strong>1. 技术定义</strong></p>
<p>每个 Topic 都可以被划分为一个或多个分区（Partition），分区（Partition）是一个逻辑概念，它的物理存在形式是副本（Replica），而每一个副本的本质，就是一个有序的、只能追加写入的日志文件（Append-only Log）。</p>
<p>当声称在要将消息写入 <code>分区0</code> 时，Kafka 内部会把它翻译成：“找到 <code>分区0</code> 的 <strong>Leader 副本</strong>，然后把消息追加到那个<strong>副本对应的日志文件</strong>的末尾</p>
<p><strong>2. 分区的核心特性</strong></p>
<ul>
<li><strong>有序性 (Ordering):</strong> 在<strong>单个 Partition 内部</strong>，消息是严格按照其被写入的顺序进行存储和读取的。这意味着，如果你发送消息 M1，然后发送 M2 到同一个 Partition，那么消费者也一定会先读到 M1，再读到 M2。<strong>这是 Kafka 提供的最重要的顺序保证。</strong></li>
<li><strong>不可变性 (Immutability):</strong> 一旦消息被写入 Partition，它就不能被修改。这种设计简化了系统，并提高了性能。</li>
<li><strong>偏移量 (Offset):</strong> Partition 中的每一条消息都有一个唯一的、从 0 开始单调递增的序列号，这个序列号被称为 <strong>Offset</strong>。Offset 唯一地标识了 Partition 中的一条消息。消费者通过 Offset 来追踪自己消费到了哪个位置。</li>
</ul>
<p><strong>3. 为什么要设计分区？</strong></p>
<p>设计分区的核心目的有两个：</p>
<ul>
<li><strong>可伸缩性&#x2F;水平扩展 (Scalability)：</strong><ul>
<li><strong>存储层面：</strong> 一个 Topic 的数据可以被分散存储在集群的多个 Broker 上（如我们上一步所讨论的）。这打破了单台服务器的磁盘容量和 I&#x2F;O 性能的限制。如果数据量增长，你可以通过增加 Broker 节点来水平扩展整个集群的存储能力。</li>
<li><strong>性能层面：</strong> 读写操作可以并行地在多个 Broker 上的多个 Partition 上进行，极大地提高了整个 Topic 的总吞吐量。</li>
</ul>
</li>
<li><strong>并行处理 (Parallelism)：</strong><ul>
<li>分区的存在，使得消费者可以实现并行消费。一个消费者组（Consumer Group）可以有多个消费者实例，每个实例负责消费一个或多个 Partition。这样，一个 Topic 的总消费负载就被分摊到了多个消费者上，大大提高了数据处理能力。</li>
</ul>
</li>
</ul>
<hr>
<p><strong>总结一下第三步的关键点：</strong></p>
<blockquote>
<p>Topic 是一个逻辑概念，而 Partition 是物理上的实现。一个 Topic 由多个 Partition 组成，这些 Partition 分布在不同的 Broker 上。消息在单个 Partition 内是有序的，并通过 Offset 进行唯一标识。分区的设计是 Kafka 实现高吞吐量和高可伸缩性的核心原因。</p>
</blockquote>
<h2 id="副本-Replika-与-Leader-Follower-模型-Kafka-可靠性的保障"><a href="#副本-Replika-与-Leader-Follower-模型-Kafka-可靠性的保障" class="headerlink" title="副本 (Replika) 与 Leader&#x2F;Follower 模型 - Kafka 可靠性的保障"></a>副本 (Replika) 与 Leader&#x2F;Follower 模型 - Kafka 可靠性的保障</h2><p><strong>1. 技术定义</strong></p>
<ul>
<li><strong>副本 (Replica):</strong> Kafka 允许为每个分区（Partition）创建多个数据副本，这些副本被分布在集群中不同的 Broker 上。这就是<strong>副本机制</strong>。副本的数量是可以配置的，这个数量被称为<strong>副本因子 (Replication Factor)</strong>。例如，如果副本因子为 3，那么每个分区就会有 1 个主副本和 2 个次副本。</li>
</ul>
<p><strong>2. Leader 与 Follower 的角色分工</strong></p>
<p>一个分区的多个副本之间，并不是平等的，它们有明确的主从关系。</p>
<ul>
<li><strong>Leader (领导者 &#x2F; 主副本)：</strong><ul>
<li><strong>职责：</strong> 每个分区在任意时刻，有且仅有一个副本是 Leader。它负责处理所有来自客户端（生产者和消费者）的<strong>读和写</strong>请求。</li>
<li><strong>类比：</strong> 它是唯一对外营业的“正本”柜台。</li>
</ul>
</li>
<li><strong>Follower (跟随者 &#x2F; 次副本)：</strong><ul>
<li><strong>职责：</strong> Leader 以外的其他副本都是 Follower。Follower 不与客户端直接交互。它们唯一的任务就是<strong>被动地、持续地</strong>从 Leader 那里拉取最新的数据，以保持和 Leader 的数据同步。</li>
<li><strong>类比：</strong> 它们是内部使用的“备份”柜台，只负责抄写正本柜台的数据，不对外服务。</li>
</ul>
</li>
</ul>
<p><strong>3. 数据同步与故障转移的流程</strong></p>
<p>这个主从模型是如何工作的？</p>
<ul>
<li><strong>数据写入流程 (正常情况):</strong><ol>
<li>生产者发送一条消息到某个分区。</li>
<li>请求被直接发送到该分区的 <strong>Leader</strong> 所在的 Broker 上。</li>
<li>Leader 将消息写入自己的本地日志。</li>
<li>各个 <strong>Follower</strong> 定期向 Leader 发送拉取请求，将 Leader 的新消息复制到自己的本地日志中。</li>
</ol>
</li>
<li><strong>故障转移流程 (Leader 宕机):</strong><ol>
<li>分区的 Leader 所在的 Broker 突然宕机。</li>
<li>Kafka 控制器 (Controller) 检测到这个情况。</li>
<li>控制器会从所有与 Leader 保持“同步”的 Follower 列表中，选举出一个新的 Leader。</li>
<li>选举成功后，这个曾经的 Follower 就成为了新的 Leader，开始对外提供读写服务。客户端会被告知新的 Leader 地址。整个过程对用户来说是无感知的，是自动完成的。</li>
</ol>
</li>
</ul>
<p>现在，我们用一个非常具体、直观的例子来说明这个过程。</p>
<p><strong>场景设定：</strong></p>
<ul>
<li><strong>集群：</strong> 我们有一个由 3 台服务器组成的 Kafka 集群，分别是 <strong>Broker 1</strong>、<strong>Broker 2</strong> 和 <strong>Broker 3</strong>。</li>
<li><strong>Topic：</strong> 我们创建一个名为 <code>payment_topic</code> 的主题，用来处理支付消息。</li>
<li><strong>分区和副本：</strong> 为了让例子简单清晰，我们假设 <code>payment_topic</code> 只有 <strong>1 个分区</strong>，就是 <code>Partition 0</code>。我们设置<strong>副本因子为 3</strong>，这意味着 <code>Partition 0</code> 会有 1 个 Leader 和 2 个 Follower。</li>
</ul>
<p><strong>阶段一：正常运行</strong></p>
<p>系统启动后，Kafka 会自动进行选举和分配。一个可能的结果是：</p>
<ul>
<li><code>Partition 0</code> 的 <strong>Leader</strong> 被分配在了 <strong>Broker 1</strong> 上。</li>
<li><code>Partition 0</code> 的两个 <strong>Follower</strong> 分别被分配在了 <strong>Broker 2</strong> 和 <strong>Broker 3</strong> 上。</li>
</ul>
<p><strong>现在，一个生产者要发送一条支付消息：<code>&#123; &quot;paymentId&quot;: &quot;abcde&quot;, &quot;amount&quot;: 50 &#125;</code></strong></p>
<ol>
<li>生产者的请求被直接发送到 <strong>Broker 1</strong>（因为它是 Leader）。</li>
<li><strong>Broker 1</strong> 收到消息，将它写入自己的磁盘。</li>
<li><strong>Broker 2</strong> 和 <strong>Broker 3</strong> 上的 Follower，像往常一样，从 Broker 1 拉取数据，发现有一条新消息，于是也把这条消息写入各自的磁盘。</li>
<li>当数据成功同步到足够数量的副本后（这个数量可以配置），<strong>Broker 1</strong> 向生产者返回一个“发送成功”的确认。</li>
</ol>
<p>在这个阶段，所有读写都由 Broker 1 处理，Broker 2 和 3 只是默默地在后台备份。</p>
<hr>
<p><strong>阶段二：故障发生</strong></p>
<p><strong>突然，Broker 1 所在的服务器因为电源故障，宕机了！</strong></p>
<p>现在的情况是：</p>
<ul>
<li><code>Partition 0</code> 的 Leader 消失了。</li>
<li>生产者和消费者无法再连接到 Broker 1。</li>
</ul>
<hr>
<p><strong>阶段三：自动故障转移 (Failover)</strong></p>
<p>Kafka 的高可用机制现在开始启动：</p>
<ol>
<li>集群的<strong>控制器 (Controller)</strong>（通常是集群中的某一个 Broker）通过心跳机制，很快就发现 <strong>Broker 1</strong> 失联了。</li>
<li>控制器立刻查看 <code>Partition 0</code> 的 Follower 列表，发现 <strong>Broker 2</strong> 和 <strong>Broker 3</strong> 上的副本都处于“同步”状态。</li>
<li>控制器在这两个 Follower 中发起一次新的选举。假设选举结果是 <strong>Broker 2</strong> 胜出。</li>
<li>控制器发布命令：<strong>“从现在起，Broker 2 成为 <code>Partition 0</code> 的新 Leader！”</strong></li>
<li><strong>Broker 2</strong> 的角色从 Follower 转变为 Leader。<strong>Broker 3</strong> 保持 Follower 不变，但它现在开始从新的 Leader（Broker 2）那里同步数据。</li>
<li>Kafka 会通知生产者客户端：“<code>payment_topic</code> 的 <code>Partition 0</code> 的 Leader 地址已经变更为 Broker 2。”</li>
</ol>
<p><strong>结果：</strong></p>
<ul>
<li>现在，当生产者要发送下一条消息 <code>&#123; &quot;paymentId&quot;: &quot;fghij&quot;, &quot;amount&quot;: 80 &#125;</code> 时，它会直接将请求发送到 <strong>Broker 2</strong>。</li>
<li>整个系统恢复了正常读写，整个切换过程是自动的，通常在几秒钟内完成，保证了服务的连续性。</li>
</ul>
<h2 id="Kafka-实现高并发的四大核心支柱"><a href="#Kafka-实现高并发的四大核心支柱" class="headerlink" title="Kafka 实现高并发的四大核心支柱"></a><strong>Kafka 实现高并发的四大核心支柱</strong></h2><h3 id="磁盘的高效利用"><a href="#磁盘的高效利用" class="headerlink" title="磁盘的高效利用"></a>磁盘的高效利用</h3><ul>
<li><strong>顺序读写</strong>：传统数据库为了更新数据，需要进行大量的随机磁盘读写，这非常慢，因为磁头需要不停地移动寻道。而 Kafka 的设计是<strong>日志追加 (Append-only Log)</strong>，所有新消息都只是简单地追加到文件的末尾。这种顺序写入的方式，速度几乎和写内存一样快，因为它省去了代价高昂的磁头寻道时间。</li>
<li><strong>操作系统页缓存的利用</strong>：Kafka 并不自己去设计复杂的缓存机制，而是把这个工作巧妙地“甩锅”给了操作系统。数据写入磁盘时，实际上是先写入了操作系统的页缓存（Page Cache），这是一个位于内存中的高速缓存区，然后由操作系统在后台异步地将数据刷到磁盘上。读取数据时，如果数据恰好在 Page Cache 中（对于热门数据很常见），就可以直接从内存中读取，避免了磁盘I&#x2F;O。</li>
</ul>
<h3 id="I-O优化：减少一切不必要的操作"><a href="#I-O优化：减少一切不必要的操作" class="headerlink" title="I&#x2F;O优化：减少一切不必要的操作"></a>I&#x2F;O优化：减少一切不必要的操作</h3><ul>
<li><strong>零拷贝（Zero-Copy）</strong>：<ul>
<li>在传统的数据发送流程中，数据需要从磁盘拷贝到内核空间（页缓存），再从内核空间拷贝到用户应用程序空间，然后应用程序再把数据拷贝回内核的 Socket 缓存区，最后才发送到网卡。这个过程涉及到多次数据拷贝和CPU上下文切换。</li>
<li>而Kafka使用了<strong>零拷贝技术</strong>，允许数据直接从内核空间的页缓存，发送到网卡，全程不经过用户应用程序。这极大地减少了数据拷贝次数和CPU开销，是Kafka实现超高数据发送性能的秘密武器之一。</li>
</ul>
</li>
<li><strong>批处理（Batching）</strong>：它体现在生产者和消费者两端。<ul>
<li><strong>生产者侧：</strong> 生产者不会来一条消息就立刻发送一条，而是会将多条消息收集成一个<strong>批次 (Batch)</strong>，然后再统一发送给 Broker，大大减少了网络请求的开销。</li>
<li><strong>消费者侧：</strong> 消费者也是一次性从 Broker 拉取一个批次的数据回来处理，而不是一条一条地去请求。</li>
</ul>
</li>
</ul>
<h3 id="并行化架构设计"><a href="#并行化架构设计" class="headerlink" title="并行化架构设计"></a>并行化架构设计</h3><p>**分区机制 (Partitioning):：**这是 Kafka 实现水平扩展和高并发的根本。一个 Topic 被分成多个分区，这些分区可以被分布在不同的 Broker 服务器上。</p>
<ul>
<li><strong>写并行：</strong> 生产者可以同时向多个分区写入数据。</li>
<li><strong>读并行：</strong> 消费者组内的多个消费者可以同时消费不同的分区。</li>
<li>一个 Topic 的总吞吐量，理论上是<strong>所有分区的吞吐量之和</strong>。如果觉得吞吐量不够，最直接的办法就是增加 Topic 的分区数（并相应增加消费者数量），以此来水平扩展整个系统的处理能力。</li>
</ul>
<h3 id="精简的协议与数据结构"><a href="#精简的协议与数据结构" class="headerlink" title="精简的协议与数据结构"></a><strong>精简的协议与数据结构</strong></h3><ul>
<li><strong>二进制协议:</strong> Kafka 客户端和服务器之间使用非常精简的二进制协议进行通信，开销小，序列化和反序列化效率高。</li>
<li><strong>简单的日志结构:</strong> 分区的数据文件就是简单的日志文件，查询时通过 Offset 进行，这是一个简单的数学计算，不需要像数据库那样复杂的索引结构，因此查找效率非常高。</li>
</ul>
<h3 id="小结"><a href="#小结" class="headerlink" title="小结"></a>小结</h3><p>Kafka之所以能实现这么高的并发和吞吐能力，主要得益于它在四个方面的精妙设计：</p>
<p><strong>第一，是对磁盘的极致高效利用。</strong> 它通过采用顺序读写（Append-only Log）的方式，将慢速的磁盘随机I&#x2F;O变成了接近内存速度的顺序I&#x2F;O。同时，它充分利用了操作系统的页缓存（Page Cache），实现了读写的进一步加速。</p>
<p><strong>第二，是极致的I&#x2F;O优化。</strong> 它使用了‘零拷贝’技术，在数据发送时避免了不必要的内核与用户空间的数据复制，大大降低了CPU开销。此外，无论是生产者还是消费者，都采用了‘批处理’的设计，将多次小的网络请求合并为一次大的请求，极大地提升了效率。</p>
<p><strong>第三，是它的并行化架构。</strong> Kafka通过‘分区’机制，将一个Topic的数据打散到多个Broker上，实现了读写的并行处理。Topic的整体吞吐量可以通过增加分区数来水平扩展。</p>
<p><strong>第四，是它精简的底层设计。</strong> 它使用了高效的二进制通信协议，并且其核心的数据结构（日志文件）非常简单，通过Offset进行数据定位，查询效率很高。</p>
<p>总的来说，Kafka并非凭空变快，而是通过这一系列精妙的设计，将压力分解、将操作合并、将数据流优化，最终实现了看似不可思议的高吞吐能力。”</p>
<h2 id="Kafka-消费之后的消息会被删除吗？"><a href="#Kafka-消费之后的消息会被删除吗？" class="headerlink" title="Kafka 消费之后的消息会被删除吗？"></a>Kafka 消费之后的消息会被删除吗？</h2><p><strong>答：绝对不会。这是 Kafka 与传统消息队列（如 RabbitMQ）最核心、最本质的区别之一。</strong></p>
<ul>
<li><strong>传统消息队列：</strong> 消息被消费（并确认）后，通常会从队列中删除，因为它被视为一个“待办事项”，办完了就销毁。</li>
<li><strong>Kafka：</strong> <strong>消费行为本身，绝对不会导致 Kafka 删除消息。</strong></li>
</ul>
<p><strong>为什么不删除？</strong><br>在 Kafka 的世界里，数据被看作是一条<strong>事实记录流（Stream of Facts）</strong>，而不是一次性的任务。消费者（Consumer）更像是一个“读者”，它只是从日志的某个位置（我们称之为 <strong>Offset</strong>）开始读取数据。</p>
<ul>
<li>消费者的消费进度，仅仅是移动它自己的书签（Offset）。</li>
<li>多个不同的消费者组（比如“实时风控组”、“数据分析组”、“日志监控组”）可以<strong>独立地、反复地</strong>消费同一份数据，它们的消费进度互不影响。一个组读完了，另一个组可能才刚开始读。</li>
</ul>
<p><strong>那么，数据到底什么时候被删除？</strong></p>
<p>数据删除<strong>只和 Topic 配置的“数据保留策略 (Log Retention Policy)”有关</strong>。Kafka 提供两种主要的保留策略：</p>
<ol>
<li><strong>基于时间的保留 (Time-based Retention):</strong><ul>
<li>这是最常用的策略。你可以为一个 Topic 设置一个保留时长，比如 7 天。</li>
<li><strong>配置示例：</strong> <code>retention.ms=604800000</code> (7天的毫秒数)</li>
<li><strong>效果：</strong> Kafka 会启动一个后台线程，定期检查并<strong>自动删除</strong>那些发布时间超过 7 天的旧数据，<strong>无论这些数据是否被消费过。</strong></li>
</ul>
</li>
<li><strong>基于大小的保留 (Size-based Retention):</strong><ul>
<li>你也可以为一个 Topic 设置一个总的存储大小阈值，比如 50 GB。</li>
<li><strong>配置示例：</strong> <code>retention.bytes=53687091200</code> (50 GB的字节数)</li>
<li><strong>效果：</strong> 当这个 Topic 的总数据量将要超过 50 GB 时，Kafka 会<strong>从最老的数据开始删除</strong>，以确保总大小不超过这个限制。</li>
</ul>
</li>
</ol>
<p>通常，你可以同时设置这两个参数，任何一个条件先被触发，都会导致数据被删除。</p>
<h2 id="消费者组-Consumer-Group-和消费过程"><a href="#消费者组-Consumer-Group-和消费过程" class="headerlink" title="消费者组 (Consumer Group) 和消费过程"></a>消费者组 (Consumer Group) 和消费过程</h2><h3 id="消费者组-Consumer-Group-Kafka-如何实现并行处理"><a href="#消费者组-Consumer-Group-Kafka-如何实现并行处理" class="headerlink" title="消费者组 (Consumer Group) - Kafka 如何实现并行处理"></a>消费者组 (Consumer Group) - Kafka 如何实现并行处理</h3><p><strong>1. 技术定义</strong></p>
<ul>
<li><strong>消费者组 (Consumer Group):</strong> 一个消费者组由一个或多个消费者实例（进程）组成。它们共享同一个 <code>group.id</code>，并作为一个整体，共同来消费一个或多个 Topic 的数据。</li>
</ul>
<p><strong>2. 核心工作原则（这是关键）</strong></p>
<p>Kafka 通过消费者组来实现两件事：<strong>负载均衡</strong>和<strong>并行消费</strong>。它遵循一条黄金法则：</p>
<blockquote>
<p>一个 Topic 的同一个分区，在任意时刻，只能被同一个消费者组里的一个消费者实例所消费。</p>
</blockquote>
<p>这条规则的<strong>作用域，仅限于单个消费者组（Consumer Group）内部</strong>。不同的消费者组之间是完全独立的、互不干扰的。</p>
<p>换句话说，分区是消费的最小并行单元。Kafka 会把一个 Topic 的所有分区，尽可能均匀地分配给一个消费者组里的所有成员。</p>
<p><strong>3. 分配规则与场景示例</strong></p>
<p>我们来看一个 Topic，名为 <code>log_topic</code>，它有 <strong>4 个分区</strong>（P0, P1, P2, P3）。</p>
<ul>
<li><strong>场景 A：组里只有 1 个消费者 (C1)</strong><ul>
<li><strong>分配结果：</strong> 消费者 C1 会获得全部分区的消费权，即它需要自己处理 P0, P1, P2, P3 的所有消息。</li>
</ul>
</li>
<li><strong>场景 B：组里有 2 个消费者 (C1, C2)</strong><ul>
<li><strong>分配结果：</strong> Kafka 会进行负载均衡。C1 可能会被分配 P0 和 P1，C2 会被分配 P2 和 P3。消费能力理论上翻了一倍。</li>
</ul>
</li>
<li><strong>场景 C：组里有 4 个消费者 (C1, C2, C3, C4)</strong><ul>
<li><strong>分配结果：</strong> 这是最理想的并行状态。每个消费者刚好分配到 1 个分区。C1-&gt;P0, C2-&gt;P1, C3-&gt;P2, C4-&gt;P3。</li>
</ul>
</li>
<li><strong>场景 D：组里有 5 个消费者 (C1, C2, C3, C4, C5)</strong><ul>
<li><strong>分配结果：</strong> 由于分区总共只有 4 个，根据“某一时刻一个分区只能被一个消费者消费”的原则，有 4 个消费者会被分配到分区。<strong>而第 5 个消费者 (C5) 将会处于空闲（idle）状态，接收不到任何消息。</strong></li>
</ul>
</li>
</ul>
<p><strong>4. 消费者组的意义</strong></p>
<ul>
<li><strong>高吞吐 &#x2F; 并行处理：</strong> 如果你觉得消息处理得太慢，只需要在同一个消费者组里增加更多的消费者实例，就可以线性地提升处理能力（但消费者数量超过分区数就无效了）。</li>
<li><strong>高可用 &#x2F; 故障转移：</strong> 如果组里的某个消费者实例突然宕机，它之前负责消费的分区，会被 Kafka 自动地重新分配给组里其他存活的消费者。这个过程被称为<strong>重平衡 (Rebalance)</strong>。</li>
</ul>
<h2 id="消费者组-Consumer-Group-的“总控-调度”模型"><a href="#消费者组-Consumer-Group-的“总控-调度”模型" class="headerlink" title="消费者组 (Consumer Group) 的“总控-调度”模型"></a>消费者组 (Consumer Group) 的“总控-调度”模型</h2><ul>
<li><strong>Group Coordinator (总控中心):</strong> 这是集群中某一个 Broker 担当的角色。它专门负责管理某一个消费者组，比如维护组成员列表、监控成员心跳，以及最重要的——<strong>主持和启动重平衡 (Rebalance)</strong>，也就是“分配任务”。</li>
<li><strong>Consumers (一线员工):</strong> 组里的每个消费者实例就是 worker。它们负责执行具体的工作（消费分区），并定期向 Coordinator 汇报心跳（表示自己还活着）。</li>
</ul>
<h3 id="1-“部分消费者没有分配到消息”（员工闲置问题）"><a href="#1-“部分消费者没有分配到消息”（员工闲置问题）" class="headerlink" title="1. “部分消费者没有分配到消息”（员工闲置问题）"></a>1. “部分消费者没有分配到消息”（员工闲置问题）</h3><p>这种情况确实会发生，其根本原因是：<strong>组内的消费者实例数量 &gt; Topic 的分区数量</strong>。</p>
<ul>
<li><strong>核心原则：</strong> Kafka 的黄金法则是，一个分区在同一时刻只能被组内的一个消费者消费。分区是最小的工作单元。</li>
<li><strong>举例：</strong> 一个 Topic 有 5 个分区，但你的消费组里却启动了 8 个消费者实例。</li>
<li><strong>结果：</strong> Coordinator 会将 5 个分区一对一地分配给 5 个消费者。剩下的 3 个消费者因为“无任务可领”，就会处于<strong>空闲 (idle)</strong> 状态，它们不会收到任何消息。</li>
</ul>
<p><strong>要点：</strong> 这说明通过无限增加消费者来提升处理能力是有上限的，上限就是 Topic 的分区数。</p>
<h3 id="2-“消息分配不均匀”（工作量不均问题）"><a href="#2-“消息分配不均匀”（工作量不均问题）" class="headerlink" title="2. “消息分配不均匀”（工作量不均问题）"></a>2. “消息分配不均匀”（工作量不均问题）</h3><p>这种情况也很常见，通常发生在<strong>分区数不能被消费者数整除</strong>的情况下。</p>
<ul>
<li><strong>举例：</strong> 一个 Topic 有 7 个分区，但组里有 3 个消费者。</li>
<li><strong>结果：</strong> Coordinator 没法做到完美平均分配。根据分配策略（比如默认的 <code>RangeAssignor</code>），分配结果可能是：<ul>
<li>消费者 A：负责 P0, P1, P2 (3个分区)</li>
<li>消费者 B：负责 P3, P4 (2个分区)</li>
<li>消费者 C：负责 P5, P6 (2个分区)</li>
</ul>
</li>
<li><strong>后果：</strong> 消费者 A 的负载会比 B 和 C 更重。在设计系统时，需要考虑到这种不均衡的可能性。</li>
</ul>
<h3 id="3-“重复分配消息”（任务交接问题）"><a href="#3-“重复分配消息”（任务交接问题）" class="headerlink" title="3. “重复分配消息”（任务交接问题）"></a>3. “重复分配消息”（任务交接问题）</h3><p>Kafka 的 Coordinator <strong>绝对不会在同一时刻，将同一个分区分配给两个不同的消费者</strong>。这会造成严重的数据混乱。</p>
<p>您感受到的“重复”，实际上指的是我们之前讨论过的 <strong>“重复消费 (Duplicate Processing)”</strong>，它发生在 <strong>Rebalance</strong> 的过程中。</p>
<ul>
<li><strong>场景：</strong><ol>
<li>消费者 A 正在处理分区 P0 的消息，它已经处理到 Offset 150，但还没来得及提交这个进度。</li>
<li>此时，消费者 A 突然崩溃。</li>
<li>Coordinator 检测到 A 死亡，触发 Rebalance，将分区 P0 这个“孤儿任务”<strong>重新分配</strong>给了消费者 B。</li>
<li>消费者 B 接手 P0 后，它会从<strong>上一次成功提交的 Offset</strong>（比如是100）开始消费。</li>
</ol>
</li>
<li><strong>结果：</strong> 消费者 B 会重新处理一遍 Offset 100 到 150 的消息。从旁观者角度看，消息好像被“重复分配”了，但实际上是<strong>任务被干净地交接了，只是接手者从上次的存档点开始工作而已</strong>。</li>
</ul>
<h3 id="4-“消费者在消费时是处于不可用状态的”"><a href="#4-“消费者在消费时是处于不可用状态的”" class="headerlink" title="4. “消费者在消费时是处于不可用状态的”"></a>4. “消费者在消费时是处于不可用状态的”</h3><p>这个描述同样非常精准，它指的正是 <strong>Rebalance 期间的“Stop-the-World”现象</strong>。</p>
<p>在正常情况下，消费者是一直在工作的。但一旦 Rebalance 被触发（比如有成员加入或退出），就会发生以下情况：</p>
<ol>
<li><strong>全体暂停：</strong> Coordinator 会通知组内<strong>所有</strong>的消费者：“全体注意，停止拉取新消息，准备重新分配任务！”</li>
<li><strong>放弃任务：</strong> 所有消费者会放弃对自己当前负责的分区的“所有权”。</li>
<li><strong>等待分配：</strong> 所有消费者都进入等待状态，直到 Coordinator 完成新的分配方案。</li>
<li><strong>恢复工作：</strong> 消费者收到新的任务分配后，才开始根据新的分配方案去消费。</li>
</ol>
<p>这个从“暂停”到“恢复工作”的整个过程，就是消费者组的“<strong>全体不可用状态</strong>”。频繁的 Rebalance 会严重影响消费组的整体吞吐量，是生产环境中需要尽量避免的。</p>
<h2 id="深入理解“某一时刻”：重平衡-Rebalance"><a href="#深入理解“某一时刻”：重平衡-Rebalance" class="headerlink" title="深入理解“某一时刻”：重平衡 (Rebalance)"></a>深入理解“某一时刻”：重平衡 (Rebalance)</h2><h3 id="什么是重平衡？"><a href="#什么是重平衡？" class="headerlink" title="什么是重平衡？"></a><strong>什么是重平衡？</strong></h3><p><strong>重平衡</strong>，本质上就是 Kafka 将一个 Topic 的全部分区，在<strong>同一个消费者组</strong>的所有成员之间，进行<strong>重新分配</strong>的过程。</p>
<p>它的最终目的是为了确保：</p>
<ol>
<li>组里的每个消费者都分到了合理的工作量。</li>
<li>Topic 的每个分区都有一个明确的负责人。</li>
</ol>
<h3 id="重平衡的三大触发场景"><a href="#重平衡的三大触发场景" class="headerlink" title="重平衡的三大触发场景"></a><strong>重平衡的三大触发场景</strong></h3><p><strong>1. 消费者组成员数量发生变化</strong></p>
<p>这完全是<strong>和消费者直接相关</strong>的。</p>
<ul>
<li><strong>新消费者加入：</strong><ul>
<li><strong>场景：</strong> 你觉得消费速度太慢，于是启动了一个新的消费者实例，并让它加入到现有的消费者组中。</li>
<li><strong>原因：</strong> 新来的成员需要被分配工作（分区）。为了公平，不能让它闲着，所以需要从其他成员那里拿走一些分区，重新进行“大锅饭”式的分配。</li>
</ul>
</li>
<li><strong>旧消费者离开：</strong><ul>
<li><strong>场景：</strong> 组里的一个消费者实例因为正常关闭或意外崩溃而下线。</li>
<li><strong>原因：</strong> 它之前负责的分区现在成了“孤儿”，无人处理。为了保证这些分区的数据能被继续消费，必须将它们分配给组里其他还存活的成员。我们之前讨论的 <code>session.timeout.ms</code> 和 <code>max.poll.interval.ms</code> 就是用来检测这种“意外离开”的。</li>
</ul>
</li>
</ul>
<p><strong>2. 订阅的 Topic 分区数量发生变化</strong></p>
<p>“<strong>分区导致</strong>”的情况。</p>
<ul>
<li><strong>场景：</strong> 一个 Topic <code>my-topic</code> 原本有 5 个分区，一个消费者组正在稳定地消费它。这时，运维管理员为了提升吞吐量，执行命令将 <code>my-topic</code> 的分区数增加到了 8 个。</li>
<li><strong>原因：</strong> 集群中突然多出来了 3 个新的分区（P5, P6, P7），这些新分区目前没有消费者负责。为了让这些新分区的数据也能被消费，Kafka 必须触发一次重平衡，将全部的 8 个分区在所有消费者之间重新分配。</li>
</ul>
<p><strong>3. 订阅的 Topic 本身发生变化</strong></p>
<ul>
<li><strong>场景：</strong> 一个消费者组原本只订阅了 <code>topic-A</code>。现在你修改了消费者的代码，让它同时订阅 <code>topic-A</code> 和 <code>topic-B</code>。</li>
<li><strong>原因：</strong> 整个消费者组需要消费的总分区列表发生了变化（增加了 <code>topic-B</code> 的所有分区）。旧的分配方案已经过时，因此必须触发重平衡，以制定一个包含两个 Topic 所有分区的新分配方案。</li>
</ul>
<h3 id="重平衡期间会发生什么？"><a href="#重平衡期间会发生什么？" class="headerlink" title="重平衡期间会发生什么？"></a><strong>重平衡期间会发生什么？</strong></h3><p>这是一个“<strong>Stop-the-World</strong>”的过程，对消费有一定影响：</p>
<ol>
<li><strong>暂停消费：</strong> 当 Rebalance 触发时，该消费组内的<strong>所有消费者</strong>都会暂停拉取和处理消息。</li>
<li><strong>重新分配：</strong> 由组协调器（Group Coordinator，一个 Broker）来主持，根据分配策略，为每个消费者成员重新分配分区。</li>
<li><strong>恢复消费：</strong> 分配完成后，每个消费者只消费新分配给自己的分区。</li>
</ol>
<h2 id="Offset-的提交机制"><a href="#Offset-的提交机制" class="headerlink" title="Offset 的提交机制"></a>Offset 的提交机制</h2><h3 id="1-概念回顾与定义"><a href="#1-概念回顾与定义" class="headerlink" title="1. 概念回顾与定义"></a><strong>1. 概念回顾与定义</strong></h3><ul>
<li><strong>Offset (位移):</strong> 我们之前提过，分区（Partition）内的每一条消息都有一个唯一的、从 0 开始递增的序列号，这就是 Offset。它就是消息的地址。</li>
<li><strong>提交位移 (Commit Offset):</strong> 消费者在消费消息的过程中，需要定期地向 Kafka 集群中的一个特殊内部 Topic（名为 <code>__consumer_offsets</code>）报告：“对于我负责的某个分区，我已经成功处理到哪个 Offset 了”。这个“报告”或“记录”的动作，就叫做<strong>提交位移</strong>。</li>
</ul>
<p><strong>它的核心目的，就像在书里夹一个书签：</strong></p>
<p>当消费者重启，或者分区被重新分配给另一个消费者时，新的消费者可以先去<code>__consumer_offsets</code>这个地方查找这个分区对应的“书签”，从而准确地知道应该从哪里开始继续阅读，以保证数据处理的连续性。</p>
<h3 id="2-两种核心的提交方式"><a href="#2-两种核心的提交方式" class="headerlink" title="2. 两种核心的提交方式"></a><strong>2. 两种核心的提交方式</strong></h3><p>提交“书签”的方式主要有两种：</p>
<ul>
<li><strong>方式一：自动提交 (Auto Commit)</strong><ul>
<li><strong>工作方式：</strong> 这是 Kafka 消费者的<strong>默认行为</strong>。你只需要在配置中设置 <code>enable.auto.commit=true</code>（默认就是 true），并设定一个时间间隔（<code>auto.commit.interval.ms</code>，默认是 5 秒）。消费者客户端会每隔 5 秒，自动地将它拉取到的<strong>最新 Offset</strong> 提交上去。</li>
<li><strong>优点：</strong> 非常简单，用户基本无感知，不用自己写提交代码。</li>
<li><strong>缺点（非常致命）：</strong> <strong>时机不精确，可能导致消息丢失或重复消费。</strong><ul>
<li><strong>场景1（重复消费）：</strong> 你的程序在 3 秒内处理完了 100 条消息，但还没到 5 秒的提交时间点，你的程序突然崩溃了。重启后，由于上次的进度没有被提交，它只能从 100 条消息之前的位置开始重新消费，导致这 100 条消息被重复处理。</li>
<li><strong>场景2（消息丢失，更危险）：</strong> 你的程序拉取了 100 条消息，还没开始处理，5 秒的提交时间就到了，客户端自动把这 100 条消息的进度提交了。紧接着，你的程序在处理第 10 条消息时崩溃了。重启后，由于进度已经被提交，它会从第 101 条消息开始消费，导致第 10 到 100 条消息永远没有被处理，造成了数据丢失。</li>
</ul>
</li>
</ul>
</li>
<li><strong>方式二：手动提交 (Manual Commit)</strong><ul>
<li><strong>工作方式：</strong> 在配置中设置 <code>enable.auto.commit=false</code>，然后在你的代码逻辑中，<strong>在你确认消息已经被业务逻辑完全成功处理之后</strong>（比如，数据已经成功写入数据库），再手动调用提交方法来更新 Offset。</li>
<li><strong>优点：</strong> <strong>控制权完全在开发者手中，非常可靠。</strong> 你可以确保只有当业务逻辑成功完成后，才去移动“书签”。这极大地保证了消息处理的准确性。</li>
<li><strong>常用的手动提交方法：</strong><ul>
<li><code>commitSync()</code> (同步提交): 它会阻塞程序，直到位移被成功提交才继续往下走。如果提交失败会一直重试。简单可靠，但会牺牲一点性能。</li>
<li><code>commitAsync()</code> (异步提交): 它不会阻塞程序，提交请求后立刻返回。性能更高，但如果提交失败，它不会自动重试，需要开发者在回调函数中自行处理。</li>
</ul>
</li>
</ul>
</li>
</ul>
<h3 id="1-解构消费者的位置指针：四个核心-Offset"><a href="#1-解构消费者的位置指针：四个核心-Offset" class="headerlink" title="1. 解构消费者的位置指针：四个核心 Offset"></a><strong>1. 解构消费者的位置指针：四个核心 Offset</strong></h3><p>为了精确控制消费，我们需要了解消费者在工作时涉及的四种“位移”或“指针”：</p>
<ul>
<li><strong>Committed Offset (已提交位移):</strong><ul>
<li><strong>定义：</strong> 这是我们之前讨论的“书签”。它被持久化地存储在 Kafka 的 <code>__consumer_offsets</code> 主题中。它代表消费者组<strong>确认已经成功处理完成</strong>的最后一个 Offset + 1。</li>
<li><strong>作用：</strong> 这是消费者<strong>故障恢复的依据</strong>。当消费者重启或 Rebalance 后，它会从这个位置开始消费。</li>
</ul>
</li>
<li><strong>Current Offset &#x2F; Position (当前消费位置):</strong><ul>
<li><strong>定义：</strong> 这是一个<strong>内存中</strong>的指针，代表消费者<strong>下一次调用 <code>poll()</code> 方法时应该获取的消息的起始位置</strong>。</li>
<li><strong>关系：</strong> 消费者调用 <code>poll()</code> 拉取一批数据后，这个 <code>Position</code> 指针就会向前移动。所以，<code>Position</code> 总是领先于 <code>Committed Offset</code>。(<code>Position</code> &gt;&#x3D; <code>Committed Offset</code>)</li>
</ul>
</li>
<li><strong>Log End Offset (LEO，日志末端位移):</strong><ul>
<li><strong>定义：</strong> 这不属于消费者，而是<strong>分区（Partition）本身的属性</strong>。它代表该分区中<strong>下一条待写入消息</strong>的 Offset。可以理解为分区当前“最末尾”的位置。</li>
<li><strong>作用：</strong> 消费者通过比较自己的 <code>Committed Offset</code> 和分区的 <code>LEO</code>，可以计算出<strong>消费延迟 (Lag)</strong>，即还有多少消息没被消费。<code>Lag = LEO - Committed Offset</code>。</li>
</ul>
</li>
<li><strong>Start Offset &#x2F; Beginning Offset (起始位移):</strong><ul>
<li><strong>定义：</strong> 这也是<strong>分区本身的属性</strong>，代表该分区中<strong>现存的最旧的一条消息</strong>的 Offset。</li>
<li><strong>作用：</strong> 通常是 0，但如果因为数据保留策略删除了旧数据，这个值就会变大。</li>
</ul>
</li>
</ul>
<h3 id="2-auto-offset-reset：什么时候-Kafka-会‘找不到-Offset’？"><a href="#2-auto-offset-reset：什么时候-Kafka-会‘找不到-Offset’？" class="headerlink" title="2. auto.offset.reset：什么时候 Kafka 会‘找不到 Offset’？"></a><strong>2. <code>auto.offset.reset</code>：<strong>什么时候 Kafka 会‘找不到 Offset’</strong>？</strong></h3><p><strong>触发时机（找不到 Offset 的两种情况）：</strong></p>
<ol>
<li><strong>全新的消费者组：</strong> 一个全新的 <code>group.id</code> 第一次启动，它在 Kafka 中没有任何历史记录，自然也就没有已提交的 <code>Committed Offset</code>。</li>
<li><strong>位移已过期：</strong> 消费者提交了 Offset（比如 500），然后下线了很长时间（例如一周）。在这一周里，Kafka 的数据保留策略已经将旧数据删除，现在分区里最老的 Start Offset 已经是 1000 了。当这个消费者再次上线时，它想从 500 开始消费，但这个位置的数据早已不存在，因此“找不到 Offset”。</li>
</ol>
<p>当这些情况发生时，<code>auto.offset.reset</code> 参数就决定了消费者的行为：</p>
<ul>
<li><code>earliest</code>：“从头读起”。消费者会从该分区当前可用的<strong>最早的 Offset</strong> (Start Offset) 开始消费；但是需要注意的是，earliest 会存在重复处理的可能性。<ul>
<li>情况一：正常下线（先 Commit，后下线）<ul>
<li><strong>处理完成：</strong> 消费者处理完一批消息（比如到 Offset 150）。</li>
<li><strong>成功提交：</strong> 调用 <code>commitSync()</code> 或 <code>commitAsync()</code> 成功，将“书签”更新到 151。</li>
<li><strong>服务下线：</strong> 程序正常关闭。</li>
<li><strong>重新上线：</strong> 程序重启后，去 Kafka 读取“书签”，发现是 151。</li>
<li><strong>结果：</strong> 从 Offset 151 开始消费，一切正常，<strong>没有重复，也没有遗漏</strong>。</li>
</ul>
</li>
<li>情况二：异常下线（来不及 Commit 就下线）<ul>
<li><strong>处理完成：</strong> 消费者处理完一批消息（比如到 Offset 150），数据已经写入数据库。</li>
<li><strong>提交前崩溃：</strong> 在更新“书签”到 151 <strong>之前</strong>，程序因意外（如服务器断电、进程被强制杀死）而崩溃。</li>
<li><strong>重新上线：</strong> 程序重启后，去 Kafka 读取“书签”，发现书签还停留在<strong>上一次成功提交的位置</strong>（比如 Offset 100）。</li>
<li><strong>结果：</strong> 消费者只能从旧的“书签”位置 100 开始重新拉取数据。因此，它会<strong>再一次</strong>处理 100 到 150 的消息，这就造成了<strong>重复处理</strong>。</li>
</ul>
</li>
</ul>
</li>
<li><code>latest</code>：（默认值）“只读新的”。消费者会直接跳到分区的<strong>最末尾</strong> (Log End Offset) 开始消费。它会忽略掉所有在它启动之前就已经存在的数据。</li>
<li><code>none</code>：“直接报错”。如果找不到有效的 Offset，消费者会直接抛出 <code>NoOffsetForPartitionException</code> 异常，将问题交给程序自己处理。</li>
</ul>
<h3 id="3-如何选择-auto-offset-reset-的值？——-一个基于业务场景的决策指南"><a href="#3-如何选择-auto-offset-reset-的值？——-一个基于业务场景的决策指南" class="headerlink" title="3. 如何选择 auto.offset.reset 的值？—— 一个基于业务场景的决策指南"></a><strong>3. 如何选择 <code>auto.offset.reset</code> 的值？—— 一个基于业务场景的决策指南</strong></h3><p>选择哪个值，取决于你的应用<strong>能否容忍数据丢失</strong>。</p>
<p><strong>1. 选择 <code>latest</code> (默认值)</strong></p>
<ul>
<li><strong>适合的业务场景：</strong><ul>
<li>实时监控和告警系统</li>
<li>展示最新状态的仪表盘 (Dashboard)</li>
<li>对时效性要求极高，但对历史数据完整性不敏感的应用</li>
</ul>
</li>
<li><strong>决策逻辑：</strong><br>这类应用的核心是“<strong>关注当下</strong>”。如果系统中断了一小时，它最关心的是尽快跟上当前的实时数据流，而不是回头去处理一小时前的旧告警。因此，它选择“忽略历史，从最新的开始”，这是最合理的。</li>
<li><strong>需要承担的风险：潜在的数据丢失风险。</strong> 如果服务因为任何原因（无论是新加入还是位移过期）发生了位移重置，它会<strong>永久性地跳过</strong>所有在它离线期间产生的数据。</li>
</ul>
<p><strong>2. 选择 <code>earliest</code></strong></p>
<ul>
<li><strong>适合的业务场景：</strong><ul>
<li>数据同步任务（例如，将数据从 Kafka 同步到数据库或数据仓库）</li>
<li>离线数据分析和报表系统</li>
<li>所有<strong>数据完整性</strong>至关重要的核心业务系统</li>
</ul>
</li>
<li><strong>决策逻辑：</strong><br>这类应用的核心是“<strong>一条都不能少</strong>”。数据的任何缺失都会导致最终结果的错误。因此，即使代价是可能需要处理大量历史数据，也必须选择从最早的位置开始，以确保数据的完整性。</li>
<li><strong>需要承担的风险：潜在的数据重复处理和启动延迟。</strong> 如果一个全新的消费组错误地配置为 <code>earliest</code>，它可能会试图从分区中现存的最早（可能是几天甚至几周前）的数据开始消费，这可能不是预期的行为，并可能给下游系统带来巨大压力。</li>
</ul>
<p><strong>3. 选择 <code>none</code></strong></p>
<ul>
<li><strong>适合的业务场景：</strong><ul>
<li>极其敏感的金融交易或审计系统</li>
<li>你希望对位移丢失的情况有完全的、自定义的控制权</li>
</ul>
</li>
<li><strong>决策逻辑：</strong><br>这类应用的核心是“<strong>杜绝任何不确定性</strong>”。<code>earliest</code> 和 <code>latest</code> 都是一种“猜测”，而 <code>none</code> 则拒绝猜测。它会直接抛出异常，强制程序或运维人员介入，搞清楚到底发生了什么，然后再手动决定从哪里开始消费。这是最安全、但自动化程度最低的选择。</li>
<li><strong>需要承担的代价：</strong><br>需要编写额外的异常处理代码，并可能需要人工介入，降低了系统的自动化程度，但换来了最高的确定性。</li>
</ul>
<hr>
<p><strong>结论与经验法则</strong></p>
<p>所以，不存在“最好”的设置，只有“<strong>最适合你的业务场景</strong>”的设置。</p>
<ul>
<li><strong>经验法则 (Rule of Thumb):</strong><ul>
<li>如果你的应用<strong>能容忍数据丢失</strong>，但需要尽快跟上实时流，用 <code>latest</code>。</li>
<li>如果你的应用<strong>绝不能丢失任何数据</strong>，用 <code>earliest</code>，并为可能处理大量历史数据做好准备。</li>
<li>如果你的应用处理的是<strong>极其敏感的数据</strong>，任何不确定性都需要报警并由人来决策，用 <code>none</code>。</li>
</ul>
</li>
</ul>
<h3 id="4-会话管理与-max-poll-interval-ms：“你还活着吗？”"><a href="#4-会话管理与-max-poll-interval-ms：“你还活着吗？”" class="headerlink" title="4. 会话管理与 max.poll.interval.ms：“你还活着吗？”"></a><strong>4. 会话管理与 <code>max.poll.interval.ms</code>：“你还活着吗？”</strong></h3><p>Kafka 有一套心跳机制来判断消费者是否存活。</p>
<ul>
<li><strong><code>session.timeout.ms</code> (会话超时):</strong> Broker（组协调器）会认为，如果一个消费者在这个时间内没有发送任何心跳，那么它就死了，会触发 Rebalance。</li>
<li><strong><code>heartbeat.interval.ms</code> (心跳间隔):</strong> 消费者客户端在后台会按照这个间隔，持续地向 Broker 发送心跳。这个值必须远小于 <code>session.timeout.ms</code>。</li>
</ul>
<p><strong>但是，心跳只能证明消费者的进程还活着，万一它卡在业务逻辑里（比如死循环），无法继续处理消息怎么办？</strong></p>
<p>这就是 <code>max.poll.interval.ms</code> 的作用。</p>
<ul>
<li><strong><code>max.poll.interval.ms</code> (处理时长上限):</strong> 这个参数定义了<strong>两次调用 <code>consumer.poll()</code> 方法之间的最大时间间隔</strong>。消费者的业务逻辑必须在这个时间内处理完并返回，再次调用 <code>poll()</code>。如果超过了这个时间，消费者客户端会主动认为自己“失联”，并离开消费组，同样也会触发 Rebalance。这可以防止“假活”的僵尸消费者拖垮整个消费进度。</li>
</ul>
<h3 id="4-如何避免长时间处理导致消费者被踢出？"><a href="#4-如何避免长时间处理导致消费者被踢出？" class="headerlink" title="4. 如何避免长时间处理导致消费者被踢出？"></a><strong>4. 如何避免长时间处理导致消费者被踢出？</strong></h3><p>这是 <code>max.poll.interval.ms</code> 带来的实际问题：如果我的业务逻辑确实很耗时，超过了默认的5分钟怎么办？</p>
<ol>
<li><strong>简单粗暴：调大参数。</strong> 直接增加 <code>max.poll.interval.ms</code> 的值。但这会延长真正检测到消费者死亡的时间，不是最佳方案。</li>
<li><strong>减少单次处理量：</strong> 调小 <code>max.poll.records</code> 参数，让每次 <code>poll()</code> 返回更少的消息，这样你的处理循环就能更快地结束。</li>
<li><strong>最佳实践：解耦处理（异步化）。</strong><ul>
<li>创建一个专门的 Kafka 消费线程，它的<strong>唯一工作</strong>就是快速地调用 <code>poll()</code>，将拉取到的消息塞进一个内存队列（例如 <code>BlockingQueue</code>）。这个线程的循环非常快，永远不会超时。</li>
<li>另外创建<strong>一个或多个工作线程池</strong>，由它们从内存队列中取出消息，慢慢地执行耗时的业务逻辑。</li>
<li><strong>注意：</strong> 这种模式下，Offset 管理变得更复杂。你必须在工作线程<strong>真正处理完</strong>数据后，再由消费线程去手动提交对应的 Offset。</li>
</ul>
</li>
</ol>

                
            </div>
            <hr/>

            



            <div class="tag_share" style="display: block;">
                <div class="post-meta__tag-list" style="display: inline-block;">
                    
                        <div class="article-tag">
                            
                                <a href="/tags/Kafka/">
                                    <span class="chip bg-color">Kafka</span>
                                </a>
                            
                        </div>
                    
                </div>
                <div class="post_share" style="zoom: 80%; width: fit-content; display: inline-block; float: right; margin: -0.15rem 0;">
                    <link rel="stylesheet" type="text/css" href="/libs/share/css/share.min.css">
<div id="article-share">

    

    

</div>

                </div>
            </div>
            
        </div>
    </div>

    

    

    

    

    

    

    

    

    

<article id="prenext-posts" class="prev-next articles">
    <div class="row article-row">
        
        <div class="article col s12 m6" data-aos="fade-up">
            <div class="article-badge left-badge text-color">
                <i class="fas fa-chevron-left"></i>&nbsp;上一篇</div>
            <div class="card">
                <a href="/2024/09/18/nginx-bi-ji/">
                    <div class="card-image">
                        
                        
                        <img src="/medias/featureimages/18.jpg" class="responsive-img" alt="Nginx笔记">
                        
                        <span class="card-title">Nginx笔记</span>
                    </div>
                </a>
                <div class="card-content article-content">
                    <div class="summary block-with-text">
                        
                            
                        
                    </div>
                    <div class="publish-info">
                        <span class="publish-date">
                            <i class="far fa-clock fa-fw icon-date"></i>2024-09-18
                        </span>
                        <span class="publish-author">
                            
                            <i class="fas fa-bookmark fa-fw icon-category"></i>
                            
                            <a href="/categories/%E4%B8%AD%E9%97%B4%E4%BB%B6/" class="post-category">
                                    中间件
                                </a>
                            
                            
                        </span>
                    </div>
                </div>
                
                <div class="card-action article-tags">
                    
                    <a href="/tags/Nginx/">
                        <span class="chip bg-color">Nginx</span>
                    </a>
                    
                </div>
                
            </div>
        </div>
        
        
        <div class="article col s12 m6" data-aos="fade-up">
            <div class="article-badge right-badge text-color">
                下一篇&nbsp;<i class="fas fa-chevron-right"></i>
            </div>
            <div class="card">
                <a href="/2024/08/23/git-bi-ji/">
                    <div class="card-image">
                        
                        
                        <img src="/medias/featureimages/15.jpg" class="responsive-img" alt="Git 命令完整笔记">
                        
                        <span class="card-title">Git 命令完整笔记</span>
                    </div>
                </a>
                <div class="card-content article-content">
                    <div class="summary block-with-text">
                        
                            
                        
                    </div>
                    <div class="publish-info">
                            <span class="publish-date">
                                <i class="far fa-clock fa-fw icon-date"></i>2024-08-23
                            </span>
                        <span class="publish-author">
                            
                            <i class="fas fa-bookmark fa-fw icon-category"></i>
                            
                            <a href="/categories/%E7%AC%94%E8%AE%B0/" class="post-category">
                                    笔记
                                </a>
                            
                            
                        </span>
                    </div>
                </div>
                
                <div class="card-action article-tags">
                    
                    <a href="/tags/Git/">
                        <span class="chip bg-color">Git</span>
                    </a>
                    
                </div>
                
            </div>
        </div>
        
    </div>
</article>

</div>



<!-- 代码块功能依赖 -->
<script type="text/javascript" src="/libs/codeBlock/codeBlockFuction.js"></script>


  <!-- 是否加载使用自带的 prismjs. -->
  <script type="text/javascript" src="/libs/prism/prism.min.js"></script>


<!-- 代码语言 -->

<script type="text/javascript" src="/libs/codeBlock/codeLang.js"></script>


<!-- 代码块复制 -->

<script type="text/javascript" src="/libs/codeBlock/codeCopy.js"></script>


<!-- 代码块收缩 -->

<script type="text/javascript" src="/libs/codeBlock/codeShrink.js"></script>



    </div>
    <div id="toc-aside" class="expanded col l3 hide-on-med-and-down">
        <div class="toc-widget card" style="background-color: white;">
            <div class="toc-title"><i class="far fa-list-alt"></i>&nbsp;&nbsp;目录</div>
            <div id="toc-content"></div>
        </div>
    </div>
</div>

<!-- TOC 悬浮按钮. -->

<div id="floating-toc-btn" class="hide-on-med-and-down">
    <a class="btn-floating btn-large bg-color">
        <i class="fas fa-list-ul"></i>
    </a>
</div>


<script src="/libs/tocbot/tocbot.min.js"></script>
<script>
    $(function () {
        tocbot.init({
            tocSelector: '#toc-content',
            contentSelector: '#articleContent',
            headingsOffset: -($(window).height() * 0.4 - 45),
            collapseDepth: Number('0'),
            headingSelector: 'h2, h3, h4'
        });

        // Set scroll toc fixed.
        let tocHeight = parseInt($(window).height() * 0.4 - 64);
        let $tocWidget = $('.toc-widget');
        $(window).scroll(function () {
            let scroll = $(window).scrollTop();
            /* add post toc fixed. */
            if (scroll > tocHeight) {
                $tocWidget.addClass('toc-fixed');
            } else {
                $tocWidget.removeClass('toc-fixed');
            }
        });

        
        /* 修复文章卡片 div 的宽度. */
        let fixPostCardWidth = function (srcId, targetId) {
            let srcDiv = $('#' + srcId);
            if (srcDiv.length === 0) {
                return;
            }

            let w = srcDiv.width();
            if (w >= 450) {
                w = w + 21;
            } else if (w >= 350 && w < 450) {
                w = w + 18;
            } else if (w >= 300 && w < 350) {
                w = w + 16;
            } else {
                w = w + 14;
            }
            $('#' + targetId).width(w);
        };

        // 切换TOC目录展开收缩的相关操作.
        const expandedClass = 'expanded';
        let $tocAside = $('#toc-aside');
        let $mainContent = $('#main-content');
        $('#floating-toc-btn .btn-floating').click(function () {
            if ($tocAside.hasClass(expandedClass)) {
                $tocAside.removeClass(expandedClass).hide();
                $mainContent.removeClass('l9');
            } else {
                $tocAside.addClass(expandedClass).show();
                $mainContent.addClass('l9');
            }
            fixPostCardWidth('artDetail', 'prenext-posts');
        });
        
    });
</script>

    

</main>




    <footer class="page-footer bg-color">
    

    <div class="container row center-align"
         style="margin-bottom: 15px !important;">
        <div class="col s12 m8 l8 copy-right">
            Copyright&nbsp;&copy;
            
                <span id="year">2023-2025</span>
            
            <a href="/about" target="_blank">Sean</a>
            |&nbsp;Powered by&nbsp;<a href="https://hexo.io/" target="_blank">Hexo</a>
            |&nbsp;Theme&nbsp;<a href="https://github.com/blinkfox/hexo-theme-matery" target="_blank">Matery</a>
            
            <br>
            
                &nbsp;<i class="fas fa-chart-area"></i>&nbsp;站点总字数:&nbsp;<span
                        class="white-color">124.7k</span>
            
            
            
                
            
            
                <span id="busuanzi_container_site_pv">
                &nbsp;|&nbsp;<i class="far fa-eye"></i>&nbsp;总访问量:&nbsp;
                    <span id="busuanzi_value_site_pv" class="white-color"></span>
            </span>
            
            
                <span id="busuanzi_container_site_uv">
                &nbsp;|&nbsp;<i class="fas fa-users"></i>&nbsp;总访问人数:&nbsp;
                    <span id="busuanzi_value_site_uv" class="white-color"></span>
            </span>
            
            <br>

            <!-- 运行天数提醒. -->
            
                <span id="sitetime"> Loading ...</span>
                <script>
                    var calcSiteTime = function () {
                        var seconds = 1000;
                        var minutes = seconds * 60;
                        var hours = minutes * 60;
                        var days = hours * 24;
                        var years = days * 365;
                        var today = new Date();
                        var startYear = "2023";
                        var startMonth = "7";
                        var startDate = "28";
                        var startHour = "0";
                        var startMinute = "0";
                        var startSecond = "0";
                        var todayYear = today.getFullYear();
                        var todayMonth = today.getMonth() + 1;
                        var todayDate = today.getDate();
                        var todayHour = today.getHours();
                        var todayMinute = today.getMinutes();
                        var todaySecond = today.getSeconds();
                        var t1 = Date.UTC(startYear, startMonth, startDate, startHour, startMinute, startSecond);
                        var t2 = Date.UTC(todayYear, todayMonth, todayDate, todayHour, todayMinute, todaySecond);
                        var diff = t2 - t1;
                        var diffYears = Math.floor(diff / years);
                        var diffDays = Math.floor((diff / days) - diffYears * 365);

                        // 区分是否有年份.
                        var language = 'zh-CN';
                        if (startYear === String(todayYear)) {
                            document.getElementById("year").innerHTML = todayYear;
                            var daysTip = 'This site has been running for ' + diffDays + ' days';
                            if (language === 'zh-CN') {
                                daysTip = '本站已运行 ' + diffDays + ' 天';
                            } else if (language === 'zh-HK') {
                                daysTip = '本站已運行 ' + diffDays + ' 天';
                            }
                            document.getElementById("sitetime").innerHTML = daysTip;
                        } else {
                            document.getElementById("year").innerHTML = startYear + " - " + todayYear;
                            var yearsAndDaysTip = 'This site has been running for ' + diffYears + ' years and '
                                + diffDays + ' days';
                            if (language === 'zh-CN') {
                                yearsAndDaysTip = '本站已运行 ' + diffYears + ' 年 ' + diffDays + ' 天';
                            } else if (language === 'zh-HK') {
                                yearsAndDaysTip = '本站已運行 ' + diffYears + ' 年 ' + diffDays + ' 天';
                            }
                            document.getElementById("sitetime").innerHTML = yearsAndDaysTip;
                        }
                    }

                    calcSiteTime();
                </script>
            
            <br>
            
        </div>
        <div class="col s12 m4 l4 social-link social-statis">
    <a href="https://github.com/HyxiaoGe" class="tooltipped" target="_blank" data-tooltip="访问我的GitHub" data-position="top" data-delay="50">
        <i class="fab fa-github"></i>
    </a>



    <a href="mailto:hyxiao97@gmail.com" class="tooltipped" target="_blank" data-tooltip="邮件联系我" data-position="top" data-delay="50">
        <i class="fas fa-envelope-open"></i>
    </a>













</div>
    </div>
</footer>

<div class="progress-bar"></div>


    <!-- 搜索遮罩框 -->
<div id="searchModal" class="modal">
    <div class="modal-content">
        <div class="search-header">
            <span class="title"><i class="fas fa-search"></i>&nbsp;&nbsp;搜索</span>
            <input type="search" id="searchInput" name="s" placeholder="请输入搜索的关键字"
                   class="search-input">
        </div>
        <div id="searchResult"></div>
    </div>
</div>

<script type="text/javascript">
$(function () {
    var searchFunc = function (path, search_id, content_id) {
        'use strict';
        $.ajax({
            url: path,
            dataType: "xml",
            success: function (xmlResponse) {
                // get the contents from search data
                var datas = $("entry", xmlResponse).map(function () {
                    return {
                        title: $("title", this).text(),
                        content: $("content", this).text(),
                        url: $("url", this).text()
                    };
                }).get();
                var $input = document.getElementById(search_id);
                var $resultContent = document.getElementById(content_id);
                $input.addEventListener('input', function () {
                    var str = '<ul class=\"search-result-list\">';
                    var keywords = this.value.trim().toLowerCase().split(/[\s\-]+/);
                    $resultContent.innerHTML = "";
                    if (this.value.trim().length <= 0) {
                        return;
                    }
                    // perform local searching
                    datas.forEach(function (data) {
                        var isMatch = true;
                        var data_title = data.title.trim().toLowerCase();
                        var data_content = data.content.trim().replace(/<[^>]+>/g, "").toLowerCase();
                        var data_url = data.url;
                        data_url = data_url.indexOf('/') === 0 ? data.url : '/' + data_url;
                        var index_title = -1;
                        var index_content = -1;
                        var first_occur = -1;
                        // only match artiles with not empty titles and contents
                        if (data_title !== '' && data_content !== '') {
                            keywords.forEach(function (keyword, i) {
                                index_title = data_title.indexOf(keyword);
                                index_content = data_content.indexOf(keyword);
                                if (index_title < 0 && index_content < 0) {
                                    isMatch = false;
                                } else {
                                    if (index_content < 0) {
                                        index_content = 0;
                                    }
                                    if (i === 0) {
                                        first_occur = index_content;
                                    }
                                }
                            });
                        }
                        // show search results
                        if (isMatch) {
                            str += "<li><a href='" + data_url + "' class='search-result-title'>" + data_title + "</a>";
                            var content = data.content.trim().replace(/<[^>]+>/g, "");
                            if (first_occur >= 0) {
                                // cut out 100 characters
                                var start = first_occur - 20;
                                var end = first_occur + 80;
                                if (start < 0) {
                                    start = 0;
                                }
                                if (start === 0) {
                                    end = 100;
                                }
                                if (end > content.length) {
                                    end = content.length;
                                }
                                var match_content = content.substr(start, end);
                                // highlight all keywords
                                keywords.forEach(function (keyword) {
                                    var regS = new RegExp(keyword, "gi");
                                    match_content = match_content.replace(regS, "<em class=\"search-keyword\">" + keyword + "</em>");
                                });

                                str += "<p class=\"search-result\">" + match_content + "...</p>"
                            }
                            str += "</li>";
                        }
                    });
                    str += "</ul>";
                    $resultContent.innerHTML = str;
                });
            }
        });
    };

    searchFunc('/search.xml', 'searchInput', 'searchResult');
});
</script>

    <!-- 白天和黑夜主题 -->
<div class="stars-con">
    <div id="stars"></div>
    <div id="stars2"></div>
    <div id="stars3"></div>  
</div>

<script>
    function switchNightMode() {
        $('<div class="Cuteen_DarkSky"><div class="Cuteen_DarkPlanet"></div></div>').appendTo($('body')),
        setTimeout(function () {
            $('body').hasClass('DarkMode') 
            ? ($('body').removeClass('DarkMode'), localStorage.setItem('isDark', '0'), $('#sum-moon-icon').removeClass("fa-sun").addClass('fa-moon')) 
            : ($('body').addClass('DarkMode'), localStorage.setItem('isDark', '1'), $('#sum-moon-icon').addClass("fa-sun").removeClass('fa-moon')),
            
            setTimeout(function () {
            $('.Cuteen_DarkSky').fadeOut(1e3, function () {
                $(this).remove()
            })
            }, 2e3)
        })
    }
</script>

    <!-- 回到顶部按钮 -->
<div id="backTop" class="top-scroll">
    <a class="btn-floating btn-large waves-effect waves-light" href="#!">
        <i class="fas fa-arrow-up"></i>
    </a>
</div>


    <script src="/libs/materialize/materialize.min.js"></script>
    <script src="/libs/masonry/masonry.pkgd.min.js"></script>
    <script src="/libs/aos/aos.js"></script>
    <script src="/libs/scrollprogress/scrollProgress.min.js"></script>
    <script src="/libs/lightGallery/js/lightgallery-all.min.js"></script>
    <script src="/js/matery.js"></script>

    

    
    
    

    <!-- 雪花特效 -->
     
        <script type="text/javascript">
            // 只在桌面版网页启用特效
            var windowWidth = $(window).width();
            if (windowWidth > 768) {
                document.write('<script type="text/javascript" src="/libs/others/snow.js"><\/script>');
            }
        </script>
    

    <!-- 鼠标星星特效 -->
    

    

    <!-- Baidu Analytics -->

    <!-- Baidu Push -->

<script>
    (function () {
        var bp = document.createElement('script');
        var curProtocol = window.location.protocol.split(':')[0];
        if (curProtocol === 'https') {
            bp.src = 'https://zz.bdstatic.com/linksubmit/push.js';
        } else {
            bp.src = 'http://push.zhanzhang.baidu.com/push.js';
        }
        var s = document.getElementsByTagName("script")[0];
        s.parentNode.insertBefore(bp, s);
    })();
</script>

    
    <script src="/libs/others/clicklove.js" async="async"></script>
    
    
    <script async src="/libs/others/busuanzi.pure.mini.js"></script>
    

    

    

    <!--腾讯兔小巢-->
    
    

    

    

    
    <script src="/libs/instantpage/instantpage.js" type="module"></script>
    

</body>

</html>
