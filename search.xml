<?xml version="1.0" encoding="utf-8"?>
<search> 
  
  
    
    <entry>
      <title>Markdown代码样式测试文件</title>
      <link href="/2025/04/26/demo/"/>
      <url>/2025/04/26/demo/</url>
      
        <content type="html"><![CDATA[<h1 id="Markdown代码样式测试文件"><a href="#Markdown代码样式测试文件" class="headerlink" title="Markdown代码样式测试文件"></a>Markdown代码样式测试文件</h1><p>这是一个用于测试Markdown代码格式和样式的文件，包含了多种代码块和格式化内容。</p><h2 id="目录"><a href="#目录" class="headerlink" title="目录"></a>目录</h2><ul><li><a href="#%E4%BB%A3%E7%A0%81%E5%9D%97%E6%B5%8B%E8%AF%95">代码块测试</a></li><li><a href="#%E8%A1%A8%E6%A0%BC%E6%B5%8B%E8%AF%95">表格测试</a></li><li><a href="#%E6%95%B0%E5%AD%A6%E5%85%AC%E5%BC%8F%E6%B5%8B%E8%AF%95">数学公式测试</a></li><li><a href="#%E5%88%97%E8%A1%A8%E6%B5%8B%E8%AF%95">列表测试</a></li><li><a href="#%E5%BC%95%E7%94%A8%E6%B5%8B%E8%AF%95">引用测试</a></li></ul><h2 id="代码块测试"><a href="#代码块测试" class="headerlink" title="代码块测试"></a>代码块测试</h2><h3 id="普通代码块"><a href="#普通代码块" class="headerlink" title="普通代码块"></a>普通代码块</h3><p>这是一个没有指定语言的代码块：</p><pre><code>function normalCode() &#123;  console.log(&quot;这是一个普通代码块&quot;);&#125;</code></pre><h3 id="Python代码块"><a href="#Python代码块" class="headerlink" title="Python代码块"></a>Python代码块</h3><pre class="line-numbers language-language-python"><code class="language-language-python">def hello_world():    print("Hello, World!")    # 一个简单的类定义class Person:    def __init__(self, name, age):        self.name = name        self.age = age            def greet(self):        return f"你好，我是&#123;self.name&#125;，今年&#123;self.age&#125;岁"        # 使用类p = Person("张三", 25)print(p.greet())<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><h3 id="JavaScript代码块"><a href="#JavaScript代码块" class="headerlink" title="JavaScript代码块"></a>JavaScript代码块</h3><pre class="line-numbers language-language-javascript"><code class="language-language-javascript">// 箭头函数const add = (a, b) => a + b;// 使用模板字符串function greet(name) &#123;  return `Hello, $&#123;name&#125;!`;&#125;// Promise示例function fetchData() &#123;  return new Promise((resolve, reject) => &#123;    setTimeout(() => &#123;      resolve(&#123; data: "这是一些数据" &#125;);    &#125;, 1000);  &#125;);&#125;// 异步函数async function getData() &#123;  try &#123;    const result = await fetchData();    console.log(result.data);  &#125; catch (error) &#123;    console.error("发生错误:", error);  &#125;&#125;<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><h3 id="Bash-Shell代码块"><a href="#Bash-Shell代码块" class="headerlink" title="Bash&#x2F;Shell代码块"></a>Bash&#x2F;Shell代码块</h3><pre class="line-numbers language-language-bash"><code class="language-language-bash">#!/bin/bash# 这是一个简单的shell脚本echo "当前目录是:"pwd# 循环示例for i in &#123;1..5&#125;; do  echo "第 $i 次迭代"done# 条件判断if [ -f "config.yml" ]; then  echo "配置文件存在"else  echo "配置文件不存在"fi<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><h3 id="Java代码块"><a href="#Java代码块" class="headerlink" title="Java代码块"></a>Java代码块</h3><pre class="line-numbers language-language-java"><code class="language-language-java">public class HelloWorld &#123;    public static void main(String[] args) &#123;        System.out.println("Hello, World!");                // 创建一个对象        Person person = new Person("李四", 30);        System.out.println(person.greet());    &#125;&#125;class Person &#123;    private String name;    private int age;        public Person(String name, int age) &#123;        this.name = name;        this.age = age;    &#125;        public String greet() &#123;        return "你好，我是" + name + "，今年" + age + "岁";    &#125;&#125;<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><h3 id="包含管道符的代码块（测试特殊字符）"><a href="#包含管道符的代码块（测试特殊字符）" class="headerlink" title="包含管道符的代码块（测试特殊字符）"></a>包含管道符的代码块（测试特殊字符）</h3><p>下面的代码块包含了管道符 <code>|</code>，这可能会被误解为表格分隔符：</p><pre class="line-numbers language-language-text"><code class="language-language-text"># 这行包含管道符echo "A" | grep "A"# 数据示例名称 | 年龄 | 职业小明 | 25 | 工程师小红 | 24 | 设计师<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><h2 id="表格测试"><a href="#表格测试" class="headerlink" title="表格测试"></a>表格测试</h2><p>这是一个标准的 Markdown 表格：</p><table><thead><tr><th>名称</th><th>年龄</th><th>职业</th></tr></thead><tbody><tr><td>小明</td><td>25</td><td>工程师</td></tr><tr><td>小红</td><td>24</td><td>设计师</td></tr><tr><td>小李</td><td>26</td><td>医生</td></tr></tbody></table><p>左对齐、居中和右对齐的混合表格：</p><table><thead><tr><th align="left">名称 (左对齐)</th><th align="center">年龄 (居中)</th><th align="right">薪资 (右对齐)</th></tr></thead><tbody><tr><td align="left">张三</td><td align="center">25</td><td align="right">¥10,000</td></tr><tr><td align="left">李四</td><td align="center">26</td><td align="right">¥12,000</td></tr><tr><td align="left">王五</td><td align="center">24</td><td align="right">¥9,500</td></tr></tbody></table><h2 id="数学公式测试"><a href="#数学公式测试" class="headerlink" title="数学公式测试"></a>数学公式测试</h2><p>这里是一些数学公式测试（使用 LaTeX 语法）：</p><p>行内公式: $E &#x3D; mc^2$</p><p>独立公式:</p><p>$$<br>\frac{d}{dx}e^x &#x3D; e^x<br>$$</p><p>复杂公式:</p><p>$$<br>\begin{align}<br>\nabla \times \vec{\mathbf{B}} -, \frac1c, \frac{\partial\vec{\mathbf{E}}}{\partial t} &amp; &#x3D; \frac{4\pi}{c}\vec{\mathbf{j}} \<br>\nabla \cdot \vec{\mathbf{E}} &amp; &#x3D; 4 \pi \rho \<br>\nabla \times \vec{\mathbf{E}}, +, \frac1c, \frac{\partial\vec{\mathbf{B}}}{\partial t} &amp; &#x3D; \vec{\mathbf{0}} \<br>\nabla \cdot \vec{\mathbf{B}} &amp; &#x3D; 0<br>\end{align}<br>$$</p><p>余弦相似度计算公式:</p><p>$$<br>similarity(A,B) &#x3D; \frac{A \cdot B}{||A|| \cdot ||B||}<br>$$</p><p>欧氏距离计算公式:</p><p>$$<br>distance(A,B) &#x3D; \sqrt{\sum_{i&#x3D;1}^{n}(A_i-B_i)^2}<br>$$</p><h2 id="列表测试"><a href="#列表测试" class="headerlink" title="列表测试"></a>列表测试</h2><h3 id="无序列表"><a href="#无序列表" class="headerlink" title="无序列表"></a>无序列表</h3><ul><li>第一项</li><li>第二项</li><li>第三项<ul><li>子项 1</li><li>子项 2<ul><li>子子项 1</li><li>子子项 2</li></ul></li></ul></li></ul><h3 id="有序列表"><a href="#有序列表" class="headerlink" title="有序列表"></a>有序列表</h3><ol><li>第一步</li><li>第二步</li><li>第三步<ol><li>子步骤 1</li><li>子步骤 2<ol><li>详细步骤 a</li><li>详细步骤 b</li></ol></li></ol></li></ol><h3 id="任务列表"><a href="#任务列表" class="headerlink" title="任务列表"></a>任务列表</h3><ul><li><input checked disabled type="checkbox"> 已完成任务</li><li><input disabled type="checkbox"> 未完成任务</li><li><input disabled type="checkbox"> 另一个未完成任务<ul><li><input checked disabled type="checkbox"> 已完成子任务</li><li><input disabled type="checkbox"> 未完成子任务</li></ul></li></ul><h2 id="引用测试"><a href="#引用测试" class="headerlink" title="引用测试"></a>引用测试</h2><blockquote><p>这是一个简单的引用</p></blockquote><p>多层嵌套引用:</p><blockquote><p>第一层引用</p><blockquote><p>第二层引用</p><blockquote><p>第三层引用</p><p>继续第三层</p></blockquote></blockquote></blockquote><p>带有其他元素的引用:</p><blockquote><h4 id="引用中的标题"><a href="#引用中的标题" class="headerlink" title="引用中的标题"></a>引用中的标题</h4><ul><li>引用中的列表项</li><li>另一个列表项</li></ul><pre class="line-numbers language-language-python"><code class="language-language-python"># 引用中的代码块print("Hello from a quote!")<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span></span></code></pre></blockquote><h2 id="图片和链接测试"><a href="#图片和链接测试" class="headerlink" title="图片和链接测试"></a>图片和链接测试</h2><h3 id="链接"><a href="#链接" class="headerlink" title="链接"></a>链接</h3><p><a href="https://www.markdownguide.org/">Markdown语法指南</a></p><p><a href="https://hexo.io/">Hexo官方网站</a></p><h3 id="图片"><a href="#图片" class="headerlink" title="图片"></a>图片</h3><p><img src="https://via.placeholder.com/600x400" alt="示例图片" title="这是一个占位图片"></p><h2 id="高级格式测试"><a href="#高级格式测试" class="headerlink" title="高级格式测试"></a>高级格式测试</h2><h3 id="高亮文本"><a href="#高亮文本" class="headerlink" title="高亮文本"></a>高亮文本</h3><p>使用 <code>&lt;mark&gt;</code> 标签可以 <mark>高亮显示文本</mark>。</p><h3 id="删除线和下划线"><a href="#删除线和下划线" class="headerlink" title="删除线和下划线"></a>删除线和下划线</h3><p><del>这是删除线文本</del> 和 <u>这是下划线文本</u>。</p><h3 id="脚注"><a href="#脚注" class="headerlink" title="脚注"></a>脚注</h3><p>这是一个带有脚注的文本<a href="%E8%BF%99%E6%98%AF%E8%84%9A%E6%B3%A8%E7%9A%84%E5%86%85%E5%AE%B9%E3%80%82">^1</a>。</p><h2 id="总结"><a href="#总结" class="headerlink" title="总结"></a>总结</h2><p>这个Markdown文档包含了多种常见的代码块和格式化元素，可以用来测试您的Hexo主题是否正确渲染这些元素。如果所有内容都能正确显示，那么您的配置应该是正确的。</p><p>如果出现问题，特别注意:</p><ol><li>代码块中的语言标记是否正确</li><li>包含特殊字符的代码块是否正确渲染</li><li>数学公式是否正确显示</li><li>表格是否对齐且正确显示</li></ol>]]></content>
      
      
      <categories>
          
          <category> 测试 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> Markdown </tag>
            
            <tag> 测试 </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>ConcurrentHashMap 整理</title>
      <link href="/2025/02/28/concurrenthashmap/"/>
      <url>/2025/02/28/concurrenthashmap/</url>
      
        <content type="html"><![CDATA[<p>ConcurrentHashMap 提供了线程安全的映射操作，可以在多线程环境下被安全地访问和修改，内部使用 数组+链表+红黑树 结构来存储元素。适用于高并发，特别是高读少写的场景。</p><h2 id="JDK-8-之前数据结构（数组-链表）"><a href="#JDK-8-之前数据结构（数组-链表）" class="headerlink" title="JDK 8 之前数据结构（数组+链表）"></a>JDK 8 之前数据结构（数组+链表）</h2><ul><li>内部结构分为多个 Segment（分段）。每个 Segment 是一个静态内部类，继承了 ReentrantLock，因此 Segment 就是可重入锁。</li><li>每个 Segment 包含多个 HashEntry，每个 HashEntry 是一个链表节点，包含键值对和指向下一个节点的引用。</li></ul><h2 id="并发操作机制"><a href="#并发操作机制" class="headerlink" title="并发操作机制"></a>并发操作机制</h2><ul><li><strong>并发读取</strong>：允许多个线程同时读取不同的 Segment 的数据，因为读取操作不需要锁定整个 Segment。</li><li><strong>并发写入</strong>：写入操作（如 put 和 remove）会在对应的 Segment 上加锁。这意味着不同 Segment 的写入操作可以同时进行，而相同 Segment 的写入操作则需要等待锁。</li></ul><p><strong>示例场景</strong></p><p>假设有 ConcurrentHashMap 内部有四个Segment，线程A和线程B分别向不同的键写入值，他们通过哈希算法定位到不同的Segment。因此，线程A和B可以同时进行操作，不会互相堵塞，从而实现高效的并发。</p><p>那假如说线程A和B通过哈希算法定位到同一个Segment呢？</p><p><strong>当多个线程定位到同一个 Segment 时，它们必须获得该 Segment 的锁才能进行任何操作。这意味着在任何时候，每个Segment只允许一个线程进行操作</strong>。</p><h2 id="扩容机制"><a href="#扩容机制" class="headerlink" title="扩容机制"></a>扩容机制</h2><h3 id="触发扩容"><a href="#触发扩容" class="headerlink" title="触发扩容"></a><strong>触发扩容</strong></h3><ul><li>当任何一个 Segment 的填充度达到阈值时（基于负载因子和 Segment 的容量），就会触发该 Segment 的扩容。</li><li>扩容是针对于单个 Segment 的，而不是整个 ConcurrentHashMap。</li><li>如果一个线程在进行插入操作时触发了扩容，该线程会锁定对应的 Segment 并开始扩容过程，其他试图访问同一个 Segment 的线程将会被堵塞（其他的Segment不会受影响），直到扩容完成。</li></ul><h3 id="扩容过程"><a href="#扩容过程" class="headerlink" title="扩容过程"></a><strong>扩容过程</strong></h3><p>当某个 Segment 的填充度达到设定阈值时，该 Segment 将独立触发扩容，这个过程包括：</p><ol><li>创建一个新的哈系统数组，大小通常是原数组的两倍。</li><li>重新计算旧数据的哈希值并将数据迁移到新数组。</li><li>迁移完成后，将旧 Segment 的引用更新为新 Segment。</li></ol><p><strong>利弊点</strong>：</p><ul><li>这种扩容机制减少了整个 ConcurrentHashMap 范围内的锁竞争，因为只有被扩容的 Segment 会被锁定，扩容和数据迁移通常由触发扩容的单个线程完成的。</li><li>然而会存在局限性，在单个 Segment 达到较大时，扩容过程仍可能达到性能瓶颈，因为其他线程需要等待扩容线程完成操作。</li></ul><h3 id="小结"><a href="#小结" class="headerlink" title="小结"></a>小结</h3><ol><li>提高数据访问效率<ul><li>在不同线程访问不同 Segment 的场景中，由于锁是分段的，线程间几乎不会相互堵塞，这大大提高了数据访问的效率。</li></ul></li><li>减少锁的范围<ul><li>锁分段技术通过仅锁定部分数据结构，来减少锁的范围，这意味着更少的线程会因为等待锁被堵塞。</li></ul></li><li>降低锁竞争<ul><li>锁分段机制有效降低了竞争，特别是有大量读操作和一定量写操作的情况下。</li></ul></li></ol><h2 id="JDK-8及以后"><a href="#JDK-8及以后" class="headerlink" title="JDK 8及以后"></a>JDK 8及以后</h2><p><strong>ConcurrentHashMap 的进化</strong></p><p>在JDK8及之后的版本中，ConcurrentHashMap的内部结构和锁机制有了重大改进，主要是引入了<code>红黑树</code> 来优化长链表带来的性能问题，并且取消了 Segment 的使用，改为直接对节点进行分散加锁。</p><h3 id="数据结构"><a href="#数据结构" class="headerlink" title="数据结构"></a><strong>数据结构</strong></h3><ul><li><strong>Node数组</strong>：使用统一的 Node 数组替代了旧版本的多个 Segment。每个 Node 包含了一个 key, value 及指向下一个 Node 的引用。</li><li><strong>链表和红黑树</strong>：当链表长度超过设定阈值时（默认为8），自动转化为红黑树，提升查找效率。</li></ul><h3 id="底线实现"><a href="#底线实现" class="headerlink" title="底线实现"></a><strong>底线实现</strong></h3><ul><li><strong>CAS操作</strong>：用于无锁的读取和高效的更新，实现原子性操作。</li><li><strong>Synchronized 同步块</strong>：控制复杂的写操作，如转换链表为红黑树。</li></ul><h3 id="特性和并发控制"><a href="#特性和并发控制" class="headerlink" title="特性和并发控制"></a>特性和并发控制</h3><ul><li><strong>并发读取</strong>：无锁操作允许多线程可以同时进行读取操作，读取操作是完全无锁的。</li><li><strong>并发写入</strong>：写入操作使用了 CAS 操作和 synchronized 块。CAS 用于简单的更新，而 synchronized 块用于删除或（链表转红黑树）操作。</li></ul><p><strong>示例场景</strong></p><p>假设有两个线程：线程A和线程B，两个线程分别向ConcurrentHashMap中添加值：</p><ul><li>两个键经过哈希运算之后，分别发生在不同的key中，那么更新操作主要依赖于CAS操作来安全地完成更新，而不需要锁定这个段。</li><li>如果两个键恰好映射到同一个桶，且其中一个操作需要更复杂的同步（如转换链表为红黑树或删除操作），则会使用synchronized来锁定这个特定的桶或节点，另外一个线程需要被堵塞。</li></ul><p>这种新的机制减少了锁的使用，提高了读取效率和写操作的并发控制能力。允许更多线程无锁地读取数据，同时仍然保持一定程度的写入性能。</p><h2 id="扩容"><a href="#扩容" class="headerlink" title="扩容"></a>扩容</h2><h3 id="触发条件"><a href="#触发条件" class="headerlink" title="触发条件"></a><strong>触发条件</strong></h3><ul><li>扩容通常在两种情况下被触发：当桶的数量不足以容纳当前元素时，或者单个链表的长度过长，影响了查询效率。</li></ul><h3 id="扩容过程-1"><a href="#扩容过程-1" class="headerlink" title="扩容过程"></a><strong>扩容过程</strong></h3><ol><li>新建数组：<ul><li>当扩容开始时，创建一个新的<code>节点数组</code>，其容量是原数组的两倍。</li></ul></li><li>数据迁移：<ul><li>ConcurrentHashMap 会将旧数组中的每个桶（bucket）中的节点迁移到新数组中。整个过程是并发进行的，多个线程可以同时参与到不同桶的迁移过程中。</li></ul></li><li>重哈希：<ul><li>每个节点在迁移时需要重新计算其在新数组中的位置。这是因为数组大小改变后，原哈希值映射到新数组的位置也可能发生变化。</li></ul></li><li>转移节点：<ul><li>对于链表中的每个节点，根据其哈希值确定它在新数组中的位置，并将其移动到新位置。如果原链表已经转换为红黑树，那么红黑树也会重新组织并迁移到新数组中。</li></ul></li></ol><p><strong>并发控制：</strong></p><p>在扩容过程中，ConcurrentHashMap 使用了精细的并发控制机制来确保数据一致性和线程安全。它允许多个线程同时参与扩容过程，每个线程可以处理一部分数据的迁移，从而加快整体扩容过程。</p><h3 id="锁定特定桶（bucket）"><a href="#锁定特定桶（bucket）" class="headerlink" title="锁定特定桶（bucket）"></a>锁定特定桶（bucket）</h3><ol><li><strong>粒度更细的锁</strong>：锁的粒度更细。它不再锁定整个Segment，而是锁定特定的桶。</li><li><strong>使用synchronized关键字</strong>：Synchronized关键字来锁定特定的桶。当一个线程想要访问或修改一个桶时，它必须首先获取该桶的锁。</li><li><strong>每个桶作为独立的锁</strong>：每个桶都作为一个独立的锁，可以被单独锁定或解锁。这减少了线程的竞争，因为不同的线程可以锁定不同的桶。</li></ol><p><strong>工作流程</strong></p><ol><li>**计算桶的索引：**当一个线程想要添加、删除或访问一个元素时，它首先会计算元素的hash值。</li><li><strong>获取桶的锁</strong>：线程在操作桶之前必须首先获取该桶的锁。如果锁不可用（已经被其他线程持有），线程将被堵塞，直到锁变为可用。</li><li><strong>操作桶</strong>：一旦线程获取了桶的锁，它就可以安全地修改该桶。</li><li><strong>释放锁</strong>：操作完成后，线程必须释放桶的锁，以便其他线程可以锁定该桶。</li></ol><p>通过这种方式，Java 8的ConcurrentHashMap允许多个线程同时访问和修改不同的桶，从而实现了更高的并发性和性能。同时，通过锁定特定的桶，它确保了线程安全性，防止了多个线程同时修改同一个桶的情况。</p><h2 id="CAS和Synchronized在ConcurrentHashMap中的应用"><a href="#CAS和Synchronized在ConcurrentHashMap中的应用" class="headerlink" title="CAS和Synchronized在ConcurrentHashMap中的应用"></a>CAS和Synchronized在ConcurrentHashMap中的应用</h2><h3 id="CAS"><a href="#CAS" class="headerlink" title="CAS"></a><strong>CAS</strong></h3><p><code>CAS</code> 操作是一种无锁的同步机制。它包括三个操作数：<code>内存位置（要操作的数据）</code>、<code>预期原值</code>和<code>新值</code>。CAS首先检查<code>内存位置的当前值</code>是否与<code>预期原值</code>相同，如果相同，就将此位置更新为<code>新值</code>。整个过程是<code>原子的</code>。</p><ol><li>用于插入操作：<ul><li>当插入一个新的键值对时，ConcurrentHashMap 使用CAS操作来确保线程安全。</li><li>它首先计算键的哈希值，然后使用这个哈希值来找到对应的桶。</li><li>使用CAS操作来插入新的节点到桶中，如果CAS操作失败（说明有其他线程已经修改了这个桶），它会重试操作，直到成功。</li></ul></li><li>用于删除操作：<ul><li>当删除一个键值对时，ConcurrentHashMap 同样使用CAS操作。</li><li>它找到要删除的节点，然后使用CAS操作来安全地从桶中删除节点。</li></ul></li><li>用于扩容：<ul><li>当ConcurrentHashMap的大小超过一定的阈值，它会进行扩容。</li><li>扩容操作也使用CAS来确保只有一个线程可以扩容数组，并且在扩容过程中，其他线程还可以继续安全地访问和修改 ConcurrentHashMap。</li></ul></li></ol><h3 id="Synchronized"><a href="#Synchronized" class="headerlink" title="Synchronized"></a><strong>Synchronized</strong></h3><ol><li>复杂结构的修改：<ul><li>当链表长度超过阈值，将链表转换为红黑树时，需要锁定整个链表。这种转换是复杂的结构修改，涉及多个节点，因此使用 synchronized 来确保在修改期间，没有其他线程可以修改这些节点。</li></ul></li><li>删除操作：<ul><li>在删除过程中，synchronized 被用来锁定特定节点或整个桶，保证操作的原子性和一致性。</li></ul></li></ol><h2 id="为什么使用CAS"><a href="#为什么使用CAS" class="headerlink" title="为什么使用CAS"></a>为什么使用CAS</h2><ol><li>无锁优势：<ul><li>CAS 提供了一种<code>无锁</code>的同步方式。相比传统的锁机制，CAS在多线程环境下可以减少堵塞和上下文切换的开销，减少线程之间的竞争，提高系统整体性能。</li></ul></li><li>原子性：<ul><li>CAS 保证了原子性，无需使用复杂的锁定机制。</li></ul></li><li>避免死锁：<ul><li>CAS 可以避免死锁的发生，因为不会像传统锁那样持有资源。</li></ul></li></ol><p><strong>替代方案的局限性</strong></p><ul><li><strong>悲观锁</strong>：使用传统的悲观锁（synchronized 或 ReentrantLock）可能会导致在高并发环境下性能下降。</li><li><strong>自旋锁</strong>：自旋锁可以作为一种替代方案，但它在等待锁释放时会占用处理器时间，这在长时间等待的情况下可能不高效。</li></ul><h2 id="Java-8-ConcurrentHashMap-引入了什么新的技术？"><a href="#Java-8-ConcurrentHashMap-引入了什么新的技术？" class="headerlink" title="Java 8 ConcurrentHashMap 引入了什么新的技术？"></a>Java 8 ConcurrentHashMap 引入了什么新的技术？</h2><ol><li>统一的 Node 数组：<ul><li>使用单个统一的 Node 数组替代了分段的 Segment 数组。每个 Node 包含了一个键值对。</li></ul></li><li>CAS 操作：<ul><li>CAS用于在无锁的情况下实现安全的更新。在更新节点时不需要锁定整个结构。</li></ul></li><li>synchronized 同步块：<ul><li>对于需要同步的操作（如节点的删除或整个桶的更新），使用了内部的 synchronized 同步块来控制。</li></ul></li><li>引入链表和红黑树：<ul><li>在链表长度超过一定阈值时，链表转换为红黑树，这提高了查找效率。</li></ul></li></ol><h2 id="为什么要移除掉JDK7中的分段锁Segment？"><a href="#为什么要移除掉JDK7中的分段锁Segment？" class="headerlink" title="为什么要移除掉JDK7中的分段锁Segment？"></a>为什么要移除掉JDK7中的分段锁Segment？</h2><ol><li>提高并发性和性能：<ul><li>分段锁虽然允许多个线程同时访问不同的Segment，但如果多个线程修改同一个Segment，它们仍然会堵塞。堵塞意味着线程会被挂起，操作系统需要进行上下文切换，阻塞和上下文切换可能导致 CPU 资源的不充分利用，因为等待锁的线程不能执行任何操作。</li><li>在 Java 8中，通过锁定特定的桶而不是整个Segment，引入CAS和 Synchronized 减少锁的竞争，可以进一步提高并发读。CAS 自旋是在用户态完成的，不涉及操作系统层面的线程挂起或上下文切换。</li></ul></li><li>减少内存开销：<ul><li>每个Segment对象都是一个额外的内存开销，不需要再为每个 Segment 维护独立的哈希表和锁结构，降低了内存占用。</li></ul></li><li>优化扩容过程：<ul><li>新的扩容机制允许多个线程协作进行，减少了扩容期间的堵塞和性能损失。</li></ul></li></ol><h2 id="ConcurrentHashMap-一定是线程安全的吗？"><a href="#ConcurrentHashMap-一定是线程安全的吗？" class="headerlink" title="ConcurrentHashMap 一定是线程安全的吗？"></a>ConcurrentHashMap 一定是线程安全的吗？</h2><p>高并发场景下，当涉及到符合操作的情况下，ConcurrentHashMap 还是会出现数据不一致的情况。</p><p>ConcurrentHashMap 本身确保了单个操作，如<code>get</code>、<code>put</code>、<code>remove</code> 等的线程安全性，这意味着每个这样的操作都是原子的。然而，当这些操作组合在一起形成复合逻辑时，例如：</p><ol><li><p>检查后执行（Check-then-act）：如先通过</p><pre><code>get</code></pre><p>检查键是否存在，然后根据检查结果决定是否执行</p><pre><code>put</code></pre><p>。在多线程环境中，即使这两个操作各是安全的，组合在一起就可能不再是线程安全的。</p><ul><li><strong>问题示例</strong>：如果两个线程同时发现某个键不存在，它们可能各自创建一个新的值，并尝试将其插入到<code>ConcurrentHashMap</code> 中。这可能会导致后一个线程的操作覆盖前一个线程的操作。</li></ul></li></ol><p><strong>避免措施</strong></p><ol><li>使用原子操作：<code>ConcurrentHashMap</code> 提供了一些复合操作，如<code>putIfAbsent</code>、<code>compute</code> 、<code>computeIfAbsent</code> 和<code>computeIfPresent</code> ，这些方法可以安全地执行复合逻辑，确保整个过程的原子性。</li></ol><h3 id="computeIfAbsent"><a href="#computeIfAbsent" class="headerlink" title="computeIfAbsent"></a>computeIfAbsent</h3><ul><li>这个方法用于在<code>键不存在</code>时计算其值，并将其添加到 HashMap 中。</li><li>方法签名：computeIfAbsent(K key, Function mappingFunction)</li><li>工作原理：如果给定的键在 HashMap 中不存在或其值为 null，computeIfAbsent 会使用提供的映射函数计算其值，并将键值对添加到 HashMap 中。如果键已经存在，则不执行任何操作。</li><li>应用场景：常用于缓存实现，或者你希望键不存在时自动计算并存储值时。</li></ul><pre class="line-numbers language-language-java"><code class="language-language-java">Map<String, Integer> map = new HashMap<>();map.put("apple", 3);// 使用 computeIfAbsent 更新不存在的键 "banana" 的值map.computeIfAbsent("banana", k -> 6);System.out.println(map); // 输出: &#123;apple=3, banana=6&#125;// 使用 computeIfAbsent 尝试更新存在的键 "apple" 的值map.computeIfAbsent("apple", k -> 10);System.out.println(map); // 输出: &#123;apple=3, banana=6&#125;，"apple" 的值没有改变<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><h3 id="computeIfPresent"><a href="#computeIfPresent" class="headerlink" title="computeIfPresent"></a>computeIfPresent</h3><ul><li>这个方法用于在<code>键存在</code>且值非null时，重新计算并更新其值。</li><li>方法签名：computeIfPresent(K key, BiFunction remappingFunction)</li><li>工作原理：如果给定的键在 HashMap 中存在且其值非 null，computeIfPresent 会使用提供的重新映射函数根据旧值计算新值，并替换旧值。如果计算出的新值为 null，则删除该建。</li><li>应用场景：常用于需要基于旧值更新键值对的场合。</li></ul><pre class="line-numbers language-language-java"><code class="language-language-java">Map<String, Integer> map = new HashMap<>();map.put("apple", 3);// 使用 computeIfPresent 更新存在的键 "apple" 的值map.computeIfPresent("apple", (k, v) -> v + 2);System.out.println(map); // 输出: &#123;apple=5&#125;// 使用 computeIfPresent 尝试更新不存在的键 "banana" 的值map.computeIfPresent("banana", (k, v) -> v + 2);System.out.println(map); // 输出: &#123;apple=5&#125;，没有 "banana" 键<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre>]]></content>
      
      
      <categories>
          
          <category> 并发集合 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> ConcurrentHash </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>RabbitMQ 整理</title>
      <link href="/2025/02/26/rabbitmq/"/>
      <url>/2025/02/26/rabbitmq/</url>
      
        <content type="html"><![CDATA[<h2 id="消息队列-RabbitMQ"><a href="#消息队列-RabbitMQ" class="headerlink" title="消息队列-RabbitMQ"></a>消息队列-RabbitMQ</h2><p>RabbitMQ 基于 AMQP 协议，Advanced Message Queuing Protocol（高级消息队列协议），是一个网络协议，是应用层协议的一个开放标准，为面向消息中间设计的。基于这个协议的客户端和消息中间件可以传递消息，并且不会因为客户端或中间件产品的不同所受限，也不会受到不同开发语言的限制。</p><h3 id="主要特性"><a href="#主要特性" class="headerlink" title="主要特性"></a>主要特性</h3><ol><li>灵活的路由能力<ul><li>RabbitMQ 提供了多种交换机类型（如 direct、fanout、topic、headers），这些交换器支持灵活的消息路由机制。</li><li>它允许精确控制消息应该被发送到哪个队列，支持复杂的路由方案。</li></ul></li><li>高可靠性和持久性<ul><li>RabbitMQ 支持消息和队列的持久化，确保在系统故障时消息不会丢失。</li><li>它支持镜像队列（mirrored queues）来提高可用性，这通过在多个节点上复制队列来实现。</li></ul></li><li>多种协议和语言支持<ul><li>RabbitMQ 支持多种消息协议，包括 AMQP、STOMP、MQTT 等。</li><li>它提供了广泛的客户端库支持，适用于各种编程语言，如 Java、Python、Ruby、.NET等。</li></ul></li><li>集群和负载均衡<ul><li>RabbitMQ 可以在多个服务器上形成集群，提高吞吐量和可靠性。</li><li>它支持负载均衡和故障转移，帮助保持应用的高可用性。</li></ul></li><li>管理和监控<ul><li>RabbitMQ 附带管理界面，允许用户轻松管理和监控他们的消息系统。</li><li>提供了丰富的监控和管理 API，方便集成到现有的监控系统。</li></ul></li><li>易于扩展和集成<ul><li>它的插件系统使得扩展 RabbitMQ 功能变得简单，可以添加新的功能或集成到其他系统中。</li><li>社区提供了许多插件，例如用于消息追踪、Shovel 插件用于在多个 RabbitMQ 实例之间迁移消息等。</li></ul></li><li>事务支持<ul><li>RabbitMQ 提供事务功能，允许将消息的发送、接受和确认操作组合为单个原子操作。</li><li>虽然事务会增加一定的开销，但它们对于确保消息处理的完整性非常有用。</li></ul></li><li>灵活的消息处理模式<ul><li>支持多种消息处理模式，包括简单的点对点通信、工作队列模式、发布&#x2F;订阅模式等。</li><li>通过不同的交换器和队列配置，可以灵活地实现各种消息处理需求。</li></ul></li></ol><h3 id="主要结构"><a href="#主要结构" class="headerlink" title="主要结构"></a>主要结构</h3><p><img src="http://www.hyxiaoblog.com/images/21/rabbitmq_model.png" alt="img"></p><ol><li>交换器（Exchanges）<ul><li>交换器是 RabbitMQ 消息路由的核心组件，它负责接收生产者发送的消息并根据路由规则将它们转发到一个或多个队列。</li><li>RabbitMQ 提供了几种类型的交换器：<code>direct</code>、<code>topic</code>、<code>fanout</code> 和 <code>headers</code>，每种类型的交换器都有其特定的路由逻辑。</li></ul></li><li>队列（Queues）<ul><li>队列是 RabbitMQ 中的基本存储结构，用于存储待消费的消息。</li><li>队列与交换器之间通过绑定关系（Binding）建立连接，决定了哪些消息应该被路由到特定的队列。</li></ul></li><li>绑定（Bindings）<ul><li>绑定是交换器和队列之间的关系，它基于路由键（routing key）和（对于某些交换器类型）绑定键（binding key）来路由消息。</li><li>绑定可以包含路由键匹配规则，尤其是在适用 topic 交换器时。</li></ul></li><li>生产者（Producers）<ul><li>生产者是发送消息到交换器的应用程序或服务。</li><li>生产者决定将消息发送到哪个交换器，并指定消息的路由键。</li></ul></li><li>消费者（Consumers）<ul><li>消费者从队列中提取消息并处理它们。</li><li>消费者可以监听一个或多个队列，以接收和处理存储在队列中的消息。</li></ul></li><li>消息（Messages）<ul><li>消息是 RabbitMQ 传递的数据单元，由生产者创建并发送到交换器。</li><li>每个消息都包含有效负载（payload，即实际数据）和标签（header），其中可能包括路由键、消息优先级、过期时间等信息。</li></ul></li><li>虚拟主机（Virtual Hosts）<ul><li>虚拟主机提供了一种隔离方式，可以在同一个 RabbitMQ 服务器上运行多个独立的消息系统。</li><li>每个虚拟主机都有自己的队列、交换器和绑定。</li></ul></li><li>用户和权限<ul><li>RabbitMQ 允许你定义多个用户，并且可以给每个用户分配不同的角色和权限。</li><li>这种权限控制可以用来限制对特定队列、交换器和其他资源的访问。</li></ul></li></ol><h3 id="工作流程"><a href="#工作流程" class="headerlink" title="工作流程"></a>工作流程</h3><ol><li><strong>生产者</strong>创建一条消息，这条消息包含有效负载（即实际要传递的数据）和一些元数据（如路由键）。</li><li>生产者将这条消息发送到一个<strong>交换器</strong>。生产者在发送消息时指定<strong>交换器</strong>和<strong>路由键</strong>。</li><li>交换器接收到消息后，根据<strong>交换类型</strong>（如 direct、fanout、topic）和消息的路由键来决定如何路由消息。</li><li>在<strong>binding key</strong>的帮助下，交换器将消息路由到一个或多个<strong>队列</strong>。绑定定义了交换器和队列之间的关系，并可能包含与路由键匹配的模式。</li><li>一旦消息被路由到某个队列，它将在那里等待，直到出现一个<strong>消费者</strong>准备好接收它。</li><li>如果消息配置了消息持久化，消息将在磁盘上存储，以防止在系统崩溃时丢失。</li><li>消费者从队列中接收消息，并进行处理。消费者可以是任何能够连接到队列并读取消息的应用程序或服务。</li><li>消费者可以手动或自动确认消息。确认（acknowledge）是否告诉 RabbitMQ 消息已经被接收并处理。</li><li>一旦消息被正确处理，消费者会发送一个确认给 RabbitMQ。</li><li>如果消费者因为某种原因无法处理消息，它可以拒绝（reject）或将消息重回队列（nack）。</li><li>当 RabbitMQ 收到确认后，它将从队列中移除该消息。</li><li>如果在处理消息时发生故障，系统可以配置为重试机制或将消息移动到死信队列（dead-letter queue）。</li></ol><p><img src="https://prod-files-secure.s3.us-west-2.amazonaws.com/4d514fab-2492-4877-a269-a017b8992bb6/e21bc9b8-8a43-4e48-b3f9-1dee429ddef2/Screenshot_2024-07-10-13-19-25-957_com.android.chrome-edit.jpg" alt="Screenshot_2024-07-10-13-19-25-957_com.android.chrome-edit.jpg"></p><h3 id="Exchanges-交换器"><a href="#Exchanges-交换器" class="headerlink" title="Exchanges 交换器"></a>Exchanges 交换器</h3><p>在RabbitMQ中，交换器（Exchanges）是决定如何路由消息的关键组件。它们接收来自生产者的消息，并根据特定规则将它们路由到一个或多个队列。</p><p>RabbitMQ 提供了四种主要的交换器类型，每种类型根据不同的规则路由消息。</p><ol><li><p><strong>Direct Exchange</strong></p><ul><li><strong>工作原理</strong>：根据消息的路由键（routing key）将消息路由到具有相同绑定值（binding key）的队列。</li><li><strong>用途</strong>：当你想要将消息发送到指定的队列时，可以使用 direct exchanges。它适用于一对一的消息路由场景。</li><li><strong>示例场景</strong>：订单服务向指定的处理队列发送订单更新消息。</li></ul><p>示例代码：</p><pre class="line-numbers language-language-java"><code class="language-language-java">// 创建 Direct Exchange@Beanpublic DirectExchange directExchange() &#123;    return new DirectExchange("direct_exchange");&#125;// 创建队列@Beanpublic Queue orderQueue() &#123;    return new Queue("order_queue");&#125;// 绑定队列到交换器@Beanpublic Binding bindingDirect(Queue orderQueue, DirectExchange directExchange) &#123;    return BindingBuilder.bind(orderQueue).to(directExchange).with("order_key");&#125;<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre></li><li><p><strong>Fanout Exchange</strong></p><ul><li><strong>工作原理</strong>：忽略路由键，将消息广播到所有绑定到该交换器的队列。</li><li><strong>用途</strong>：当你需要将相同的消息发送到多个队列时，fanout exchange 非常有用。它实现发布&#x2F;订阅模式。</li><li><strong>示例场景</strong>：广播系统通知或实时更新，如股票价格变动。</li></ul><p>示例代码：</p><pre class="line-numbers language-language-java"><code class="language-language-java">// 创建 Fanout Exchange@Beanpublic FanoutExchange fanoutExchange() &#123;    return new FanoutExchange("fanout_exchange");&#125;// 创建队列@Beanpublic Queue notificationQueue() &#123;    return new Queue("notification_queue");&#125;// 绑定队列到交换器@Beanpublic Binding bindingFanout(Queue notificationQueue, FanoutExchange fanoutExchange) &#123;    return BindingBuilder.bind(notificationQueue).to(fanoutExchange);&#125;<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre></li><li><p><strong>Topic Exchange</strong></p><ul><li><strong>工作原理</strong>：根据消息的路由键和队列的绑定键（可以包含通配符）进行模糊匹配，来决定消息路由到哪些队列。</li><li><strong>用途</strong>：当你需要根据特定模式或多个标准路由消息时，topic exchange 是最佳选择。它提供了很高的灵活性。</li><li><strong>示例场景</strong>：向不同的日志记录系统发送不同级别（如 error，info，debug）的日志消息。</li></ul><p>示例代码：</p><pre class="line-numbers language-language-java"><code class="language-language-java">// 创建 Topic Exchange@Beanpublic TopicExchange topicExchange() &#123;    return new TopicExchange("topic_exchange");&#125;// 创建队列@Beanpublic Queue logQueue() &#123;    return new Queue("log_queue");&#125;// 绑定队列到交换器@Beanpublic Binding bindingTopic(Queue logQueue, TopicExchange topicExchange) &#123;    return BindingBuilder.bind(logQueue).to(topicExchange).with("log.*");&#125;<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><pre class="line-numbers language-language-java"><code class="language-language-java">@Componentpublic class LogMessagePublisher &#123;    @Autowired    private RabbitTemplate rabbitTemplate;    @Autowired    private TopicExchange topicExchange;    public void sendInfoLog(String message) &#123;        rabbitTemplate.convertAndSend(topicExchange.getName(), "log.info", message);    &#125;    public void sendErrorLog(String message) &#123;        rabbitTemplate.convertAndSend(topicExchange.getName(), "log.error", message);    &#125;&#125;<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre></li><li><p><strong>Headers Exchange</strong></p><ul><li><strong>工作原理</strong>：基于消息头（headers）中的一个或多个属性进行匹配，而不是路由键。匹配规则可以是“全部匹配”（all）或“任意匹配”（any）。</li><li><strong>用途</strong>：当你需要基于多个属性进行复杂的路由规则时，可以使用 headers exchanges。</li><li><strong>示例场景</strong>：基于消息内容的多个属性（如源、目的地、优先级）路由消息到不同的处理队列。</li></ul><p>示例代码：</p><pre class="line-numbers language-language-java"><code class="language-language-java">// 创建 Headers Exchange@Beanpublic HeadersExchange headersExchange() &#123;    return new HeadersExchange("headers_exchange");&#125;// 创建队列@Beanpublic Queue processQueue() &#123;    return new Queue("process_queue");&#125;// 绑定队列到交换器@Beanpublic Binding bindingHeaders(Queue processQueue, HeadersExchange headersExchange) &#123;    Map<String, Object> map = new HashMap<>();    map.put("x-match", "all");    map.put("header1", "value1");    map.put("header2", "value2");    return BindingBuilder.bind(processQueue).to(headersExchange).whereAll(map).match();&#125;<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre></li></ol><h3 id="Queue-队列"><a href="#Queue-队列" class="headerlink" title="Queue 队列"></a>Queue 队列</h3><h3 id="持久化"><a href="#持久化" class="headerlink" title="持久化"></a><strong>持久化</strong></h3><ul><li><strong>持久化队列</strong>：在 RabbitMQ 中，队列可以被标记为持久化（durable）。持久化队列会在代理重启后自动重建，但这本身并不保证队列中的消息也是持久的。</li><li><strong>消息持久化</strong>：要确保消息不丢失，除了声明队列为持久化之外，发送到队列的每条消息也需要被标记为持久化。这意味着消息会被写入磁盘，尽管这可能会引入额外的性能开销。</li><li><strong>写入磁盘的时机</strong>：RabbitMQ 不会为每条消息写入磁盘，而是可能仅在必要时进行，这取决于消息代理的配置和当前的负载。这种机制提供了性能和持久性之间的平衡。</li></ul><p><strong>在代码中使用队列持久化</strong></p><p>声明一个持久化队列</p><pre class="line-numbers language-language-java"><code class="language-language-java">@Beanpublic Queue myDurableQueue() &#123;    return new Queue("myDurableQueue", true); // true 表示队列是持久化的&#125;<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span></span></code></pre><p>在这个示例中，<code>Queue</code> 的构造函数接受一个布尔值作为第二个参数，用来指定队列是否持久化。<code>true</code> 表示队列是持久化的。</p><p>对于消息的持久化，可以在发送消息时设置它的持久性。使用 <code>MessageProperties</code> 设置消息为持久化：</p><pre class="line-numbers language-language-java"><code class="language-language-java">MessageProperties messageProperties = new MessageProperties();messageProperties.setDeliveryMode(MessageDeliveryMode.PERSISTENT);Message message = new Message("Your message content".getBytes(), messageProperties);rabbitTemplate.send("myDurableQueue", message);<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span></span></code></pre><p>在这个示例中，<code>MessageDeliveryMode.PERSISTENT</code> 指定了消息应该被持久化。</p><h3 id="事务支持"><a href="#事务支持" class="headerlink" title="事务支持"></a><strong>事务支持</strong></h3><ul><li>RabbitMQ 中的事务允许你将一系列动作（如发送消息、确认消息）包装在一个事务中。事务保证了这些操作要么全部成功，要么全部失败，从而提供了一定程度的消息处理保证。</li><li>操作步骤：<ul><li>开启事务：通过 <code>channel.txSelect()</code> 开启事务。</li><li>执行操作：在事务中发送消息或执行其他操作。</li><li>提交或回滚：使用 <code>channel.txCommit()</code> 提交事务或使用 <code>channel.txRollback()</code> 回滚事务。</li></ul></li></ul><p>示例代码：</p><pre class="line-numbers language-language-java"><code class="language-language-java">Channel channel = connection.createChannel();try &#123;    channel.txSelect();    channel.basicPublish("", "queue_name", null, message.getBytes());    // 可能的其他操作...    channel.txCommit();&#125; catch (Exception e) &#123;    channel.txRollback();&#125;<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><p>但是这种事务机制在 RabbitMQ 中会显得影响消息吞吐量。由于每个事务都涉及到磁盘 I&#x2F;O 操作来确保状态的持久化，这会导致性能瓶颈。对于需要高吞吐量的系统，事务可能不是一个理想的选择。</p><p><strong>替代方案</strong></p><p><img src="http://www.hyxiaoblog.com/images/21/message_reliable.png" alt="img"></p><ul><li><p><strong>confirm 确认模式</strong></p><ul><li>消息一旦从生产者发送给 MQ Server，也就是被交换器接收到，这个时候会有一个回调 confirmCallback，代表 MQ Server 接收到了。不管消息是否消费成功，这个回调函数一定会被执行。</li></ul><p><strong>示例代码</strong>：在代码设置 confirm 确认模式</p><pre class="line-numbers language-language-java"><code class="language-language-java">/*** correlationData: 相关性数据* ack: 交换机是否成功接收到消息，true：成功* cause: 失败的原因（成功则为null）*/rabbitTemplate.setConfirmCallback((correlationData, ack, cause) -> &#123;    if (ack) &#123;        log.info("交换机接收消息成功~~ &#123;&#125;", cause);        // 确认成功逻辑    &#125; else &#123;        log.info("交换机接收消息失败~~ &#123;&#125;", cause);        // 确认失败逻辑    &#125;&#125;);<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre></li><li><p><strong>return 回退模式</strong></p><ul><li>如果交换器无法根据自身的类型和路由键或绑定规则将消息路由到一个队列，它会调用生产者的回退回调函数（<code>returnCallback</code>）。这通常意味着消息无法送达任何队列。</li></ul><p><strong>示例代码</strong>：在代码设置 return 回退模式</p><pre class="line-numbers language-language-java"><code class="language-language-java">rabbitTemplate.setReturnsCallback(returnedMessage -> &#123;    log.info("return");    log.info("returnedMessage:&#123;&#125;", returnedMessage);&#125;);<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span></span></code></pre></li></ul><p><strong>结合使用</strong></p><p>通常情况下，<code>confirmCallback</code> 和 <code>returnCallback</code> 被一起使用，以确保消息不仅被交换器接收，而且能被正确路由到队列。</p><pre class="line-numbers language-language-java"><code class="language-language-java">rabbitTemplate.setConfirmCallback((correlationData, ack, cause) -> &#123;    if (ack) &#123;        // 确认成功逻辑    &#125; else &#123;        // 确认失败逻辑，例如记录日志、重试等    &#125;&#125;);rabbitTemplate.setReturnCallback((message, replyCode, replyText, exchange, routingKey) -> &#123;    // 处理无法路由的消息，例如记录日志、通知生产者等&#125;);rabbitTemplate.setMandatory(true); // 设置为 true，以确保触发 returnCallback<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><p>设置了 <code>setMandatory(true)</code> 之后，如果消息无法被正确路由到队列，<code>returnCallback</code> 会被触发。如果没有设置 <code>mandatory</code> 参数，无法路由的消息会被 RabbitMQ 丢弃，生产者不会收到通知。</p><h3 id="死信队列"><a href="#死信队列" class="headerlink" title="死信队列"></a><strong>死信队列</strong></h3><p>死信队列（Dead Letter Queue, DLQ）是用来收集死信的队列。在消息队列服务中，死信通常是指<strong>那些无法被正常消费的消息</strong>。有几种情况会导致消息称为死信：</p><ol><li><strong>消息被拒绝（Rejected）</strong>：消费者收到消息后，可以选择拒绝它，这是可以设置是否重新入队。如果消费者拒绝消息且不重新入队，该消息就会成为死信。</li><li><strong>消息过期</strong>：如果消息在队列中存在时间超过了设置的TTL（Time-To-Live），它就会变成信息。</li><li><strong>队列达到最大长度</strong>：如果队列满了，新消息就会变成死信。</li></ol><p>在 RabbitMQ 中，你可以通过配置队列的参数来指定死信交换器（DLX）和死信路由键（DLK）。当消息成为死信后，它会被发送到 DLX 指定的交换器，并根据 DLK 进行路由。</p><p><strong>示例代码</strong>：配置死信队列</p><pre class="line-numbers language-language-java"><code class="language-language-java">Map<String, Object> args = new HashMap<>();args.put("x-dead-letter-exchange", "dlx_exchange");args.put("x-dead-letter-routing-key", "dlx_routing_key");@Beanpublic Queue myQueue() &#123;return new Queue("myQueue", true, false, false, args);&#125;@Beanpublic DirectExchange deadLetterExchange() &#123;return new DirectExchange("dlx_exchange");&#125;@Beanpublic Queue dlQueue() &#123;return new Queue("deadLetterQueue");&#125;@Beanpublic Binding dlBinding() &#123;return BindingBuilder.bind(dlQueue()).to(deadLetterExchange()).with("dlx_routing_key");&#125;<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><p>在这个配置中，如果 <code>myQueue</code> 中的消息变成了死信，它会被路由到 <code>deadLetterQueue</code> 队列。</p><h3 id="延迟队列"><a href="#延迟队列" class="headerlink" title="延迟队列"></a><strong>延迟队列</strong></h3><p>延迟队列（Delayed Queue）是一种特殊类型的队列，消息被发送到这个队列之后不会立即被消费，而是会在延迟一定时间后才能被消费。</p><p>需要注意的是，RabbitMQ 本身默认不支持延迟队列，但是可以通过<strong>安装插件</strong>或者<strong>使用消息TTL和死信队列的组合</strong>来实现相似的功能。</p><ol><li><strong>安装插件</strong></li></ol><ul><li><p>先通过命令行 <code>rabbitmqctl veriosn</code> 得到mq的版本号，根据版本号去下载插件</p></li><li><p>下载延迟插件 <a href="https://github.com/rabbitmq/rabbitmq-delayed-message-exchange/releases">https://github.com/rabbitmq/rabbitmq-delayed-message-exchange/releases</a></p></li><li><p>下载好了之后，传到 Linux 服务器</p></li><li><p>然后再从虚拟机拷贝到 docker 的 rabbitmq 插件中：<code>docker cp rabbitmq_delayed_message_exchange-3.9.0.ez rabbitmq:/plugins</code></p></li><li><p>运行命令开启延迟插件，<code>rabbitmq-plugins enable rabbitmq_delayed_message_exchange</code></p></li><li><p>查看插件列表是否存在延迟插件，<code>rabbitmq-plugins list</code></p></li><li><p><code>ctrl+d</code>退出控制台并且重启rabbitmq，<code>docker restart rabbitmq</code></p><p>示例代码：</p><pre class="line-numbers language-language-java"><code class="language-language-java">@Configurationpublic class DelayConfig_Article &#123;    // 定义交换机的名称    public static final String EXCHANGE_DELAY_ARTICLE = "exchange_delay_article";    // 定义队列的名称    public static final String QUEUE_DELAY_ARTICLE = "queue_delay_article";    // 统一定义路由key    public static final String DELAY_DISPLAY_ARTICLE = "delay.display.article";    // 创建交换机    @Bean(EXCHANGE_DELAY_ARTICLE)    public Exchange exchange() &#123;        return ExchangeBuilder                    .topicExchange(EXCHANGE_DELAY_ARTICLE)                    .durable(true)                    .delayed()              // 设置延迟特性                    .build();    &#125;    // 创建队列    @Bean(QUEUE_DELAY_ARTICLE)    public Queue queue() &#123;        return QueueBuilder                .durable(QUEUE_DELAY_ARTICLE)                .build();    &#125;    // 创建绑定关系    @Bean    public Binding delayBindingArticle(@Qualifier(EXCHANGE_DELAY_ARTICLE) Exchange exchange,                                        @Qualifier(QUEUE_DELAY_ARTICLE) Queue queue) &#123;        return BindingBuilder                .bind(queue)                .to(exchange)                .with("delay.display.*")                .noargs();    &#125;    /**     * 设置消息属性处理器，目的是设置延迟的时间     * @param times     * @return     */    public static MessagePostProcessor setDelayTimes(Integer times) &#123;        return message -> &#123;            message.getMessageProperties().setDeliveryMode(MessageDeliveryMode.PERSISTENT);            message.getMessageProperties().setDelay(times);            return message;        &#125;;    &#125;&#125;<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><pre class="line-numbers language-language-java"><code class="language-language-java">...Integer delayTimes = 10 * 1000;MessagePostProcessor processor = DelayConfig_Article.setDelayTimes(delayTimes);rabbitTemplate.convertAndSend(DelayConfig_Article.EXCHANGE_DELAY_ARTICLE,                                DelayConfig_Article.DELAY_DISPLAY_ARTICLE,                                message,                                processor);...<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre></li></ul><p>这个插件扩展了 RabbitMQ 的功能，允许创建一个自定义的交换器类型 <code>x-delayed-message</code>，这种类型的交换器可以接收带有延迟信息的消息，并在指定的延迟时间后将消息路由到绑定的队列。</p><ul><li>使用 <code>.delayed()</code>方法标记交换器以支持延迟消息。</li><li>在发送消息时，通过<code>MessagePostProcessor</code>设置消息的延迟时间，这是通过设置消息属性中的 <code>x-delay</code>来实现的。</li><li>当消息发送到这个交换器时，它不会立即被路由到一个队列，而是会在经过指定的延迟时间之后被路由。</li></ul><ol><li><p><strong>使用TTL和DLX实现延迟队列：</strong></p><pre class="line-numbers language-language-java"><code class="language-language-java">@Beanpublic Queue delayProcessQueue() &#123;    Map<String, Object> args = new HashMap<>();    args.put("x-dead-letter-exchange", "dlx_exchange");    args.put("x-dead-letter-routing-key", "process_routing_key");    args.put("x-message-ttl", 60000);    // 消息TTL为60000ms(1分钟)    return new Queue("delayQueue", true, false, false, args);&#125;@Beanpublic DirectExchange processExchange() &#123;    return new DirectExchange("processExchange");&#125;@Beanpublic Queue processQueue() &#123;    return new Queue("processQueue");&#125;#Beanpublic Binding processBinding() &#123;    return BindingBuilder.bind(processQueue()).to(processExchange()).with("process_routing_key");&#125;@Beanpublic Binding delayBinding() &#123;    return BindingBuilder.bind(delayProcessQueue()).to(processExchange()).with("delay_routing_key");&#125;<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre></li></ol><p>在这个示例中，<code>delayQueue</code> 是一个带有 TTL 和 DLX 配置的队列。消息会在这个队列中延迟一定时间（这里是1分钟），然后通过 DLX 被发送到 <code>processQueue</code> 队列进行处理。</p><p>使用 TTL 和 DLX 实现的延迟队列的<strong>工作流程</strong>大致如下：</p><ol><li><p>生产者（<code>producer</code>）将消息发送到一个普通的交换器（<code>processExchange</code>）。</p></li><li><p>该交换器将消息路由到配置有 TTL 和 DLX 的队列（<code>delayQueue</code>）。</p></li><li><p>消息在<code>delayQueue</code>中停留，直到其 TTL 过期。如果消息在 TTL 时间内没有被消费，它就会变成死信。</p></li><li><p>一旦消息成为死信，它会被发送到配置在<code>delayQueue</code>上的DLX（<code>dlx_exchange</code>）。</p></li><li><p>DLX 交换器（<code>dlx_exchange</code>）将这个死信路由到最终的处理队列（<code>processQueue</code>）。</p></li><li><p>消费者（<code>comsumer</code>）监听<code>processQueue</code>，准备处理消息。</p><pre class="line-numbers language-language-rust"><code class="language-language-rust">producer -> processExchange -> delayQueue --(after TTL)--> DLX(dlx_exchange) -> processQueue -> consumer<span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre></li></ol><p>这里的<code>DLX</code>是<code>delayQueue</code>配置的死信交换器，它负责接收<code>delayQueue</code>中过期的消息，并将它们路由到<code>processQueue</code>。需要确保<code>delayQueue</code>的DLX指向了正确的交换器，这个交换器会将消息路由到<code>processQueue</code>。</p><h3 id="重回队列"><a href="#重回队列" class="headerlink" title="重回队列"></a><strong>重回队列</strong></h3><p>在 RabbitMQ 中，“重回队列”（Requeue）是一个过程，当消费者因为某些原因不能处理接收到的消息时，它可以选择将消息发送回队列中以便稍后重新消费。</p><p><strong>重回队列适合场景</strong></p><ol><li><p>手动拒绝消息：</p><ul><li><p>当消费者接收到消息但不想或不能立即处理时，它可以使用 <code>basicReject</code> 或 <code>basicNack</code> 方法拒绝消息，并将 <code>requeue</code> 标志设置为 <code>true</code>，这会将消息重新放回队列。</p><pre class="line-numbers language-language-java"><code class="language-language-java">channel.basicNack(message.getMessageProperties().getDeliveryTag(), true, true);<span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre></li></ul></li><li><p>消费者断开连接：</p><ul><li>如果消费者在处理消息时断开连接（比如由于崩溃或网络问题），没有发送 ack（消息确认），那么 RabbitMQ 会将消息重新入队。</li></ul></li></ol><p><strong>与死信队列和延迟队列的关系</strong></p><pre><code>**死信队列**：</code></pre><ul><li><p>如果消息被消费者多次拒绝且不重回队列（<code>requeue</code>标志设置为<code>false</code>），或者消息超过了最大重试次数（如果设置了），那么这条消息可以被发送到死信队列。</p></li><li><p>死信队列用来收集那些无法被成功消费的消息，以便后续可以对这些消息进行监控和处理。</p><p><strong>延迟队列</strong>：</p></li><li><p>与重回队列不同，延迟队列通常是用来延迟消息的投递。当你希望消息在一段时间后被处理，而不是立即被消费时，可以使用延迟队列。</p></li><li><p>如果一个消息在延迟队列中到期后不能被成功消费，并且不再被重回队列，它同样可以变成死信并被发送到死信队列。</p></li></ul><p><strong>注意事项</strong></p><ul><li>无限重试的风险：<ul><li>如果消息被不断地重回队列而不进行任何修改，这可能导致“死循环”，其中消费者不断尝试处理同一条消息。</li><li>为了避免这种情况，通常需要实现一些逻辑来跟踪消息的重试次数，并在超过某个阈值后将其发送到死信队列或其他的处理队列。</li></ul></li><li>消息顺序：<ul><li>如果队列中的消息顺序很重要，那么重回队列可能会打乱原有的顺序，因为重新排队的消息将会放置在队列的末尾。</li></ul></li></ul><h3 id="手动确认和自动确认"><a href="#手动确认和自动确认" class="headerlink" title="手动确认和自动确认"></a>手动确认和自动确认</h3><p>在 RabbitMQ 中，消息确认（ACK）是保证消息被正确处理的一种机制。生产者将消息发送到队列中，消费者从队列中获取消息并进行处理。一旦消息被成功处理，消费者应该向 RabbitMQ 发送一个确认信号，即 ACK。这个确认过程可以是自动的或手动的，具体取决于消费者的配置。</p><p><strong>手动确认（Manual-acknowledge）</strong></p><ul><li><p>在手动确认模式下，消费者必须明确地告诉 RabbitMQ 它已经完成了消息的处理，并且消息可以被安全地删除。</p></li><li><p>如果消费者在处理消息之前发生故障，消息不会丢失，因为它还没有被确认。</p></li><li><p>手动确认给了消费者更多的控制，但也增加了复杂性，因为需要在代码中明确地处理ACK。</p></li><li><p>使用手动确认可以避免消息的意外丢失，适用于需要保证<strong>消息处理可靠性</strong>的场景。</p><p>示例代码：</p><pre class="line-numbers language-language-java"><code class="language-language-java">// 消费者接收消息的方法public void onMessage(Message message, Channel channel) throws IOException &#123;    try &#123;        // 处理消息的逻辑...        // 手动发送ACK        channel.basicAck(message.getMessageProperties().getDeliveryTag(), false);    &#125; catch (Exception e) &#123;        // 如果处理消息时发生异常，拒绝消息，并根据情况决定是否重新入队        channel.basicNack(message.getMessageProperties().getDeliveryTag(), false, true);    &#125;&#125;<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><p>在这个示例中，如果消息成功处理，消费者会调用 <code>basicAck</code> 方法来确认消息。如果处理失败，它会调用 <code>basicNack</code> 方法来拒绝消息，并可能选择将其重新入队。</p></li></ul><p><strong>自动确认（Auto-acknowledge）</strong></p><ul><li>在自动确认模式下，一旦消息被投递给消费者，RabbitMQ 就会立即将其标记为已确认。</li><li>这种模式下简化了处理流程，因为消费者不需要显示地发送 ACK 信号。</li><li>但是，如果消费者在处理消息后发生故障（例如，应用崩溃或断电），那么消息可能会丢失，因为 RabbitMQ 认为它已经被处理了。</li><li>自动确认适用于那些对消息丢失不敏感或可以容忍丢失的场景。</li></ul><h2 id="常见问题"><a href="#常见问题" class="headerlink" title="常见问题"></a>常见问题</h2><h3 id="RabbitMQ-如何保证消息的可靠性"><a href="#RabbitMQ-如何保证消息的可靠性" class="headerlink" title="RabbitMQ 如何保证消息的可靠性"></a>RabbitMQ 如何保证消息的可靠性</h3><p><strong>可靠性</strong>主要关注消息在传输过程中不丢失，确保消息从生产者到MQ Server 再到消费者的过程中被正确处理。</p><p>RabbitMQ 提供了多种机制来确保消息的可靠性和安全性，以下是几个主要的方法：</p><ol><li>消息持久化<ul><li>将消息标记为持久化，并且确保队列也是持久的，这样即使在 RabbitMQ 重启后，消息也不会丢失。</li></ul></li><li>事务<ul><li>虽然事务会降低性能，但它们可以确保一系列操作（如消息发布）要么全部成功，要么全部不执行。</li></ul></li><li>confirm 确认模式和 return 回退模式<ul><li>前者是一个轻量级的、异步的机制，允许生产者知道其消息是否已成功到达交换器。</li><li>后者是当消息无法路由到任何一个队列时，它会调用生产者的回退回调函数。</li></ul></li><li>消费者确认（Consumer Acknowledgements）<ul><li>通过手动确认模式，消费者可以控制什么时候确认消息。这确保了只有在消息被正确处理后，它才会从队列中移除。</li></ul></li><li>死信队列<ul><li>设置死信队列可以处理无法正常消费的消息，例如因为消息被拒绝、过期或队列达到最大长度。</li></ul></li></ol><h3 id="RabbitMQ-如何做到削峰限流"><a href="#RabbitMQ-如何做到削峰限流" class="headerlink" title="RabbitMQ 如何做到削峰限流"></a>RabbitMQ 如何做到削峰限流</h3><ol><li><p><strong>预取计数（Prefetch Count）</strong></p><p>通过设置预取计数，可以限制 RabbitMQ 向每个消费者发送的未确认消息的数量。一旦达到这个数量，RabbitMQ 将停止向该消费者发送更多消息，直到它开始确认消息。</p><pre class="line-numbers language-language-java"><code class="language-language-java">channel.basicQos(prefetchCount);<span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre><p>在这里，<code>prefetchCount</code> 是你想要设置的预取数量。这个设置可以帮助避免给单个消费者分配过多消息，从而平衡负载并限制处理速率。</p></li><li><p><strong>消息延迟</strong></p><p>可以将消息发送到延迟队列&#x2F;死信队列，并设定消息的延迟时间。这样，消息会在指定的延迟之后才被投递到实际的工作队列。</p></li><li><p><strong>手动消息确认</strong></p><p>通过手动确认消息，可以更细粒度地控制消息的处理速度。消费者在完成消息处理后手动发送确认，这样可以根据处理能力来调整接收消息的速度。</p></li></ol><h3 id="RabbitMQ-如何保证最终一致性"><a href="#RabbitMQ-如何保证最终一致性" class="headerlink" title="RabbitMQ 如何保证最终一致性"></a>RabbitMQ 如何保证最终一致性</h3><p>使用数据库（DB）来辅助 RabbitMQ 实现消息的最终一致性是一个常见的模式，尤其是在分布式系统和微服务架构中。这种方法通常涉及到在消息处理和数据库操作之间保持一致性。以下是如何借助数据库实现 RabbitMQ 消息的最终一致性的步骤：</p><p>&#x2F;&#x2F;TODO 消息的延迟投递，做二次确认，回调检查</p><ol><li>事务日志记录<ul><li>在发送消息前，首先在数据库中记录事务日志。这个日志记录了即将发送的消息及其状态。这样做的目的是在发送消息之前确保有一个持久的记录存在。</li></ul></li><li>发送消息<ul><li>发送消息到 RabbitMQ，此时消息可能仅被标记为“待发送”或类似状态。</li></ul></li><li>发布者确认<ul><li>利用 RabbitMQ 的发布者确认机制来确保消息已被交换器接收。一旦收到确认，更新数据库中的事务日志，表明消息已成功发送。</li></ul></li><li>消费者处理<ul><li>消费者从 RabbitMQ 接收消息并进行处理。处理过程可能涉及到更改数据库的数据。</li></ul></li><li>处理确认<ul><li>处理完成后，消费者手动确认消息。这个确认告诉 RabbitMQ 消息已被成功处理，可以将数据的日志记录删除或者更改消息状态为完成。</li></ul></li><li>处理失败和重试<ul><li>如果消费者处理失败，可以利用 RabbitMQ 的重试机制或将消息放入死信队列。同时，可以在数据库中记录失败事件，以便进行后续的错误处理或人工干预。</li></ul></li><li>幂等性处理<ul><li>在消费者端实现幂等性，确保即使同一消息被重复消费，也不会对系统状态产生不良影响。</li></ul></li><li>同步或补偿机制<ul><li>在某些情况下，如果处理过程中发生了故障或不一致性，可能需要在数据库中执行补偿操作来恢复一致性。</li></ul></li><li>监控和告警<ul><li>通过对 RabbitMQ 队列和数据库的监控，可以及时发现问题并进行干预，比如处理积压的消息或解决数据不一致的问题。</li></ul></li></ol><h3 id="RabbitMQ-如何避免消息被重复消费"><a href="#RabbitMQ-如何避免消息被重复消费" class="headerlink" title="RabbitMQ 如何避免消息被重复消费"></a>RabbitMQ 如何避免消息被重复消费</h3><ol><li>使用唯一标识符<ul><li>为每条消息分配一个唯一标识符（如 UUID 或 消息 ID）。在消息者处理消息之前，先检查数据库或缓存中是否存在该标识符。如果存在，表明该消息已被处理，可以跳过；如果不存在，进行处理并记录该标识符。</li></ul></li><li>消息指纹<ul><li>为消息内容生成一个指纹（如哈希值），并检查这个指纹是否已被处理。这种方法适用于消息内容不变的情况。</li></ul></li><li>利用Redis的原子性<ul><li>需要考虑两个问题<ul><li>问题1：是否要进行数据落库，如果落库的话，关键解决的问题是数据库和缓存如何做到原子性？（假如redis保存数据成功，数据库保存失败的情况）</li><li>问题2：如果不进行落库，那么都存储到缓存中，如何设置定时同步的策略？（并且有可能会出现redis保存数据失败的情况）</li></ul></li></ul></li></ol>]]></content>
      
      
      <categories>
          
          <category> 消息队列 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> RabbitMQ </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>Kakfa 整理</title>
      <link href="/2025/02/26/kafka-bi-ji/"/>
      <url>/2025/02/26/kafka-bi-ji/</url>
      
        <content type="html"><![CDATA[<p>📌 引言</p><p>在使用 Kafka 进行消息消费时，Offset 机制是一个核心概念。Offset 决定了消费者从哪里读取数据，并影响消费的可靠性与一致性。本篇文章将深入剖析 Kafka Offset 的工作原理，以及 <code>auto.offset.reset</code> 在不同场景下的行为。</p><h2 id="Kafka-Offset-机制概述"><a href="#Kafka-Offset-机制概述" class="headerlink" title="Kafka Offset 机制概述"></a>Kafka Offset 机制概述</h2><p>Kafka 采用 Offset（偏移量）来跟踪消费者的消费进度。Offset 是消息在 Kafka 分区中的唯一编号，类似数据库中的自增 ID。</p><ul><li><strong>Start Offset</strong>（日志起始 Offset）：该分区最早可用的消息 Offset（受 Kafka 日志保留策略影响）。</li><li><strong>End Offset</strong>（日志结束 Offset）：该分区最新消息的 Offset。</li><li><strong>Committed Offset</strong>（已提交 Offset）：消费者组提交的最新 Offset，表示该消费者已成功消费的数据。</li><li><strong>Current Offset</strong>（当前 Offset）：消费者<strong>正在消费</strong>的消息 Offset。</li></ul><p>Kafka 允许消费者手动或自动提交 Offset，并提供 <code>auto.offset.reset</code> 选项来决定在找不到 Offset 时的行为。</p><hr><h3 id="auto-offset-reset-详解"><a href="#auto-offset-reset-详解" class="headerlink" title="auto.offset.reset 详解"></a>auto.offset.reset 详解</h3><h4 id="🔹-什么是-auto-offset-reset"><a href="#🔹-什么是-auto-offset-reset" class="headerlink" title="🔹 什么是 auto.offset.reset"></a>🔹 什么是 auto.offset.reset</h4><p><code>auto.offset.reset</code> 决定了消费者在 Kafka <strong>找不到已提交的 Offset</strong> 时应该如何处理。</p><ul><li><code>earliest</code>：从 <strong>Start Offset</strong>（最早可用消息）开始消费。</li><li><code>latest</code>：从 <strong>End Offset</strong>（最新写入的消息）开始消费。</li><li><code>none</code>：如果找不到 Offset，则抛出异常。</li></ul><h4 id="🔹-什么时候-Kafka-会“找不到-Offset”"><a href="#🔹-什么时候-Kafka-会“找不到-Offset”" class="headerlink" title="🔹 什么时候 Kafka 会“找不到 Offset”"></a>🔹 什么时候 Kafka 会“找不到 Offset”</h4><p>Kafka 找不到 Offset 主要发生在以下几种场景：</p><table><thead><tr><th>场景</th><th>发生原因</th><th>影响</th></tr></thead><tbody><tr><td><strong>新消费者组</strong></td><td><code>group.id</code> 从未消费过该主题，没有 Offset 记录</td><td>按 <code>auto.offset.reset</code> 规则消费</td></tr><tr><td><strong>Offset 过期</strong></td><td>超过 <code>offsets.retention.minutes</code>（默认 7 天），Kafka 自动清理 Offset</td><td>按 <code>auto.offset.reset</code> 规则消费</td></tr><tr><td><strong>主题被删除&#x2F;重建</strong></td><td>主题被删除后重新创建，原 Offset 记录丢失</td><td>按 <code>auto.offset.reset</code> 规则消费</td></tr><tr><td><strong>分区调整</strong></td><td>Kafka 重新分配分区，导致 Offset 失效</td><td>按 <code>auto.offset.reset</code> 规则消费</td></tr></tbody></table><h3 id="enable-auto-commit-false-时，Offset-何时更新？"><a href="#enable-auto-commit-false-时，Offset-何时更新？" class="headerlink" title="enable.auto.commit&#x3D;false 时，Offset 何时更新？"></a>enable.auto.commit&#x3D;false 时，Offset 何时更新？</h3><p>当 <code>enable.auto.commit=false</code> 时，Kafka <strong>不会自动提交 Offset</strong>，消费者需要手动调用 <code>consumer.commit()</code> 进行提交。</p><p><strong>如果不手动 <code>commit()</code>，Offset 会发生什么？</strong></p><ul><li><strong>Kafka 不会更新 Offset</strong>，下次重启消费者时会从旧的 Offset 重新消费（可能会重复消费）。</li><li><strong>Offset 只会在 <code>commit()</code> 之后更新</strong>，否则 Kafka 认为这条消息还未消费完成。</li></ul><p><strong>示例代码</strong>：</p><pre class="line-numbers language-language-python"><code class="language-language-python">from confluent_kafka import Consumerconsumer = Consumer(&#123;    'bootstrap.servers': 'localhost:9092',    'group.id': 'my-group',    'auto.offset.reset': 'earliest',    'enable.auto.commit': False&#125;)consumer.subscribe(['my-topic'])while True:    msg = consumer.poll(1.0)    if msg is None:        continue    print(f"Received message: &#123;msg.value().decode('utf-8')&#125;")    consumer.commit()  # 手动提交 Offset<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><h3 id="max-poll-interval-ms和消费者会话管理"><a href="#max-poll-interval-ms和消费者会话管理" class="headerlink" title="max.poll.interval.ms和消费者会话管理"></a>max.poll.interval.ms和消费者会话管理</h3><p>Kafka 通过 <code>max.poll.interval.ms</code> 控制消费者的活跃性。</p><h4 id="🔹-max-poll-interval-ms机制"><a href="#🔹-max-poll-interval-ms机制" class="headerlink" title="🔹 max.poll.interval.ms机制"></a>🔹 max.poll.interval.ms机制</h4><ul><li><strong>作用</strong>：如果 <code>poll()</code> 调用间隔超过 <code>max.poll.interval.ms</code>，Kafka 认为该消费者已失效，会触发 Rebalance。</li><li><strong>默认值</strong>：<code>300000ms</code>（5分钟）。</li><li><strong>影响</strong>：如果消费逻辑太慢，或者 <code>poll()</code> 迟迟未被调用，消费者会被踢出消费组，导致分区重新分配。</li></ul><h4 id="🔹-session-timeout-ms-机制"><a href="#🔹-session-timeout-ms-机制" class="headerlink" title="**🔹 session.timeout.ms 机制"></a>**🔹 session.timeout.ms 机制</h4><ul><li><strong>作用</strong>：如果消费者在 <code>session.timeout.ms</code> 内没有向 Kafka 发送心跳，Kafka 认为它已失联，触发 Rebalance。</li><li><strong>默认值</strong>：<code>45000ms</code>（45秒）。</li><li><strong>影响</strong>：如果消费者进程崩溃或网络问题，Kafka 会快速 Rebalance。</li></ul><p><strong>示例代码：避免因 <code>poll()</code> 过慢被踢出消费组</strong></p><pre class="line-numbers language-language-python"><code class="language-language-python">consumer = Consumer(&#123;    'bootstrap.servers': 'localhost:9092',    'group.id': 'my-group',    'auto.offset.reset': 'earliest',    'enable.auto.commit': False,    'max.poll.interval.ms': 600000  # 10分钟&#125;)while True:    msg = consumer.poll(1.0)    if msg is None:        continue  # 即使没有新消息，也要继续 poll()，否则可能被踢出    print(f"Received: &#123;msg.value().decode('utf-8')&#125;")    consumer.commit()<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><h3 id="避免-Kafka-Offset-丢失的最佳实践"><a href="#避免-Kafka-Offset-丢失的最佳实践" class="headerlink" title="避免 Kafka Offset 丢失的最佳实践"></a>避免 Kafka Offset 丢失的最佳实践</h3><p>为了保证 Kafka Offset 不会丢失，避免 <code>auto.offset.reset</code> 触发意外行为，可以采用以下策略：</p><h4 id="✅-定期提交-Offset"><a href="#✅-定期提交-Offset" class="headerlink" title="✅ 定期提交 Offset"></a>✅ 定期提交 Offset</h4><ul><li>关闭 <code>enable.auto.commit</code>，并手动 <code>commit()</code>。</li><li>例如，每 100 条消息提交一次 Offset。</li></ul><h4 id="✅-避免长时间不消费"><a href="#✅-避免长时间不消费" class="headerlink" title="✅ 避免长时间不消费"></a>✅ 避免长时间不消费</h4><ul><li>定期启动消费者，避免超过 <code>offsets.retention.minutes</code>（默认 7 天）。</li></ul><h4 id="✅-使用-kafka-consumer-groups-sh-监控-Offset"><a href="#✅-使用-kafka-consumer-groups-sh-监控-Offset" class="headerlink" title="✅ 使用 kafka-consumer-groups.sh 监控 Offset"></a>✅ 使用 kafka-consumer-groups.sh 监控 Offset</h4><pre><code>kafka-consumer-groups.sh --bootstrap-server localhost:9092 --group my-group --describe</code></pre><h4 id="✅-设置合理的-max-poll-interval-ms-和-session-timeout-ms"><a href="#✅-设置合理的-max-poll-interval-ms-和-session-timeout-ms" class="headerlink" title="✅ 设置合理的 max.poll.interval.ms 和 session.timeout.ms"></a>✅ 设置合理的 max.poll.interval.ms 和 session.timeout.ms</h4><ul><li>确保消费者不会因消费太慢被踢出消费组。</li></ul><h3 id="📌-总结"><a href="#📌-总结" class="headerlink" title="📌 总结"></a>📌 总结</h3><ul><li><strong>Kafka 只有在找不到 Offset 时，才会根据 <code>auto.offset.reset</code> 规则决定从哪里消费。</strong></li><li><strong><code>enable.auto.commit=false</code> 时，Offset 需要手动 <code>commit()</code>，否则不会前进。</strong></li><li><strong><code>max.poll.interval.ms</code> 影响消费者的存活，过长的处理时间可能导致消费者被踢出消费组。</strong></li><li><strong>避免 Offset 丢失的方法包括：定期提交 Offset、避免长时间不消费、监控 Offset 变化。</strong></li></ul>]]></content>
      
      
      <categories>
          
          <category> 消息队列 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> Kafka </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>大模型 RAG 应用开发基础及入门</title>
      <link href="/2025/02/12/da-mo-xing-rag-ying-yong-kai-fa-ji-chu-ji-ru-men/"/>
      <url>/2025/02/12/da-mo-xing-rag-ying-yong-kai-fa-ji-chu-ji-ru-men/</url>
      
        <content type="html"><![CDATA[<h2 id="什么是大语言模型的幻觉？"><a href="#什么是大语言模型的幻觉？" class="headerlink" title="什么是大语言模型的幻觉？"></a>什么是大语言模型的幻觉？</h2><p>大语言模型在处理自然语言时，有时候会出现”幻觉“现象。所谓幻觉，就是模型生成的内容与事实或上下文不一致的问题。这些问题会严重影响AI应用的可靠性和实用性。</p><h2 id="幻觉的两大类型"><a href="#幻觉的两大类型" class="headerlink" title="幻觉的两大类型"></a>幻觉的两大类型</h2><h3 id="事实性幻觉"><a href="#事实性幻觉" class="headerlink" title="事实性幻觉"></a>事实性幻觉</h3><p>指模型生成的内容与实际事实不匹配。比如在回答”第一个登上月球的人是谁?”这个问题时:</p><ul><li>错误回答: “Charles Lindbergh在1951年月球任务中第一个登上月球”</li><li>正确事实: Neil Armstrong才是第一个登上月球的人(1969年阿波罗11号任务)</li></ul><p>这种幻觉之所以危险，是因为模型生成的内容看起来很可信，但实际上完全错误。</p><h3 id="忠实性幻觉"><a href="#忠实性幻觉" class="headerlink" title="忠实性幻觉"></a>忠实性幻觉</h3><p>指模型生成的内容与提供的上下文不一致。这种幻觉可以分为三类：</p><ul><li>输出与原文不一致（编出原文中没有的信息）</li><li>上下文之间不一致（前后矛盾）</li><li>逻辑链不一致（推理过程存在漏洞）</li></ul><p>比如在总结新闻时，模型可能会添加原文中不存在的细节，或者前后描述矛盾。</p><h2 id="为什么会产生幻觉？"><a href="#为什么会产生幻觉？" class="headerlink" title="为什么会产生幻觉？"></a>为什么会产生幻觉？</h2><p>大语言模型产生幻觉的原因主要来自三个方面：</p><ol><li>数据源导致的幻觉<ul><li>训练数据中的质量问题</li><li>数据中存在的错误信息</li><li>数据覆盖范围有限</li></ul></li><li>训练过程导致的幻觉<ul><li>架构限制：无法准确理解长文本的上下文关联</li><li>累积错误：生成过程中的错误会逐步传递和放大</li></ul></li><li>推理相关的幻觉<ul><li>回答过于简略</li><li>生成过程中的不完整推理</li></ul></li></ol><h2 id="如何评估幻觉问题"><a href="#如何评估幻觉问题" class="headerlink" title="如何评估幻觉问题"></a>如何评估幻觉问题</h2><p>为了客观评估模型的幻觉问题，我们可以使用多种方法：</p><ol><li>事实一致性评估：将生成内容与权威来源进行比对</li><li>分类器评估：使用专门训练的模型来检测是否存在幻觉</li><li>问答测量：通过问答来验证生成内容的一致性</li><li>不确定度分析：评估模型对自身输出的确信程度</li><li>提示测量：让模型自我评估，通过特定提示策略来评估生成内容</li></ol><h2 id="RAG解决方案"><a href="#RAG解决方案" class="headerlink" title="RAG解决方案"></a>RAG解决方案</h2><h3 id="RAG是什么？"><a href="#RAG是什么？" class="headerlink" title="RAG是什么？"></a>RAG是什么？</h3><p><strong>RAG</strong>（Retrieval-Augmented Generation）也叫<strong>检索增强生成</strong>，是指对大语言模型输出进行优化，使其能够参考并利用数据源之外的权威知识。简单来说，RAG就是从外部检索对应的知识内容，和用户的提问一起构成Prompt发给大模型，再让大模型生成内容。</p><p>它的核心思想是：</p><ol><li><strong>从外部知识库检索相关信息</strong></li><li><strong>将检索到的信息作为上下文提供给模型</strong></li><li><strong>让模型基于这些上下文生成回答</strong></li></ol><p>简单来说：RAG &#x3D; 外部知识检索 + Prompt构建 + LLM 生成</p><p><img src="/medias/featureimages/blog/da-mo-xing-rag-ying-yong-kai-fa-ji-chu-ji-ru-men/image1.png" alt="image"></p><h3 id="为什么需要RAG？"><a href="#为什么需要RAG？" class="headerlink" title="为什么需要RAG？"></a>为什么需要RAG？</h3><p>LLM虽然是一个强大的工具，但它本身拒绝了解任何时事，且它给出的答案总是非常流畅，内容却不一定靠谱。这存在几个主要的问题:</p><ol><li>LLM的训练数据量有限且无法更新到最新知识。</li><li>当用户需要专业或领域特定的数据时，LLM往往缺乏相应的知识</li><li>对于答案的问答内容很难从源创进行溯源</li><li>由于技术限制，不同的训练源使用相同的大语言技术，可能会产生不确信的响应</li></ol><p>而RAG为解决这些问题带来了以下优势：</p><ul><li><strong>经济高效</strong>：预训练和微调模型的成本很高，而RAG是一种经济高效的新方法</li><li><strong>信息时效</strong>：使用RAG可以为LLM提供最新的研究、统计数据或新闻</li><li><strong>增强用户信任度</strong>：RAG允许LLM通过来源归属来呈现具体的信息，输出可以包括对来源的引文或参考，这可以增加对对话的生成式人工智能解决方案的任何信心</li></ul><h3 id="RAG是如何工作的？"><a href="#RAG是如何工作的？" class="headerlink" title="RAG是如何工作的？"></a>RAG是如何工作的？</h3><p>RAG采用三种主要的检索方式：</p><ol><li><strong>一次性检索</strong>：<ul><li>从单次检索中获取相关知识</li><li>直接预置到大模型的提示词中</li><li>不会收集反馈信息</li></ul></li><li><strong>迭代检索</strong>：<ul><li>允许在对话过程中多次检索</li><li>每一轮都可能有新的检索</li><li>支持多轮对话优化</li></ul></li><li><strong>事后检索</strong>：<ul><li>先生成答案</li><li>然后检索验证</li><li>对答案进行修正</li></ul></li></ol><p><img src="/medias/featureimages/blog/da-mo-xing-rag-ying-yong-kai-fa-ji-chu-ji-ru-men/image2.png" alt="image"></p><h3 id="RAG实战示例"><a href="#RAG实战示例" class="headerlink" title="RAG实战示例"></a>RAG实战示例</h3><p>以一个简单的问答场景为例，展示RAG的实际应用流程:</p><ol><li>用户提问:”公司有销售什么产品？”</li><li>系统处理流程:<ul><li>使用检索器获取产品相关文档</li><li>将文档内容与问题组合成提示词</li><li>通过LLM生成回答</li><li>确保回答基于检索到的事实信息</li></ul></li><li>最终输出:包含准确的产品信息，并且所有信息都可以溯源。</li></ol><h2 id="AI应用开发利器：向量数据库详解"><a href="#AI应用开发利器：向量数据库详解" class="headerlink" title="AI应用开发利器：向量数据库详解"></a>AI应用开发利器：向量数据库详解</h2><h3 id="什么是向量数据库？"><a href="#什么是向量数据库？" class="headerlink" title="什么是向量数据库？"></a>什么是向量数据库？</h3><p>向量数据库（Vector Database）是一种专门用于存储和处理向量数据的数据库系统。它不同于传统的关系型数据库，因为它需要将所有数据映射为特定的向量格式，并采用相似性搜索作为主要的检索方式。</p><h3 id="一个生动的例子：识别猫咪"><a href="#一个生动的例子：识别猫咪" class="headerlink" title="一个生动的例子：识别猫咪"></a>一个生动的例子：识别猫咪</h3><p>让我们通过一个识别猫咪的例子来理解向量数据库。假设我们有一组不同品种的猫咪图片：</p><ul><li>波斯猫</li><li>英国短毛猫</li><li>暹罗猫</li><li>布偶猫</li><li>无毛猫</li></ul><p>每张猫咪图片都可以用一组数字向量来表示其特征，如:</p><pre class="line-numbers language-language-json"><code class="language-language-json">波斯猫: [0.4, 0.3, 0.4, 0.5, 0.3, 0.4, 0.5, ...]英国短毛猫: [0.7, 0.2, 0.5, 0.5, 0.5, 0.5, 0.5, ...]暹罗猫: [0.5, 0.3, 0.4, 0.5, 0.3, 0.4, 0.5, ...]<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span></span></code></pre><p>这些数字代表了猫咪的各种特征，比如:</p><ul><li>毛发长度</li><li>体型大小</li><li>面部特征</li><li>耳朵形状等等</li></ul><h3 id="向量数据库的优势"><a href="#向量数据库的优势" class="headerlink" title="向量数据库的优势"></a>向量数据库的优势</h3><p>与传统的数据库相比，向量数据库有以下特点：</p><ol><li><strong>数据类型</strong>：<ul><li>传统数据库：数值、字符串、时间等结构化数据</li><li>向量数据库：向量数据(不存储原始数据，有的也支持)</li></ul></li><li><strong>数据规模</strong>：<ul><li>传统数据库：小，1亿条数据对关系型数据库来说规模很大</li><li>向量数据库：大，最少千亿数据是基线</li></ul></li><li><strong>数据组织方式</strong>：<ul><li>传统数据库：基于表格、按照行和列组织</li><li>向量数据库：基于向量、按向量维度组织</li></ul></li><li><strong>查找方式</strong>：<ul><li>传统数据库：精确查找&#x2F;范围查找</li><li>向量数据库：近似查找，查询结果是与输入向量最相似的向量</li></ul></li></ol><h3 id="相似性搜索算法"><a href="#相似性搜索算法" class="headerlink" title="相似性搜索算法"></a>相似性搜索算法</h3><p>在向量数据库中，支持通过多种方式来计算两个向量的相似度：</p><p><strong>余弦相似度</strong>：主要是用于衡量向量在方向上的相似性，特别适用于文本、图像和高维空间中的向量。它不受向量长度的影响，只考虑方向的相似程度，计算公式如下（计算两个向量间的夹角的余弦值，取值范围为[-1, 1]）：</p><pre class="line-numbers language-language-bash"><code class="language-language-bash">similarity(A,B) = (A·B)/(||A||·||B||)<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span></span></code></pre><p><strong>欧式距离</strong>：主要是用于衡量向量之间的直线距离，得到的值可能很大，最小为0，通常用于低维空间或需要考虑向量各个维度之间差异的情况。欧式距离较小的向量被认为更相似，计算公式如下：</p><pre class="line-numbers language-language-bash"><code class="language-language-bash">distance(A,B) = √∑(Ai-Bi)²<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span></span></code></pre><p>例如下图：左侧就是<code>欧式距离</code>，右侧就是<code>余弦相似度</code>。</p><p><img src="/medias/featureimages/blog/da-mo-xing-rag-ying-yong-kai-fa-ji-chu-ji-ru-men/image3.png" alt="image"></p><h3 id="实际应用场景"><a href="#实际应用场景" class="headerlink" title="实际应用场景"></a>实际应用场景</h3><p>向量数据库的主要应用场景包括：</p><ol><li>人脸识别</li><li>图像搜索</li><li>音频识别</li><li>智能推荐系统</li></ol><p>这些场景的共同特点是：需要对非结构化数据（如图片、文本、音频）进行相似度搜索。</p><p>在RAG中，我们会将文档的知识按特定规则分成小块，转换成向量存储到向量数据库中。当人类提问时，我们将问题转换为向量，在数据库中找到最相似的文本块，这些文本块可以成为Prompt的补充内容。</p><h2 id="深入理解Embedding嵌入技术"><a href="#深入理解Embedding嵌入技术" class="headerlink" title="深入理解Embedding嵌入技术"></a>深入理解Embedding嵌入技术</h2><h3 id="Embedding-是什么？"><a href="#Embedding-是什么？" class="headerlink" title="Embedding 是什么？"></a>Embedding 是什么？</h3><p>Embedding(嵌入)是一种在机器学习中广泛使用的技术，它能将文本、图片、视频等非结构化数据映射到向量空间中。一个Embedding向量通常是一个包含N个浮点数的数组，这个向量不仅表示了数据的特征，更重要的是通过学习可以表达它们的内在语义。简而言之，Embedding就是一个模型生成方法，可以将非结构化的数据，例如文本&#x2F;图片&#x2F;视频等数据映射成有意义的向量数据。比如一段文本、一张图片、一段视频，警告Embedding模型处理后都会变成类似这样的向量：</p><pre class="line-numbers language-language-bash"><code class="language-language-bash">[0.5, 0.8, 0.7, 0.5, 0.8, 0.7, 0.5, 0.8, 0.7, 0.5]<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span></span></code></pre><p><img src="/medias/featureimages/blog/da-mo-xing-rag-ying-yong-kai-fa-ji-chu-ji-ru-men/image4.png" alt="image"></p><h3 id="主流的Embedding模型"><a href="#主流的Embedding模型" class="headerlink" title="主流的Embedding模型"></a>主流的Embedding模型</h3><p>目前主要有这几类Embedding模型：</p><ol><li><strong>Word2Vec（词嵌入模型）</strong><ul><li>通过学习词语转化为连续的向量表示</li><li>基于两种主要算法：<code>CBOW</code> 和 <code>Skip-gram</code></li><li>能够捕捉词语之间的语义关系</li></ul></li><li><strong>1GloVe</strong><ul><li>类似Word2Vec但采用不同的训练方式</li><li>同时考虑全局共现信息</li><li>能较好地保存词语间的语义关系</li><li>适用于多种自然语言处理任务</li></ul></li><li><strong>FastText</strong><ul><li>考虑了单词的子词信息</li><li>能处理训练集中未出现的生词</li><li>支持多语言处理</li></ul></li><li><strong>大模型Embeddings</strong><ul><li>如OpenAI的text-embedding-ada-002</li><li>输入维度8191个tokens</li><li>输出维度1536维向量</li></ul></li></ol><h3 id="Embedding的神奇之处"><a href="#Embedding的神奇之处" class="headerlink" title="Embedding的神奇之处"></a>Embedding的神奇之处</h3><p>Embedding最有趣的特性是它能够捕捉语义关系。让我们看一个著名的例子</p><pre class="line-numbers language-language-bash"><code class="language-language-bash">King - Man + Woman ≈ Queen(国王 - 男人 + 女人 ≈ 女王)<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span></span></code></pre><p>这个公式展示了Embedding不仅仅是把词语转换成数字，它还能：</p><ol><li>保留词语之间的关系</li><li>支持向量运算</li><li>产生有意义的结果</li></ol><p>我们可以通过可视化的方式看到这些词语在向量空间中的分布：</p><ul><li>woman和girl的向量位置接近</li><li>man和boy的向量位置接近</li><li>king和queen虽然性别不同，但都位于表示”统治者”的维度上</li></ul><h3 id="Embedding的重要价值"><a href="#Embedding的重要价值" class="headerlink" title="Embedding的重要价值"></a>Embedding的重要价值</h3><ol><li><strong>降维</strong>：将高维数据映射到低维空间，大大降低了计算复杂度</li><li><strong>捕捉语义信息</strong>：不仅能记录表面的词频信息，还能捕捉深层的语义关联</li><li><strong>泛化性</strong>：Embedding学习到的是通用的语言表达方式，可以应用到新的场景</li><li><strong>泛化能力</strong>：对于未见过的数据，也能基于已学习的语义特征给出合理的向量表示</li><li><strong>可视化支持</strong>：虽然Embedding本身很复杂，但我们可以使用t-SNE等工具将其可视化，帮助理解数据的内在结构。</li></ol><h3 id="在RAG中的应用"><a href="#在RAG中的应用" class="headerlink" title="在RAG中的应用"></a>在RAG中的应用</h3><p>在RAG系统中，Embedding主要用于两个场景：</p><ol><li><strong>文档向量化</strong>：将知识库中的文档转换为向量</li><li><strong>查询向量化</strong>：将用户的问题转换为向量</li></ol><p>通过比较这些向量的相似度，我们可以找到与用户问题最相关的文档片段，从而提供更准确的答案。</p><h2 id="RAG应用实战-OpenAI-Embedding与LangChain的结合"><a href="#RAG应用实战-OpenAI-Embedding与LangChain的结合" class="headerlink" title="RAG应用实战:OpenAI Embedding与LangChain的结合"></a>RAG应用实战:OpenAI Embedding与LangChain的结合</h2><h3 id="OpenAI-Embedding接口简介"><a href="#OpenAI-Embedding接口简介" class="headerlink" title="OpenAI Embedding接口简介"></a>OpenAI Embedding接口简介</h3><p>OpenAI提供了多个Embedding模型选择，以下是几个主要模型的对比:</p><table><thead><tr><th>模型</th><th>Token数(每个文档800个)</th><th>性能评估</th><th>最大输入</th><th>向量维度</th></tr></thead><tbody><tr><td>text-embedding-3-small</td><td>62,500</td><td>62.3%</td><td>8191</td><td>1536</td></tr><tr><td>text-embedding-3-large</td><td>9,615</td><td>64.6%</td><td>8191</td><td>3072</td></tr><tr><td>text-embedding-ada-002</td><td>12,500</td><td>61.0%</td><td>8191</td><td>1536</td></tr></tbody></table><h3 id="LangChain中的Embedding组件使用"><a href="#LangChain中的Embedding组件使用" class="headerlink" title="LangChain中的Embedding组件使用"></a>LangChain中的Embedding组件使用</h3><p>在LangChain中，Embedding类提供了统一的接口来使用各种嵌入模型:</p><pre class="line-numbers language-language-bash"><code class="language-language-bash">class Embeddings(ABC):    """Interface for embedding models."""        @abstractmethod    def embed_documents(self, texts: List[str]) -> List[List[float]]:        """Embed search docs."""            @abstractmethod    def embed_query(self, text: str) -> List[float]:        """Embed query text."""<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><p>使用示例:</p><pre class="line-numbers language-language-python"><code class="language-language-python">import dotenvimport numpy as npfrom langchain_openai import OpenAIEmbeddingsfrom numpy.linalg import norm# 初始化Embedding模型embeddings = OpenAIEmbeddings()# 进行文本嵌入query_vector = embeddings.embed_query("你好, 我是小潘")documents_vector = embeddings.embed_documents([    "你好, 我是小潘",    "这个自然语言处理的人叫小潘",    "来知若惘, 既心若旷"])# 计算相似度def cosine_similarity(vector1, vector2):    dot_product = np.dot(vector1, vector2)    norm1 = norm(vector1)    norm2 = norm(vector2)    return dot_product / (norm1 * norm2)<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><h3 id="CacheBackEmbedding的使用"><a href="#CacheBackEmbedding的使用" class="headerlink" title="CacheBackEmbedding的使用"></a>CacheBackEmbedding的使用</h3><p>为了提高性能，LangChain提供了缓存功能：</p><pre class="line-numbers language-language-python"><code class="language-language-python">from langchain.embeddings import CacheBackedEmbeddingsfrom langchain.storage import LocalFileStoreembeddings = OpenAIEmbeddings(model="text-embedding-3-small")embeddings_with_cache = CacheBackedEmbeddings.from_bytes_store(    embeddings,    LocalFileStore("./cache/"),    namespace=embeddings.model,    query_embedding_cache=True)<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><p>使用缓存时需要注意：</p><ol><li>underlying_embedder: 使用的基础嵌入模型</li><li>document_embedding_cache: 用于缓存文档的存储结构</li><li>batch_size: 可选参数，默认None</li><li>namespace: 用于文档缓存的命名空间</li><li>query_embedding_cache: 是否缓存查询向量</li></ol><h3 id="运行流程分析"><a href="#运行流程分析" class="headerlink" title="运行流程分析"></a>运行流程分析</h3><p>一个完整的RAG应用运行流程如下：</p><ol><li><strong>文档预处理</strong><ul><li>分割文档</li><li>生成向量</li><li>存入向量数据库</li></ul></li><li><strong>查询处理</strong><ul><li>将用户问题转为向量</li><li>在向量数据库中检索</li><li>组合上下文生成回答</li></ul></li><li><strong>缓存优化</strong><ul><li>缓存常见文档的向量</li><li>缓存常见查询的向量</li><li>提供响应速度</li></ul></li></ol><h3 id="注意事项"><a href="#注意事项" class="headerlink" title="注意事项"></a>注意事项</h3><ol><li>向量维度的选择<ul><li>需要平衡精度和效率</li><li>维度越高，表达能力越强，但计算成本也越高</li></ul></li><li>缓存策略<ul><li>合理设置缓存大小</li><li>选择适当的缓存淘汰策略</li><li>定期更新缓存</li></ul></li><li>性能优化<ul><li>使用批处理提高效率</li><li>合理使用多线程</li><li>监控资源使用情况</li></ul></li></ol>]]></content>
      
      
      <categories>
          
          <category> AI </category>
          
      </categories>
      
      
        <tags>
            
            <tag> RAG </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>LangChain RAG 应用开发优化策略详解</title>
      <link href="/2025/02/12/langchain-rag-ying-yong-kai-fa-you-hua-ce-lue-xiang-jie/"/>
      <url>/2025/02/12/langchain-rag-ying-yong-kai-fa-you-hua-ce-lue-xiang-jie/</url>
      
        <content type="html"><![CDATA[<h2 id="引言：理解RAG及其重要性"><a href="#引言：理解RAG及其重要性" class="headerlink" title="引言：理解RAG及其重要性"></a>引言：理解RAG及其重要性</h2><p>在大语言模型（LLM）应用开发中，检索增强生成（Retrival-Augmented Generation, RAG）已经成为提升模型输出质量的关键技术。本文将深入探讨在LangChain框架中如何优化RAG应用，帮助开发者构建更智能、更准确的AI应用。</p><h2 id="RAG的基本概念"><a href="#RAG的基本概念" class="headerlink" title="RAG的基本概念"></a>RAG的基本概念</h2><blockquote><p>📌 什么是RAG?<br>RAG是一种将外部知识检索与语言模型生成相结合的技术架构。它通过检索相关信息来增强LLM的知识储备，从而产生更准确、更可靠的输出。</p></blockquote><h3 id="为什么需要优化RAG？"><a href="#为什么需要优化RAG？" class="headerlink" title="为什么需要优化RAG？"></a>为什么需要优化RAG？</h3><p>在实际应用中，基础的RAG实现往往会遇到以下挑战：</p><ol><li>检索准确性不足</li><li>复杂问题处理能力有限</li><li>知识关联不够紧密</li><li>响应质量不够稳定</li></ol><p>这些问题促使我们需要采用多种优化策略来提升RAG的性能。</p><h3 id="第一部分：多查询检索优化策略"><a href="#第一部分：多查询检索优化策略" class="headerlink" title="第一部分：多查询检索优化策略"></a>第一部分：多查询检索优化策略</h3><h4 id="理解多查询检索的必要性"><a href="#理解多查询检索的必要性" class="headerlink" title="理解多查询检索的必要性"></a>理解多查询检索的必要性</h4><p>在RAG应用中，单一查询往往无法完整捕捉用户问题的所有方面。例如，当用户问”Python如何实现多线程并发控制？“时，我们可能需要同时检索：</p><ul><li>Python线程基础知识</li><li>并发控制机制</li><li>线程安全实现方法</li></ul><h4 id="多查询检索的工作原理"><a href="#多查询检索的工作原理" class="headerlink" title="多查询检索的工作原理"></a>多查询检索的工作原理</h4><blockquote><p>🔍 核心思路：利用LLM的理解能力，将一个复杂查询拆分或重写为多个相关查询，然后通过融合算法整合检索结果。</p></blockquote><p><strong>工作流程</strong>：</p><ol><li><strong>查询重写</strong>：LLM将原始查询转换为多个相关查询</li><li><strong>并行检索</strong>：对每个查询进行独立检索</li><li><strong>结果融合</strong>：使用RRF（Reciprocal Rank Fusion）算法融合检索结果</li><li><strong>内容生成</strong>：将融合后的结果输入LLM生成最终答案</li></ol><h3 id="代码实现示例"><a href="#代码实现示例" class="headerlink" title="代码实现示例"></a>代码实现示例</h3><pre class="line-numbers language-language-python"><code class="language-language-python">from langchain.retrievers import MultiQueryRetrieverfrom langchain.chains import LLMChainfrom langchain.prompts import PromptTemplate# 1. 创建多查询检索器retriever = MultiQueryRetriever(    retriever=base_retriever,    llm=ChatOpenAI(model="gpt-3.5-turbo-16k", temperature=0),    prompt_template="""基于用户的问题，生成3个不同的相关查询：    原始问题: &#123;question&#125;    生成的查询应该探索问题的不同方面。    """)# 2. 使用RRF算法融合结果def rrf_fusion(results, k=60):    fused_scores = &#123;&#125;    for rank, doc in enumerate(results):        doc_str = doc.page_content        if doc_str not in fused_scores:            fused_scores[doc_str] = 1.0 / (k + rank + 1)        else:            fused_scores[doc_str] += 1.0 / (k + rank + 1)        # 排序并返回结果    sorted_results = sorted(fused_scores.items(),                           key=lambda x: x[1],                           reverse=True)    return sorted_results<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><p>RRF 算法原理如下</p><pre class="line-numbers language-language-python"><code class="language-language-python">"""RRF (Reciprocal Rank Fusion) 算法的核心公式：RRFscore(d ∈ D) = ∑ 1/(k + r(d))其中：- d 是文档- D 是所有文档集合- k 是一个常数(通常取60)- r(d)是文档d在排序中的位置这个公式的特点：1. 对排名靠前的文档给予更高的权重2. k参数可以调节排名的影响程度3. 适合融合不同来源的排序结果"""<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><h4 id="优化效果分析"><a href="#优化效果分析" class="headerlink" title="优化效果分析"></a>优化效果分析</h4><p>多查询检索策略带来的主要优势：</p><ol><li><strong>提升召回率</strong><ul><li>通过多角度查询提高相关文档的覆盖率</li><li>减少因单一查询表达不当导致的漏检</li></ul></li><li><strong>提高准确性</strong><ul><li>RRF融合算法可以突出高质量的共同结果</li><li>降低单个查询的噪声影响</li></ul></li><li><strong>增强鲁棒性</strong><ul><li>对查询表达的变化更不敏感</li><li>能更好地处理复杂或模糊的问题</li></ul></li></ol><h4 id="实践建议"><a href="#实践建议" class="headerlink" title="实践建议"></a>实践建议</h4><p>在实际应用中，需要注意以下几点：</p><ul><li><strong>查询数量选择</strong>：通常生成3-5个查询即可，过多查询可能引入噪声</li><li><strong>相似度阈值设置</strong>：建议在RRF融合时设置合适的相似度阈值，过滤低相关性结果</li><li><strong>资源消耗考虑</strong>：多查询会增加API调用和计算资源，需要在效果和成本间权衡</li></ul><blockquote><p>💡 实践小贴士：可以通过监控检索结果的diversity和relevance指标，来调整多查询策略的参数。</p></blockquote><h3 id="第二部分：问题分解策略优化"><a href="#第二部分：问题分解策略优化" class="headerlink" title="第二部分：问题分解策略优化"></a>第二部分：问题分解策略优化</h3><h4 id="复杂问题的分解处理"><a href="#复杂问题的分解处理" class="headerlink" title="复杂问题的分解处理"></a>复杂问题的分解处理</h4><p>在实际应用中，我们经常遇到复杂的多层次问题。例如：”请分析特斯拉近五年的财务状况，并评估其在电动汽车市场的竞争优势。”这类问题需要：</p><ul><li>处理大量相关信息</li><li>分析多个维度</li><li>综合多方面结论</li></ul><p><strong>并行分解模式</strong>:</p><blockquote><p>🔄 并行模式：将问题同时分解为多个独立子问题，分别获取答案后合并。</p></blockquote><pre class="line-numbers language-language-python"><code class="language-language-python"># 并行分解示例decomposition_chain = &#123;    "question": RunnablePassthrough(),    | decomposition_prompt    # 分解问题    | ChatOpenAI(temperature=0)    | StrOutputParser()&#125;# 并行处理子问题sub_questions = decomposition_chain.invoke(question)answers = await asyncio.gather(*[    process_subquestion(q) for q in sub_questions])<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><p><strong>串行分解模式</strong>:</p><blockquote><p>⛓️ 串行模式：按照逻辑顺序依次处理子问题，后面的问题依赖前面的答案。</p></blockquote><pre class="line-numbers language-language-python"><code class="language-language-python"># 串行分解示例class StepBackRetriever(BaseRetriever):    def _get_relevant_documents(        self, query: str, *, run_manager: CallbackManagerForRetrieverRun    ) -> List[Document]:        # 1. 生成中间查询        intermediate_query = self.llm.predict(            f"为了回答'&#123;query&#125;'，我们需要先了解什么？"        )                # 2. 检索中间知识        intermediate_docs = self.retriever.get_relevant_documents(            intermediate_query        )                # 3. 基于中间知识检索最终答案        final_docs = self.retriever.get_relevant_documents(query)                return intermediate_docs + final_docs<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><h4 id="Step-Back-策略实现"><a href="#Step-Back-策略实现" class="headerlink" title="Step-Back 策略实现"></a>Step-Back 策略实现</h4><p>Step-Back策略是一种特殊的串行分解方法，它通过“后退一步”来获取更基础的知识背景。</p><pre class="line-numbers language-language-python"><code class="language-language-python">"""示例：用户问题"量子计算机如何影响现代密码学？"Step-Back分解：1. 基础知识查询：   - 什么是量子计算机的基本原理？   - 现代密码学的核心技术有哪些？2. 关联分析：   - 量子计算对RSA等算法的影响   - 后量子密码学的发展3. 最终综合：   基于以上知识形成完整答案"""<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><p><strong>工作流程</strong>：</p><ol><li>分析原始问题</li><li>生成更基础的前置问题</li><li>获取基础知识</li><li>结合基础知识回答原问题</li></ol><h4 id="Step-Back-代码实现"><a href="#Step-Back-代码实现" class="headerlink" title="Step-Back 代码实现"></a>Step-Back 代码实现</h4><pre class="line-numbers language-language-python"><code class="language-language-python">system_prompt = """你是一位专业的助手，需要：1. 理解用户的具体问题2. 思考需要哪些基础知识3. 生成相关的基础问题4. 基于基础知识回答原问题"""few_shot_prompt = FewShotChatMessagePromptTemplate(    example_prompt=example_prompt,    examples=examples,    suffix="现在，请帮我回答：&#123;question&#125;")<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><h4 id="优化效果对比"><a href="#优化效果对比" class="headerlink" title="优化效果对比"></a>优化效果对比</h4><table><thead><tr><th>分解策略</th><th>适用场景</th><th>优势</th><th>劣势</th></tr></thead><tbody><tr><td>并行分解</td><td>独立子问题</td><td>处理速度快，资源利用高</td><td>结果整合可能不够连贯</td></tr><tr><td>串行分解</td><td>逻辑依赖性强</td><td>答案更连贯，逻辑性强</td><td>处理时间较长</td></tr><tr><td>Step-Back</td><td>需要深入理解</td><td>回答更全面，准确度高</td><td>资源消耗较大</td></tr></tbody></table><h4 id="优化建议"><a href="#优化建议" class="headerlink" title="优化建议"></a>优化建议</h4><ol><li>选择策略时考虑因素:<ul><li>问题的复杂度</li><li>子问题间的依赖关系</li><li>响应时间要求</li><li>资源限制</li></ul></li><li>优化建议：<ul><li>对于并行模式，注意结果融合的质量</li><li>串行模式要控制分解的层级深度</li><li>Step-Back策略要平衡基础知识的范围</li></ul></li></ol><blockquote><p>🌟 最佳实践：可以根据问题类型动态选择分解策略，甚至组合使用多种策略。</p></blockquote><h3 id="第三部分：混合检索策略实现"><a href="#第三部分：混合检索策略实现" class="headerlink" title="第三部分：混合检索策略实现"></a>第三部分：混合检索策略实现</h3><h4 id="理解混合检索的价值"><a href="#理解混合检索的价值" class="headerlink" title="理解混合检索的价值"></a>理解混合检索的价值</h4><p>在实际应用中，单一的检索方法往往难以应对所有场景。例如：</p><ul><li>语义检索擅长理解上下文，但可能错过关键词</li><li>关键词检索准确度高，但缺乏语义理解</li><li>密集检索和稀疏检索各有优势</li></ul><p>因此，将多种检索方法结合起来，可以取长补短，提升整体检索效果。</p><h4 id="混合检索器的架构设计"><a href="#混合检索器的架构设计" class="headerlink" title="混合检索器的架构设计"></a>混合检索器的架构设计</h4><pre class="line-numbers language-language-python"><code class="language-language-python">from langchain.retrievers import EnsembleRetrieverfrom langchain_community.retrievers import BM25Retrieverfrom langchain_community.vectorstores import FAISS# 1. 创建不同类型的检索器# BM25检索器（基于关键词）bm25_retriever = BM25Retriever.from_documents(    documents, k=4)# FAISS检索器（基于向量）faiss_retriever = FAISS.from_documents(    documents,    embedding=OpenAIEmbeddings(model="text-embedding-3-small")).as_retriever(search_kwargs=&#123;"k": 4&#125;)# 2. 创建集成检索器ensemble_retriever = EnsembleRetriever(    retrievers=[bm25_retriever, faiss_retriever],    weights=[0.5, 0.5])<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><h4 id="主要检索方法的特点"><a href="#主要检索方法的特点" class="headerlink" title="主要检索方法的特点"></a>主要检索方法的特点</h4><p>下面是几种常用检索方法的对比：</p><table><thead><tr><th>检索方法</th><th>优势</th><th>适用场景</th><th>注意事项</th></tr></thead><tbody><tr><td>BM25</td><td>精确匹配，速度快</td><td>关键词搜索</td><td>不理解语义变化</td></tr><tr><td>向量检索</td><td>理解语义相似</td><td>概念搜索</td><td>计算资源消耗大</td></tr><tr><td>混合检索</td><td>综合优势</td><td>复杂查询</td><td>需要调整权重</td></tr></tbody></table><h4 id="实现细节和优化"><a href="#实现细节和优化" class="headerlink" title="实现细节和优化"></a>实现细节和优化</h4><p><strong>检索器配置</strong>:</p><pre class="line-numbers language-language-python"><code class="language-language-python"># 配置检索参数faiss_retriever = faiss_db.as_retriever(    search_kwargs=&#123;"k": 4&#125;).configurable_fields(    search_kwargs=ConfigurableField(        id="search_kwargs_faiss",        name="检索参数",        description="设置检索的参数"    ))# 设置运行时配置config = &#123;"configurable": &#123;"search_kwargs_faiss": &#123;"k": 4&#125;&#125;&#125;docs = ensemble_retriever.invoke("查询", config=config)<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><p><strong>权重调整策略</strong>:</p><ol><li><strong>初始设置</strong>：开始时可以给各检索器相同权重</li><li><strong>动态调整</strong>：根据查询类型动态调整权重</li><li><strong>性能监控</strong>：跟踪各检索器的表现，定期优化权重</li><li><strong>场景适配</strong>：针对不同领域调整最优权重组合</li></ol><h4 id="应用效果优化"><a href="#应用效果优化" class="headerlink" title="应用效果优化"></a>应用效果优化</h4><p>为了获得最佳检索效果，建议：</p><ol><li>检索器选择<ul><li>根据数据特点选择合适的检索器组合</li><li>考虑计算资源和响应时间的平衡</li><li>评估检索器的互补性</li></ul></li><li>参数优化<ul><li>使用验证集调整检索参数</li><li>监控检索质量指标</li><li>定期更新检索模型</li></ul></li><li>结果融合<ul><li>采用多样化的融合策略</li><li>考虑结果的去重和排序</li><li>平衡相关性和多样性</li></ul></li></ol><h4 id="性能监控与改进"><a href="#性能监控与改进" class="headerlink" title="性能监控与改进"></a>性能监控与改进</h4><pre class="line-numbers language-language-python"><code class="language-language-python"># 性能监控示例def evaluate_retrieval(retriever, test_queries, ground_truth):    metrics = &#123;        'precision': [],        'recall': [],        'latency': []    &#125;        for query, truth in zip(test_queries, ground_truth):        start_time = time.time()        results = retriever.get_relevant_documents(query)        latency = time.time() - start_time                # 计算评估指标        metrics['latency'].append(latency)        # ... 计算precision和recall            return metrics    <span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><h3 id="总结：RAG优化策略的实践指南"><a href="#总结：RAG优化策略的实践指南" class="headerlink" title="总结：RAG优化策略的实践指南"></a>总结：RAG优化策略的实践指南</h3><h4 id="优化策略的综合比较"><a href="#优化策略的综合比较" class="headerlink" title="优化策略的综合比较"></a>优化策略的综合比较</h4><p>以下是我们讨论过的主要优化策略的特点对比：</p><table><thead><tr><th>优化策略</th><th>主要优势</th><th>实现复杂度</th><th>资源消耗</th><th>适用场景</th></tr></thead><tbody><tr><td>多查询检索</td><td>提高召回率</td><td>中等</td><td>中等</td><td>复杂查询、模糊问题</td></tr><tr><td>问题分解</td><td>提升理解深度</td><td>较高</td><td>较高</td><td>多维度分析问题</td></tr><tr><td>Step-Back</td><td>增强理解准确性</td><td>高</td><td>高</td><td>需要深入理解的问题</td></tr><tr><td>混合检索</td><td>综合性能提升</td><td>中等</td><td>较高</td><td>通用场景</td></tr></tbody></table><h4 id="优化路径建议"><a href="#优化路径建议" class="headerlink" title="优化路径建议"></a>优化路径建议</h4><ol><li><strong>基础阶段</strong><ul><li>实现基本的RAG流程</li><li>优化向量检索参数</li><li>改进提示词设计</li></ul></li><li><strong>进阶阶段</strong><ul><li>引入多查询策略</li><li>实现基本的问题分解</li><li>尝试混合检索方法</li></ul></li><li><strong>高级阶段</strong><ul><li>实现完整的Step-Back策略</li><li>优化多检索器集成</li><li>构建自适应检索系统</li></ul></li></ol><p><strong>场景选择指南</strong>:</p><p>根据不同的应用场景，推荐以下优化组合：</p><ol><li><strong>知识问答系统</strong><ul><li>多查询检索 + 混合检索</li><li>重点优化检索准确性</li></ul></li><li><strong>文档分析系统</strong><ul><li>问题分解 + Step-Back</li><li>强化深度理解能力</li></ul></li><li><strong>通用对话系统</strong><ul><li>混合检索 + 多查询</li><li>平衡效率和准确性</li></ul></li></ol>]]></content>
      
      
      <categories>
          
          <category> AI </category>
          
      </categories>
      
      
        <tags>
            
            <tag> Langchain </tag>
            
            <tag> RAG </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>LangChain初入门</title>
      <link href="/2025/02/09/langchain-chu-ru-men/"/>
      <url>/2025/02/09/langchain-chu-ru-men/</url>
      
        <content type="html"><![CDATA[<h2 id="为什么选择LangChain"><a href="#为什么选择LangChain" class="headerlink" title="为什么选择LangChain"></a>为什么选择LangChain</h2><p>LangChain作为一个强大的框架，具有以下优势：</p><ul><li><p><strong>组件化和标准化</strong>：提供了标准化的接口来处理各种LLM，使开发更加灵活和可维护。</p></li><li><p><strong>丰富的工具集成</strong>：内置了大量工具和集成，可以轻松连接数据库、搜索引擎等外部服务。</p></li><li><p><strong>链式处理能力</strong>：可以将多个组件组合成链，实现复杂的处理流程。</p></li><li><p><strong>内存管理</strong>：提供了多种记忆组件，使应用能够保持上下文连贯性。</p></li></ul><h2 id="LangChain简介"><a href="#LangChain简介" class="headerlink" title="LangChain简介"></a>LangChain简介</h2><p>LangChain是一个用于开发由语言模型驱动的应用程序的框架。</p><h3 id="核心组件"><a href="#核心组件" class="headerlink" title="核心组件"></a>核心组件</h3><ul><li><p><strong>Models (模型)</strong>：提供与大语言模型的统一交互接口，支持各类LLM、聊天模型和文本嵌入模型的调用</p></li><li><p><strong>Prompts (提示)</strong>：专门用于管理和优化提示模板，提供标准化的提示工程工具</p></li><li><p><strong>Indexes (索引)</strong>：提供高效的文档加载、分割和向量存储系统，支持大规模文本处理和检索</p></li><li><p><strong>Memory (记忆)</strong>：用于在交互过程中管理和存储状态信息，确保对话的连贯性和上下文理解</p></li><li><p><strong>Chains (链)</strong>：能将多个组件组合成端到端应用的核心机制，实现复杂的处理流程</p></li><li><p><strong>Agents (代理)</strong>：赋予LLM使用工具的能力，支持自主推理和行动决策</p></li></ul><p><img src="/medias/featureimages/blog/langchain-chu-ru-men/image1.png" alt="image"></p><h4 id="Prompts组件"><a href="#Prompts组件" class="headerlink" title="Prompts组件"></a>Prompts组件</h4><p><strong>概念与作用</strong>:</p><p>在LLM应用开发中,我们通常不会直接将用户输入传递给大模型,而是会将用户输入添加到一个更大的文本片段中,这个文本片段被称为Prompt。Prompt为大模型提供了任务相关的上下文和指令,帮助模型更好地理解和执行任务。</p><p>LangChain中的Prompts组件提供了一系列工具来管理和优化这些提示模板。主要包含两大类:</p><ul><li><p>PromptTemplate: 将Prompt按照template进行格式化,处理变量和组合</p></li><li><p>Selectors: 根据不同条件选择不同的提示词</p></li></ul><p><strong>基本构成</strong>:</p><p>在LangChain中,Prompts组件包含多个子组件:</p><p>角色提示模板:</p><ul><li><p>SystemMessagePromptTemplate: 系统角色消息模板</p></li><li><p>HumanMessagePromptTemplate: 人类角色消息模板</p></li><li><p>AIMessagePromptTemplate: AI角色消息模板</p></li></ul><p>提示模板类型:</p><ul><li><p>PromptTemplate: 文本提示模板</p></li><li><p>ChatPromptTemplate: 聊天消息提示模板</p></li><li><p>MessagePlaceholder: 消息占位符</p></li></ul><p><strong>关键操作</strong>:</p><p>格式化LangChain支持两种格式化方式</p><pre class="line-numbers language-language-python"><code class="language-language-python"># f-string方式prompt = PromptTemplate.from_template("请将一个关于&#123;subject&#125;的笑话")# jinja2方式prompt = PromptTemplate.from_template(    "请将一个关于&#123;&#123;subject&#125;&#125;的笑话",    template_format="jinja2")<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><p>提示模板拼接</p><pre class="line-numbers language-language-python"><code class="language-language-python"># 字符串提示拼接prompt = (    PromptTemplate.from_template("请将一个关于&#123;subject&#125;的冷笑话")    + "，让我开心下"    + "\n使用&#123;language&#125;语言。")# 聊天提示拼接system_prompt = ChatPromptTemplate.from_messages([    ("system", "你是OpenAI开发的聊天机器人，请根据用户的提问进行回复，我叫&#123;username&#125;")])human_prompt = ChatPromptTemplate.from_messages([    ("human", "&#123;query&#125;")])prompt = system_prompt + human_prompt<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><p><strong>模板复用</strong>:</p><p>对于复杂的提示模板,LangChain提供了PipelinePromptTemplate来实现模板的复用:</p><pre class="line-numbers language-language-python"><code class="language-language-python"># 描述提示模板instruction_template = "你正在模拟&#123;person&#125;。"instruction_prompt = PromptTemplate.from_template(instruction_template)# 示例提示模板example_template = """下面是一个交互例子:Q: &#123;example_q&#125;A: &#123;example_a&#125;"""example_prompt = PromptTemplate.from_template(example_template)# 开始提示模板start_template = """现在开始对话:Q: &#123;input&#125;A:"""start_prompt = PromptTemplate.from_template(start_template)# 组合模板pipeline_prompt = PipelinePromptTemplate(    final_prompt=full_prompt,    pipeline_prompts=[        ("instruction", instruction_prompt),        ("example", example_prompt),        ("start", start_prompt),    ])<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><p><strong>最佳实践</strong>:</p><p>选择合适的格式化方式</p><ol><li><p>简单变量替换使用f-string</p></li><li><p>需要条件判断等复杂逻辑时使用jinja2</p></li></ol><p>提示模板设计</p><ol><li><p>保持模板的清晰和可维护性</p></li><li><p>合理使用系统消息和示例</p></li><li><p>避免过于复杂的嵌套结构</p></li></ol><p>错误处理</p><ol><li><p>验证必要的变量是否存在</p></li><li><p>处理格式化可能出现的异常</p></li></ol><p>性能优化</p><ol><li><p>重复使用的模板要缓存</p></li><li><p>避免不必要的模板拼接操作</p></li></ol><h4 id="Model组件"><a href="#Model组件" class="headerlink" title="Model组件"></a>Model组件</h4><p><strong>基本概念</strong>:</p><p>Models是LangChain的核心组件，提供了一个标准接口来封装不同类型的LLM进行交互，LangChain本身不提供LLM,而是提供了接口来集成各种模型。</p><p>LangChain支持两种类型的模型:</p><ul><li><p>LLM: 使用纯文本作为输入和输出的大语言模型</p></li><li><p>Chat Model: 使用聊天消息列表作为输入并返回聊天消息的聊天模型</p></li></ul><p><strong>组件架构</strong>:</p><p>LangChain中Models组件的基类结构如下:</p><p>BaseLanguageModel(基类)</p><p>BaseLLM(大语言模型基类)<br>    - SimpleLLM(简化大语言模型)<br>    - 第三方LLM集成(OpenAI、百度文心等)</p><p>BaseChatModel(聊天模型基类)<br>    - SimpleChatModel(简化聊天模型)<br>    - 第三方Chat Model集成</p><h4 id="Message组件"><a href="#Message组件" class="headerlink" title="Message组件"></a>Message组件</h4><ul><li><p>SystemMessage: 系统消息</p></li><li><p>HumanMessage: 人类消息</p></li><li><p>AIMessage: AI消息</p></li><li><p>FunctionMessage: 函数调用消息</p></li><li><p>ToolMessage: 工具调用消息</p></li></ul><p><strong>核心办法</strong>:</p><p>Models组件提供了几个关键方法:</p><p>invoke&#x2F;invoke_sync: 调用模型生成内容</p><pre class="line-numbers language-language-python"><code class="language-language-python">llm = ChatOpenAI(model="gpt-3.5-turbo-16k")response = llm.invoke("你好!")# 异步调用async def generate():    response = await llm.ainvoke("你好!")    <span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><p>batch&#x2F;abatch: 批量调用处理多个输入</p><pre class="line-numbers language-language-python"><code class="language-language-python">messages = [    "请讲一个关于程序员的笑话",    "请讲一个关于Python的笑话"]responses = llm.batch(messages)<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><p>stream&#x2F;astream: 流式返回生成内容</p><pre class="line-numbers language-language-python"><code class="language-language-python">response = llm.stream("请介绍下LLM和LLMOps")for chunk in response:    print(chunk.content, end="")<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span></span></code></pre><p><strong>Message组件使用</strong>:</p><p>消息组件用于构建与聊天模型的交互:</p><pre class="line-numbers language-language-python"><code class="language-language-python">from langchain_core.messages import SystemMessage, HumanMessage, AIMessage# 创建消息system_msg = SystemMessage(content="你是一个AI助手")human_msg = HumanMessage(content="你好!")ai_msg = AIMessage(content="你好!我是AI助手")# 构建消息列表messages = [system_msg, human_msg, ai_msg]# 使用消息与模型交互response = chat_model.invoke(messages)<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><p><strong>实践示例</strong>:</p><p>基本对话示例：</p><pre class="line-numbers language-language-python"><code class="language-language-python">from langchain_openai import ChatOpenAIfrom langchain_core.prompts import ChatPromptTemplate# 创建聊天模型chat = ChatOpenAI()# 创建提示模板prompt = ChatPromptTemplate.from_messages([    ("system", "你是一位&#123;role&#125;"),    ("human", "&#123;query&#125;")])# 调用模型response = chat.invoke(    prompt.format_messages(        role="Python专家",        query="什么是装饰器?"    ))<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><p>流式输出示例：</p><pre class="line-numbers language-language-python"><code class="language-language-python">prompt = ChatPromptTemplate.from_template("&#123;subject&#125;的发展历史是什么?")# 创建模型llm = ChatOpenAI()# 流式生成response = llm.stream(    prompt.format_messages(subject="人工智能"))# 处理输出for chunk in response:    print(chunk.content, end="")<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><p><strong>最佳实践</strong>:</p><p>选择合适的模型类型</p><ol><li><p>简单文本生成任务使用LLM</p></li><li><p>对话类任务使用Chat Model</p></li></ol><p>正确处理异步操作</p><ol><li><p>在异步环境中使用ainvoke&#x2F;astream</p></li><li><p>批量处理时考虑使用batch</p></li></ol><p>异常处理</p><ol><li><p>处理模型调用可能的超时</p></li><li><p>捕获API错误并适当处理</p></li></ol><p>性能优化</p><ol><li><p>合理使用批处理</p></li><li><p>适时使用流式输出</p></li></ol><p><strong>OutputParser 解析器组件</strong>:</p><p>为什么需要输出解析器</p><p>在使用大模型时,我们经常会遇到输出解析的问题。比如:</p><pre class="line-numbers language-language-python"><code class="language-language-python">llm = ChatOpenAI()# 示例1: 返回的是自然语言llm.invoke("1+1等于几?")  # 输出: 1 + 1 等于 2。# 示例2: 包含多余信息llm.invoke("告诉我3个动物的名字。")  # 输出: 好的，这里有三种动物的名字：\n1. 狮子\n2. 大熊猫\n3. 斑马# 示例3: 格式不统一llm.invoke("给我一个json数据,键为a和b")  # 输出: &#123;\n "a": 10,\n "b": 20\n&#125;<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><p>OutputParser就是为了解决这些问题而设计的。它通过:</p><ol><li><p>预设提示 - 告诉LLM需要的输出格式</p></li><li><p>解析功能 - 将输出转换成指定格式</p></li></ol><p><strong>Parser类型详解</strong>:</p><p>Langchain 提供了多种Parser：</p><ol><li><p>基础Parser：</p><ul><li>StrOutputParser: 最简单的Parser,原样返回文本</li><li>BaseOutputParser: 所有Parser的基类</li><li>BaseLLMOutputParser: 专门用于LLM输出的基类</li></ul></li><li><p>格式化Parser：</p><ul><li>JsonOutputParser: 解析JSON格式输出</li><li>XMLOutputParser: 解析XML格式输出</li><li>PydanticOutputParser: 使用Pydantic模型解析输出</li></ul></li><li><p>列表类Parser：</p><ul><li>CommaSeparatedListOutputParser: 解析逗号分隔的列表</li><li>NumberedListOutputParser: 解析数字编号的列表</li></ul></li></ol><p><strong>实践示例</strong>:</p><ol><li>StrOutputParser使用：</li></ol><pre class="line-numbers language-language-python"><code class="language-language-python">from langchain_core.output_parsers import StrOutputParserfrom langchain_core.prompts import ChatPromptTemplatefrom langchain_openai import ChatOpenAI# 创建链chain = (    ChatPromptTemplate.from_template("&#123;query&#125;")    | ChatOpenAI()    | StrOutputParser())# 调用response = chain.invoke(&#123;"query": "你好!"&#125;)<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><p>2.JsonOutputParser使用：</p><pre class="line-numbers language-language-python"><code class="language-language-python">from langchain_core.output_parsers import JsonOutputParserfrom langchain_core.pydantic_v1 import BaseModel, Field# 定义输出结构class Joke(BaseModel):    joke: str = Field(description="回答用户的冷笑话")    punchline: str = Field(description="冷笑话的笑点")# 创建Parserparser = JsonOutputParser(pydantic_object=Joke)# 创建提示模板prompt = ChatPromptTemplate.from_template(    "回答用户的问题。\n&#123;format_instructions&#125;\n&#123;query&#125;\n")# 添加格式说明prompt = prompt.partial(format_instructions=parser.get_format_instructions())# 创建链chain = prompt | ChatOpenAI() | parser# 使用response = chain.invoke(&#123;"query": "请讲一个关于程序员的冷笑话"&#125;)<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><p><strong>错误处理</strong>:</p><p>1.解析失败的处理：</p><pre class="line-numbers language-language-python"><code class="language-language-python">from langchain_core.output_parsers import OutputParserExceptiontry:    result = parser.parse(llm_output)except OutputParserException as e:    # 处理解析错误    print(f"解析错误: &#123;e&#125;")    # 可以选择重试或使用默认值<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><p>2.使用重试机制：</p><pre class="line-numbers language-language-python"><code class="language-language-python"># 可以配置回调来处理重试from langchain_core.callbacks import BaseCallbackHandlerclass RetryHandler(BaseCallbackHandler):    def on_retry(self, retry_state):        print(f"重试次数: &#123;retry_state.attempt_number&#125;")<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><p><strong>最佳实践</strong>:</p><ol><li><p>选择合适的Parser</p><ul><li>简单文本使用StrOutputParser</li><li>结构化数据使用JsonOutputParser或PydanticOutputParser</li><li>列表数据使用专门的列表Parser</li></ul></li><li><p>提示设计</p><ul><li>在提示中明确指定输出格式</li><li>使用Parser提供的format_instructions</li></ul></li><li><p>异常处理</p><ul><li>总是处理可能的解析错误</li><li>考虑添加重试机制</li><li>提供合理的默认值</li></ul></li><li><p>性能优化</p><ul><li>避免过于复杂的解析逻辑</li><li>合理使用缓存</li></ul></li></ol><h4 id="LCEL表达式与Runnable协议"><a href="#LCEL表达式与Runnable协议" class="headerlink" title="LCEL表达式与Runnable协议"></a>LCEL表达式与Runnable协议</h4><p><strong>为什么需要LCEL</strong>:</p><p>传统的链式调用方式存在嵌套问题：</p><pre class="line-numbers language-language-python"><code class="language-language-python">content = parser.invoke(    llm.invoke(        prompt.invoke(            &#123;"query": req.query.data&#125;        )    ))<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><p>LCEL 提供了更优雅的方式：</p><pre class="line-numbers language-language-python"><code class="language-language-python">chain = prompt | llm | parsercontent = chain.invoke(&#123;"query": req.query.data&#125;)<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span></span></code></pre><p><strong>Runnable协议核心方法</strong>:</p><ul><li><p>invoke&#x2F;ainvoke: 调用组件</p></li><li><p>batch&#x2F;abatch: 批量处理</p></li><li><p>stream&#x2F;astream: 流式输出</p></li><li><p>transform: 转换输入输出</p></li></ul><p><strong>两个核心类</strong>:</p><ol><li>RunnableParallel - 并行执行多个Runnable</li></ol><pre class="line-numbers language-language-python"><code class="language-language-python">from langchain_core.runnables import RunnableParallel# 并行执行多个链chain = RunnableParallel(    joke=joke_chain,    poem=poem_chain)resp = chain.invoke(&#123;"subject": "程序员"&#125;)<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><p>2.RunnablePassthrough - 传递数据</p><pre class="line-numbers language-language-python"><code class="language-language-python">from langchain_core.runnables import RunnablePassthrough# 构建检索链chain = (    RunnablePassthrough.assign(        context=lambda query: retrieval(query)    )    | prompt     | llm     | parser)<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><p><strong>实践示例</strong>:</p><ol><li>基础链构建：</li></ol><pre class="line-numbers language-language-python"><code class="language-language-python">from langchain_core.prompts import ChatPromptTemplatefrom langchain_openai import ChatOpenAIfrom langchain_core.output_parsers import StrOutputParser# 创建组件prompt = ChatPromptTemplate.from_template("&#123;input&#125;")llm = ChatOpenAI()parser = StrOutputParser()# 构建链chain = prompt | llm | parser# 执行response = chain.invoke(&#123;"input": "Hello!"&#125;)<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><p>2.带检索的链：</p><pre class="line-numbers language-language-python"><code class="language-language-python">def retrieval(query: str) -> str:    return "相关文档内容..."# 构建链chain = (    &#123;        "context": retrieval,        "question": RunnablePassthrough()    &#125;    | prompt    | llm    | StrOutputParser())# 执行response = chain.invoke("问题")<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><p><strong>最佳实践</strong>:</p><ol><li><p>链的设计</p><ul><li>使用管道操作符(|)构建简单链</li><li>复杂逻辑使用RunnableParallel</li><li>数据传递用RunnablePassthrough</li></ul></li><li><p>错误处理</p><ul><li>合理使用try&#x2F;except</li><li>实现错误回调处理</li></ul></li><li><p>性能优化</p><ul><li>合适场景使用并行执行</li><li>批处理代替单个处理</li></ul></li><li><p>代码可维护性</p><ul><li>链结构保持清晰</li><li>适当拆分复杂链</li></ul></li></ol>]]></content>
      
      
      <categories>
          
          <category> AI </category>
          
      </categories>
      
      
        <tags>
            
            <tag> Langchain </tag>
            
            <tag> LLM </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>LangChain RAG 应用开发组件深度解析</title>
      <link href="/2025/02/09/langchain-rag-ying-yong-kai-fa-zu-jian-shen-du-jie-xi/"/>
      <url>/2025/02/09/langchain-rag-ying-yong-kai-fa-zu-jian-shen-du-jie-xi/</url>
      
        <content type="html"><![CDATA[<h2 id="前言"><a href="#前言" class="headerlink" title="前言"></a>前言</h2><p>在当今的AI应用开发中，检索增强生成(Retrieval-Augmented Generation, RAG)已经成为一种重要的技术范式。它通过将大语言模型与外部知识库结合，极大地提升了AI系统的知识获取能力和输出质量。而LangChain作为一个强大的框架，为RAG应用的开发提供了丰富的组件支持。本文将深入剖析LangChain中RAG应用开发的核心组件，帮助你更好地理解和使用这些工具。</p><h2 id="核心组件概览"><a href="#核心组件概览" class="headerlink" title="核心组件概览"></a>核心组件概览</h2><p>在开始深入学习之前,我们先来了解LangChain中RAG应用开发涉及的主要组件:</p><ol><li>Document组件与文档加载器 - 负责文档的加载和基础处理</li><li>文档转换器与分割器 - 处理文档转换和分块</li><li>VectorStore组件 - 实现向量存储和检索</li><li>Blob相关组件 - 处理二进制大对象数据</li></ol><h3 id="Document-组件与文档加载器详解"><a href="#Document-组件与文档加载器详解" class="headerlink" title="Document 组件与文档加载器详解"></a>Document 组件与文档加载器详解</h3><h4 id="Document-组件基础"><a href="#Document-组件基础" class="headerlink" title="Document 组件基础"></a>Document 组件基础</h4><p>Document 是 LangChain 的核心组件之一，它定义了一个通用的文档结构，包含两个基本要素：</p><pre class="line-numbers language-language-python"><code class="language-language-python">Document = page_content(页面内容) + metadata(元数据)<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span></span></code></pre><p>这种结构允许我们统一处理各种类型的文档，同时保留文档的元信息。</p><h4 id="文档加载器类型"><a href="#文档加载器类型" class="headerlink" title="文档加载器类型"></a>文档加载器类型</h4><p>LangChain 提供了多种文档加载器：</p><ol><li>通用文本加载器</li><li>CSV文件加载器</li><li>HTML网页加载器</li><li>PDF文档加载器</li><li>Markdown文档加载器</li></ol><p><img src="/medias/featureimages/blog/langchain-rag-ying-yong-kai-fa-zu-jian-shen-du-jie-xi/image1.png" alt="image"></p><p>每种加载器都专门处理特定类型的文档，但它们都会将文档转换成统一的Document格式。</p><pre class="line-numbers language-language-python"><code class="language-language-python">from langchain_community.document_loaders import TextLoader# 加载文本文件示例loader = TextLoader("./data.txt", encoding="utf-8")documents = loader.load()<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><h4 id="异步加载支持"><a href="#异步加载支持" class="headerlink" title="异步加载支持"></a>异步加载支持</h4><p>对于大型文档，LangChain提供了异步加载方式：</p><pre class="line-numbers language-language-python"><code class="language-language-python">async def load_documents():    async with aiofiles.open(file_path, encoding="utf-8") as f:        # 异步处理文档        yield Document(            page_content=line,            metadata=&#123;"source": file_path&#125;        )<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><h3 id="文档转换器与分割器"><a href="#文档转换器与分割器" class="headerlink" title="文档转换器与分割器"></a>文档转换器与分割器</h3><h4 id="DocumentTransformer-组件"><a href="#DocumentTransformer-组件" class="headerlink" title="DocumentTransformer 组件"></a>DocumentTransformer 组件</h4><p>文档转换器用于处理以下常见问题：</p><ol><li>文档太大导致的性能问题</li><li>原始文档格式不符合要求</li><li>文档内容需要标准化处理</li></ol><h4 id="文档转换器的工作原理"><a href="#文档转换器的工作原理" class="headerlink" title="文档转换器的工作原理"></a>文档转换器的工作原理</h4><p>DocumentTransformer组件的主要职责是对文档进行各种转换操作，包括：</p><ol><li>文档切割</li><li>文档层级提取</li><li>文档翻译</li><li>HTML标签处理</li><li>重排等多个功能</li></ol><p>在LangChain中，所有文档转换器都继承自BaseDocumentTransformer基类，它提供了两个核心方法：</p><pre class="line-numbers language-language-python"><code class="language-language-python">class BaseDocumentTransformer:    def transform_documents(self):         # 转换文档列表        pass            async def atransform_documents(self):        # 异步转换处理        pass<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><h3 id="文档分割器详解"><a href="#文档分割器详解" class="headerlink" title="文档分割器详解"></a>文档分割器详解</h3><h4 id="字符分割器（CharacterTextSplitter）"><a href="#字符分割器（CharacterTextSplitter）" class="headerlink" title="字符分割器（CharacterTextSplitter）"></a>字符分割器（CharacterTextSplitter）</h4><p>CharacterTextSplitter 是基础的分割器，它有以下重要参数：</p><ol><li><code>separator</code>: 分割符,默认为’\n\n’</li><li><code>chunk_size</code>: 每块文本的最大大小,默认4000</li><li><code>chunk_overlap</code>: 块与块之间的重叠大小,默认200</li><li><code>length_function</code>: 计算文本长度的函数,默认len</li><li><code>keep_separator</code>: 是否在分割的块中保留分隔符</li></ol><p>使用示例：</p><pre class="line-numbers language-language-python"><code class="language-language-python">from langchain_text_splitters import CharacterTextSplittertext_splitter = CharacterTextSplitter(    separator="\n\n",    chunk_size=500,    chunk_overlap=50,    add_start_index=True)# 使用分割器处理文档splits = text_splitter.split_documents(documents)<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><h4 id="实践建议"><a href="#实践建议" class="headerlink" title="实践建议"></a>实践建议</h4><p>在实际应用中，有以下几点建议：</p><ol><li>选择合适的chunk_size<ul><li>太大会影响处理效率</li><li>太小可能破坏语义完整性</li><li>建议根据实际需求在400-1000之间调整</li></ul></li><li>合理设置overlap<ul><li>设置适当的重叠可以保持上下文连贯</li><li>通常设置为chunk_size的10%-20%</li></ul></li><li>注意分隔符的选择<ul><li>根据文档类型选择合适的分隔符</li><li>可以使用多级分隔符策略</li></ul></li></ol><h3 id="VectorStore组件与检索器"><a href="#VectorStore组件与检索器" class="headerlink" title="VectorStore组件与检索器"></a>VectorStore组件与检索器</h3><h4 id="VectorStore基础概念"><a href="#VectorStore基础概念" class="headerlink" title="VectorStore基础概念"></a>VectorStore基础概念</h4><p>VectorStore组件负责：</p><ol><li>存储文档的向量表示</li><li>提供相似性检索功能</li><li>支持不同的向量检索策略</li></ol><h4 id="检索器的使用"><a href="#检索器的使用" class="headerlink" title="检索器的使用"></a>检索器的使用</h4><p>LangChain 提供了多种检索策略：</p><pre class="line-numbers language-language-python"><code class="language-language-python">from langchain import VectorStore# 基础相似性检索results = vectorstore.similarity_search(query)# 带相似度分数的检索results = vectorstore.similarity_search_with_score(query)# MMR检索策略results = vectorstore.max_marginal_relevance_search(query)<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><h3 id="VectorStore实现细节"><a href="#VectorStore实现细节" class="headerlink" title="VectorStore实现细节"></a>VectorStore实现细节</h3><h4 id="支持的向量数据库"><a href="#支持的向量数据库" class="headerlink" title="支持的向量数据库"></a>支持的向量数据库</h4><ul><li>Chroma</li><li>FAISS</li><li>Pinecone</li><li>Milvus</li></ul><h4 id="检索策略详解"><a href="#检索策略详解" class="headerlink" title="检索策略详解"></a>检索策略详解</h4><ol><li>相似度检索(Similarity Search)<ul><li>基于余弦相似度</li><li>支持Top-K检索</li></ul></li><li>MMR检索(Maximum Marginal Relevance)<ul><li>平衡相关性和多样性</li><li>可配置lambda参数调整权重</li></ul></li><li>混合检索策略<ul><li>关键词+语义检索</li><li>支持自定义评分函数</li></ul></li></ol><h3 id="Blob与BlobParser组件"><a href="#Blob与BlobParser组件" class="headerlink" title="Blob与BlobParser组件"></a>Blob与BlobParser组件</h3><h4 id="Blob方案介绍"><a href="#Blob方案介绍" class="headerlink" title="Blob方案介绍"></a>Blob方案介绍</h4><p>Blob是LangChain处理二进制数据的解决方案，它具有以下特点：</p><ol><li>支持存储字节流数据</li><li>提供统一的数据访问接口</li><li>灵活的元数据管理</li></ol><p>基本使用示例：</p><pre class="line-numbers language-language-python"><code class="language-language-python">from langchain_core.document_loaders import Blobfrom langchain_core.document_loaders.base import BaseBlobParser# 创建Blob对象blob = Blob.from_path("./data.txt")# 使用解析器parser = CustomParser()documents = list(parser.lazy_parse(blob))<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><h4 id="Blob数据存储类详解"><a href="#Blob数据存储类详解" class="headerlink" title="Blob数据存储类详解"></a>Blob数据存储类详解</h4><p>LangChain中的Blob数据存储提供了丰富的属性和方法，让我们详细了解一下：</p><p>核心属性</p><ol><li><strong>data</strong>: 原始数据，支持存储字节，字符串数据</li><li><strong>mimetype</strong>: 文件的mimetype类型</li><li><strong>encoding</strong>: 文件的编码，默认utf-8</li><li><strong>path</strong>: 文件的原始路径</li><li><strong>metadata</strong>: 存储的元数据，通常包含source字段</li></ol><p>常用方法</p><pre class="line-numbers language-language-python"><code class="language-language-python"># 字符串转换as_string(): # 将数据转换为字符串# 字节转换as_bytes(): # 将数据转换为字节数据# 字节流操作as_bytes_io(): # 将数据转换为字节流# 从路径加载from_path(): # 从文件路径加载Blob数据# 从原始数据加载from_data(): # 从原始数据加载Blob数据<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><h4 id="BlobLoader实现"><a href="#BlobLoader实现" class="headerlink" title="BlobLoader实现"></a>BlobLoader实现</h4><p>BlobLoader是一个抽象接口，用于实现二进制数据的加载。以下是一个自定义BlobLoader的示例：</p><pre class="line-numbers language-language-python"><code class="language-language-python">from langchain_core.document_loaders import Blobfrom langchain_core.document_loaders.base import BaseBlobParserclass CustomBlobLoader(ABC):    """自定义Blob加载器实现"""        @abstractmethod    def yield_blobs(        self,    ) -> Iterable[Blob]:        """加载并返回Blob数据流"""            def __init__(self, file_path: str):        self.file_path = file_path            def lazy_load(self):        """延迟加载实现"""        for blob in self.yield_blobs():            yield Document(                page_content=blob.as_string(),                metadata=&#123;"source": blob.source&#125;            )<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><h4 id="通用加载器使用最佳实践"><a href="#通用加载器使用最佳实践" class="headerlink" title="通用加载器使用最佳实践"></a>通用加载器使用最佳实践</h4><p>GenericLoader是LangChain提供的一个通用加载器，它结合了BlobLoader和BaseBlobParser的功能：</p><pre class="line-numbers language-language-python"><code class="language-language-python">from langchain_community.document_loaders.generic import GenericLoader# 创建通用加载器loader = GenericLoader.from_filesystem(    "./",  # 文件系统路径    glob="*.txt",  # 文件匹配模式    show_progress=True  # 显示进度)# 使用加载器for idx, doc in enumerate(loader.lazy_load()):    print(f"当前加载第&#123;idx + 1&#125;个文件, 文件信息:&#123;doc.metadata&#125;")<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><h4 id="性能优化建议"><a href="#性能优化建议" class="headerlink" title="性能优化建议"></a>性能优化建议</h4><ol><li>使用延迟加载<ul><li>对于大文件优先使用lazy_load()</li><li>避免一次性加载全部内容</li></ul></li><li>合理配置缓存<ul><li>利用缓存减少重复加载</li><li>及时清理不需要的缓存</li></ul></li><li>错误处理<ul><li>实现适当的错误处理机制</li><li>记录加载过程中的异常</li></ul></li><li>进度监控<ul><li>对大规模数据处理添加进度显示</li><li>实现断点续传机制</li></ul></li></ol>]]></content>
      
      
      <categories>
          
          <category> AI </category>
          
      </categories>
      
      
        <tags>
            
            <tag> Langchain </tag>
            
            <tag> RAG </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>Git 命令完整笔记</title>
      <link href="/2024/08/23/git-bi-ji/"/>
      <url>/2024/08/23/git-bi-ji/</url>
      
        <content type="html"><![CDATA[<h2 id="一、Git-配置"><a href="#一、Git-配置" class="headerlink" title="一、Git 配置"></a>一、Git 配置</h2><ol><li><p><strong>配置用户信息</strong></p><pre class="line-numbers language-language-bash"><code class="language-language-bash">git config --global user.name "Your Name"git config --global user.email "your.email@example.com"# 查看配置git config --listgit config user.name<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre></li><li><p><strong>配置别名</strong></p><pre class="line-numbers language-language-bash"><code class="language-language-bash">git config --global alias.co checkoutgit config --global alias.br branchgit config --global alias.ci commitgit config --global alias.st statusgit config --global alias.lg "log --oneline --graph --decorate"<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span></span></code></pre></li><li><p><strong>配置编辑器和工具</strong></p><pre class="line-numbers language-language-bash"><code class="language-language-bash">git config --global core.editor "vim"git config --global merge.tool vimdiffgit config --global diff.tool vimdiff<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span></span></code></pre></li></ol><h2 id="二、基础操作"><a href="#二、基础操作" class="headerlink" title="二、基础操作"></a>二、基础操作</h2><ol><li><p><strong>初始化仓库</strong></p><pre class="line-numbers language-language-bash"><code class="language-language-bash">git init                    # 在当前目录初始化git init my-project        # 创建目录并初始化<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span></span></code></pre></li><li><p><strong>克隆仓库</strong></p><pre class="line-numbers language-language-bash"><code class="language-language-bash">git clone https://github.com/user/repo.gitgit clone -b develop https://github.com/user/repo.git    # 克隆特定分支git clone --depth 1 https://github.com/user/repo.git     # 浅克隆，只克隆最新提交<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span></span></code></pre></li><li><p><strong>查看状态</strong></p><pre class="line-numbers language-language-bash"><code class="language-language-bash">git status                  # 查看工作区状态git status -s              # 简短输出<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span></span></code></pre></li><li><p><strong>添加文件到暂存区</strong></p><pre class="line-numbers language-language-bash"><code class="language-language-bash">git add file.txt           # 添加特定文件git add .                  # 添加所有更改git add *.js              # 添加所有JS文件git add -p                 # 交互式添加文件块git add -u                 # 添加已跟踪文件的更改<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span></span></code></pre></li><li><p><strong>提交更改</strong></p><pre class="line-numbers language-language-bash"><code class="language-language-bash">git commit -m "Commit message"              # 提交带消息git commit -am "Add and commit message"     # 添加并提交所有更改git commit --amend                          # 修改最后一次提交git commit --amend --no-edit                # 修改但不更改提交信息<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span></span></code></pre></li></ol><h2 id="三、远程仓库操作"><a href="#三、远程仓库操作" class="headerlink" title="三、远程仓库操作"></a>三、远程仓库操作</h2><ol><li><p><strong>设置远程仓库的URL</strong></p><pre class="line-numbers language-language-bash"><code class="language-language-bash">git remote set-url origin https://github.com/your-username/xiaohub.gitgit remote add upstream https://github.com/original/repo.git    # 添加上游仓库git remote -v                                                   # 查看远程仓库git remote show origin                                          # 查看远程仓库详情git remote rename origin old-origin                             # 重命名远程仓库git remote remove old-origin                                    # 删除远程仓库<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre></li><li><p><strong>拉取远程更改</strong></p><pre class="line-numbers language-language-bash"><code class="language-language-bash">git fetch origin           # 从远程获取最新，但不合并git pull origin master     # 拉取并合并git pull --rebase         # 拉取并变基<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span></span></code></pre></li><li><p><strong>推送更改到GitHub</strong></p><pre class="line-numbers language-language-bash"><code class="language-language-bash">git push origin master                 # 推送到远程master分支git push -u origin feature-branch      # 推送并设置上游git push origin --tags                 # 推送所有标签git push origin v1.0.0                 # 推送特定标签<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span></span></code></pre></li><li><p><strong>强制推送到远程仓库</strong></p><pre class="line-numbers language-language-bash"><code class="language-language-bash">git push origin --force --all          # 强制推送所有分支git push origin --force master         # 强制推送特定分支git push --force-with-lease           # 更安全的强制推送<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span></span></code></pre></li></ol><h2 id="四、分支管理"><a href="#四、分支管理" class="headerlink" title="四、分支管理"></a>四、分支管理</h2><ol><li><p><strong>创建和切换分支</strong></p><pre class="line-numbers language-language-bash"><code class="language-language-bash">git branch                    # 查看本地分支git branch -a                 # 查看所有分支（包括远程）git branch feature-login      # 创建新分支git checkout feature-login    # 切换分支git checkout -b feature-new   # 创建并切换分支git switch -c feature-new     # 新版本创建并切换<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre></li><li><p><strong>合并分支</strong></p><pre class="line-numbers language-language-bash"><code class="language-language-bash">git merge feature-branch      # 合并分支git merge --no-ff feature     # 禁用快进合并git merge --squash feature    # 压缩合并<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span></span></code></pre></li><li><p><strong>变基操作</strong></p><pre class="line-numbers language-language-bash"><code class="language-language-bash">git rebase master            # 变基到mastergit rebase -i HEAD~3         # 交互式变基最近3个提交git rebase --continue        # 解决冲突后继续变基git rebase --abort           # 放弃变基<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span></span></code></pre></li><li><p><strong>删除分支</strong></p><pre class="line-numbers language-language-bash"><code class="language-language-bash">git branch -d feature-branch          # 删除已合并分支git branch -D feature-branch          # 强制删除分支git push origin --delete feature      # 删除远程分支<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span></span></code></pre></li></ol><h2 id="五、文件管理"><a href="#五、文件管理" class="headerlink" title="五、文件管理"></a>五、文件管理</h2><ol><li><p><strong>从Git仓库中删除文件（可以使用 <code>-f</code>（force）选项来强制移除这些文件的跟踪）</strong></p><pre class="line-numbers language-language-bash"><code class="language-language-bash">git rm --cached <file>                # 从索引中删除，保留工作区文件git rm -r --cached <directory>        # 递归删除目录git rm file.txt                       # 删除文件（同时从工作区删除）git rm --cached -r node_modules       # 移除node_modules的跟踪<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span></span></code></pre></li><li><p><strong>移动或重命名文件</strong></p><pre class="line-numbers language-language-bash"><code class="language-language-bash">git mv oldname.txt newname.txt        # 重命名文件git mv file.txt directory/            # 移动文件<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span></span></code></pre></li><li><p><strong>.gitignore文件</strong></p><pre class="line-numbers language-language-bash"><code class="language-language-bash"># 示例.gitignore文件内容*.lognode_modules/.env.DS_Store# 清除已跟踪但现在要忽略的文件git rm -r --cached .git add .git commit -m "Update .gitignore"<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre></li></ol><h2 id="六、提交历史管理"><a href="#六、提交历史管理" class="headerlink" title="六、提交历史管理"></a>六、提交历史管理</h2><ol><li><p><strong>回滚到之前的提交</strong></p><ul><li><p><strong>使用 <code>git reset --hard HEAD^</code></strong>: 这个命令将撤销最后一次提交，并且丢弃所有的更改。请注意，这将彻底删除最后一次提交的所有更改，所以请确保你没有需要保留的其他更改。</p><pre class="line-numbers language-language-bash"><code class="language-language-bash">git reset --hard HEAD^git reset --hard HEAD~2         # 回退2个提交git reset --hard commit-hash    # 回退到特定提交<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span></span></code></pre></li><li><p><strong>使用 <code>git reset --soft HEAD^</code></strong>: 如果你想保留更改但撤销提交，可以使用这个命令。这将把所有的更改放回暂存区，你可以重新编辑并再次提交。</p><pre class="line-numbers language-language-bash"><code class="language-language-bash">git reset --soft HEAD^git reset --soft HEAD~1git reset --mixed HEAD^         # 默认选项，保留工作区更改，重置暂存区<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span></span></code></pre></li></ul></li><li><p><strong>撤销更改</strong></p><pre class="line-numbers language-language-bash"><code class="language-language-bash">git checkout -- file.txt        # 撤销工作区更改git restore file.txt            # 新版本撤销更改git clean -fd                   # 删除未跟踪的文件和目录git clean -n                    # 查看将要删除的文件<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span></span></code></pre></li><li><p><strong>回滚已推送的提交</strong></p><pre class="line-numbers language-language-bash"><code class="language-language-bash">git revert HEAD                 # 创建一个新提交来撤销最后的提交git revert commit-hash          # 撤销特定提交git revert -n HEAD~3..HEAD      # 撤销多个提交但不自动提交<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span></span></code></pre></li></ol><h2 id="七、查看日志和差异"><a href="#七、查看日志和差异" class="headerlink" title="七、查看日志和差异"></a>七、查看日志和差异</h2><ol><li><p><strong>检查Git历史记录</strong></p><pre class="line-numbers language-language-bash"><code class="language-language-bash">git log --all -- <file>              # 查看文件的所有历史git log --graph --oneline --all      # 图形化显示所有分支git log --stat                       # 显示文件修改统计git log --patch                      # 显示具体修改内容git log --author="John"              # 按作者查找提交git log --grep="fix"                 # 按提交信息查找git log --since="2 weeks ago"        # 查看最近两周的提交<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre></li><li><p><strong>查看最近的提交</strong></p><pre class="line-numbers language-language-bash"><code class="language-language-bash">git log -n 10                        # 查看最近10次提交git log --oneline -5                 # 简短格式显示最近5次提交git log --pretty=format:"%h - %an, %ar : %s"   # 自定义格式<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span></span></code></pre></li><li><p><strong>查看差异</strong></p><pre class="line-numbers language-language-bash"><code class="language-language-bash">git diff                             # 查看工作区和暂存区差异git diff --staged                    # 查看暂存区和最新提交差异git diff HEAD                        # 查看工作区和最新提交差异git diff branch1..branch2            # 比较两个分支git diff commit1 commit2             # 比较两个提交git diff --name-only                 # 只显示更改的文件名<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre></li></ol><h2 id="八、标签管理"><a href="#八、标签管理" class="headerlink" title="八、标签管理"></a>八、标签管理</h2><ol><li><p><strong>创建标签</strong></p><pre class="line-numbers language-language-bash"><code class="language-language-bash">git tag v1.0.0                       # 创建轻量标签git tag -a v1.0.0 -m "Version 1.0"   # 创建带注释的标签git tag v1.0.0 commit-hash           # 给特定提交打标签<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span></span></code></pre></li><li><p><strong>查看和管理标签</strong></p><pre class="line-numbers language-language-bash"><code class="language-language-bash">git tag                              # 列出所有标签git tag -l "v1.*"                    # 列出匹配的标签git show v1.0.0                      # 查看标签信息git tag -d v1.0.0                    # 删除本地标签git push origin --delete v1.0.0      # 删除远程标签<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span></span></code></pre></li></ol><h2 id="九、储藏和清理"><a href="#九、储藏和清理" class="headerlink" title="九、储藏和清理"></a>九、储藏和清理</h2><ol><li><p><strong>储藏工作区</strong></p><pre class="line-numbers language-language-bash"><code class="language-language-bash">git stash                            # 储藏当前更改git stash save "work in progress"    # 带描述的储藏git stash list                       # 列出所有储藏git stash pop                        # 应用并删除最新储藏git stash apply stash@&#123;2&#125;            # 应用特定储藏git stash drop stash@&#123;1&#125;             # 删除特定储藏git stash clear                      # 清空所有储藏<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre></li><li><p><strong>清理工作区</strong></p><pre class="line-numbers language-language-bash"><code class="language-language-bash">git clean -n                         # 查看将被清理的文件git clean -f                         # 清理未跟踪文件git clean -fd                        # 清理文件和目录git clean -xfd                       # 清理包括.gitignore忽略的文件<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span></span></code></pre></li></ol><h2 id="十、查找和调试"><a href="#十、查找和调试" class="headerlink" title="十、查找和调试"></a>十、查找和调试</h2><ol><li><p><strong>定位Bug引入</strong></p><pre class="line-numbers language-language-bash"><code class="language-language-bash">git bisect start                     # 开始二分查找git bisect bad                       # 标记当前提交为有buggit bisect good commit-hash          # 标记某个提交为正常git bisect reset                     # 结束查找<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span></span></code></pre></li><li><p><strong>查看文件每行最后修改</strong></p><pre class="line-numbers language-language-bash"><code class="language-language-bash">git blame file.txt                   # 查看文件每行的最后修改信息git blame -L 10,20 file.txt         # 查看特定行范围<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span></span></code></pre></li></ol><h2 id="十一、Git工作流"><a href="#十一、Git工作流" class="headerlink" title="十一、Git工作流"></a>十一、Git工作流</h2><ol><li><p><strong>特性分支工作流</strong></p><pre class="line-numbers language-language-bash"><code class="language-language-bash"># 创建特性分支git checkout -b feature/login# 开发完成后git add .git commit -m "Add login feature"# 更新主分支git checkout mastergit pull origin master# 合并特性分支git merge --no-ff feature/logingit push origin master# 删除特性分支git branch -d feature/login<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre></li><li><p><strong>GitFlow工作流</strong></p><pre class="line-numbers language-language-bash"><code class="language-language-bash"># 创建开发分支git checkout -b develop master# 创建功能分支git checkout -b feature/login develop# 完成功能分支git checkout developgit merge --no-ff feature/logingit branch -d feature/login# 创建发布分支git checkout -b release/1.0.0 develop# 完成发布git checkout mastergit merge --no-ff release/1.0.0git tag -a v1.0.0git checkout developgit merge --no-ff release/1.0.0git branch -d release/1.0.0<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre></li></ol><h2 id="十二、高级操作"><a href="#十二、高级操作" class="headerlink" title="十二、高级操作"></a>十二、高级操作</h2><ol><li><p><strong>子模块管理</strong></p><pre class="line-numbers language-language-bash"><code class="language-language-bash">git submodule add https://github.com/user/repo.git path/to/submodulegit submodule initgit submodule updategit submodule update --remotegit submodule foreach git pull origin master<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span></span></code></pre></li><li><p><strong>获取指定文件版本</strong></p><pre class="line-numbers language-language-bash"><code class="language-language-bash">git show HEAD:file.txt               # 查看最新版本文件git show branch:file.txt             # 查看特定分支文件git checkout commit-hash -- file.txt  # 恢复特定版本文件<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span></span></code></pre></li><li><p><strong>导出归档</strong></p><pre class="line-numbers language-language-bash"><code class="language-language-bash">git archive --format=zip HEAD > archive.zipgit archive --format=tar.gz --prefix=project/ v1.0.0 > project.tar.gz<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span></span></code></pre></li></ol><h2 id="十三、常见问题解决"><a href="#十三、常见问题解决" class="headerlink" title="十三、常见问题解决"></a>十三、常见问题解决</h2><ol><li><p><strong>解决合并冲突</strong></p><pre class="line-numbers language-language-bash"><code class="language-language-bash"># 出现冲突后git status                  # 查看冲突文件# 编辑冲突文件git add resolved-file.txtgit commit -m "Resolve merge conflict"<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span></span></code></pre></li><li><p><strong>修改历史提交</strong></p><pre class="line-numbers language-language-bash"><code class="language-language-bash"># 修改最近N个提交git rebase -i HEAD~3# 在编辑器中将pick改为edit, reword, squash等<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span></span></code></pre></li><li><p><strong>找回丢失的提交</strong></p><pre class="line-numbers language-language-bash"><code class="language-language-bash">git reflog                   # 查看所有操作记录git checkout commit-hash     # 恢复到特定提交<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span></span></code></pre></li></ol><h2 id="十四、Git别名和快捷命令"><a href="#十四、Git别名和快捷命令" class="headerlink" title="十四、Git别名和快捷命令"></a>十四、Git别名和快捷命令</h2><ol><li><strong>常用别名设置</strong><pre class="line-numbers language-language-bash"><code class="language-language-bash">git config --global alias.co checkoutgit config --global alias.br branchgit config --global alias.ci commitgit config --global alias.st statusgit config --global alias.unstage 'reset HEAD --'git config --global alias.last 'log -1 HEAD'git config --global alias.visual '!gitk'git config --global alias.lg "log --color --graph --pretty=format:'%Cred%h%Creset -%C(yellow)%d%Creset %s %Cgreen(%cr) %C(bold blue)<%an>%Creset' --abbrev-commit"<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre></li></ol><h2 id="十五、Git最佳实践"><a href="#十五、Git最佳实践" class="headerlink" title="十五、Git最佳实践"></a>十五、Git最佳实践</h2><ol><li><p><strong>提交信息规范</strong></p><pre class="line-numbers language-language-bash"><code class="language-language-bash"># 好的提交信息feat: 添加用户登录功能fix: 修复导航栏在移动端显示异常docs: 更新README文件style: 格式化代码refactor: 重构用户模块test: 添加用户登录单元测试chore: 更新依赖版本<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre></li><li><p><strong>保持提交原子性</strong></p><pre class="line-numbers language-language-bash"><code class="language-language-bash"># 每个提交只做一件事git add file1.jsgit commit -m "Add user validation"git add file2.jsgit commit -m "Add password encryption"<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre></li><li><p><strong>定期推送和拉取</strong></p><pre class="line-numbers language-language-bash"><code class="language-language-bash"># 每天工作开始git pull origin develop# 完成功能后git push origin feature-branch<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span></span></code></pre></li></ol>]]></content>
      
      
      <categories>
          
          <category> 笔记 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> Git </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>Linux常用命令</title>
      <link href="/2024/08/10/linux-bi-ji/"/>
      <url>/2024/08/10/linux-bi-ji/</url>
      
        <content type="html"><![CDATA[<h2 id="一、文件与目录操作"><a href="#一、文件与目录操作" class="headerlink" title="一、文件与目录操作"></a>一、文件与目录操作</h2><ol><li><p><strong>列出目录内容</strong></p><ul><li><code>ls</code>：列出当前目录</li><li><code>ls -l</code>：显示详细信息（权限、拥有者、大小、修改时间）</li><li><code>ls -a</code>：包括隐藏文件（<code>.</code> 开头）</li><li><code>ls -lh</code>：人性化显示文件大小（K, M, G）</li><li><code>ls -lt</code>：按修改时间排序，最新在前</li><li><code>ls -lS</code>：按文件大小排序，最大在前</li></ul><pre class="line-numbers language-language-bash"><code class="language-language-bash">ls -la /etc          # 列出 /etc 目录的所有文件（包括隐藏文件）ls -lh ~/Downloads   # 显示下载目录文件，以人性化方式显示大小ls -lt *.log         # 按时间排序显示所有日志文件<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span></span></code></pre></li><li><p><strong>目录切换与查看</strong></p><ul><li><code>pwd</code>：显示当前所在目录的完整路径</li><li><code>cd 目录</code>：切换目录</li><li><code>cd ..</code>：返回上级目录</li><li><code>cd -</code>：返回上次所在目录</li><li><code>cd ~</code>：切换到用户主目录</li></ul><pre class="line-numbers language-language-bash"><code class="language-language-bash">pwd                  # 显示当前工作目录cd /var/log          # 切换到系统日志目录cd ../..             # 返回上两级目录cd -                 # 快速返回上一个访问的目录cd ~/Documents       # 切换到用户文档目录<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span></span></code></pre></li><li><p><strong>复制&#x2F;移动&#x2F;删除</strong></p><ul><li><code>cp 源 目标</code>：复制文件或目录（加 <code>-r</code> 递归）</li><li><code>cp -i</code>：覆盖前询问</li><li><code>cp -p</code>：保留源文件属性（时间戳、权限等）</li><li><code>mv 源 目标</code>：移动或重命名</li><li><code>mv -i</code>：覆盖前询问</li><li><code>rm 文件</code>：删除文件；<code>rm -r 目录</code>：递归删除目录</li><li><code>rm -i</code>：删除前询问确认</li><li><code>rm -f</code>：强制删除，不询问</li></ul><pre class="line-numbers language-language-bash"><code class="language-language-bash">cp file1.txt file2.txt              # 复制文件cp -r dir1/ dir2/                   # 递归复制目录cp -ip old.conf new.conf            # 复制文件并保留属性，覆盖前询问mv oldname.txt newname.txt          # 重命名文件mv *.jpg ~/Pictures/                # 移动所有图片到目录rm -rf temp/                        # 强制删除目录及内容（慎用）<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre></li><li><p><strong>创建文件与目录</strong></p><ul><li><code>mkdir 目录名</code>：创建目录</li><li><code>mkdir -p 路径/目录</code>：创建多级目录</li><li><code>touch 文件名</code>：创建空文件或更新时间戳</li><li><code>rmdir 目录名</code>：删除空目录</li><li><code>tree</code>：以树状图显示目录结构（若未安装可 <code>sudo apt install tree</code>）</li></ul></li><li><p><strong>链接操作</strong></p><ul><li><code>ln -s 源文件 软链接</code>：创建软链接（符号链接）</li><li><code>ln 源文件 硬链接</code>：创建硬链接</li><li><code>readlink 链接</code>：查看链接指向的实际路径</li></ul><pre class="line-numbers language-language-bash"><code class="language-language-bash">ln -s /usr/bin/python3 ~/bin/python           # 创建 Python 软链接ln important.txt backup_hard_link.txt         # 创建硬链接readlink /bin/sh                              # 查看链接指向的实际文件ls -l /bin | grep '^l'                        # 查看所有符号链接<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span></span></code></pre></li><li><p><strong>查看文件内容</strong></p><ul><li><code>cat 文件</code>：一次性显示全文</li><li><code>cat -n</code>：显示行号</li><li><code>more/less 文件</code>：分页查看，<code>/ + 关键字</code> 搜索，<code>n</code> 跳到下一个匹配</li><li><code>head -n 10 文件</code>：查看前 10 行；<code>tail -n 10 文件</code>：后 10 行</li><li><code>tail -f 文件</code>：实时追踪文件新增内容，常用于日志监控</li><li><code>file 文件</code>：查看文件类型</li></ul></li></ol><hr><h2 id="二、文本处理与过滤"><a href="#二、文本处理与过滤" class="headerlink" title="二、文本处理与过滤"></a>二、文本处理与过滤</h2><ol><li><p><strong>过滤与查找</strong></p><ul><li><code>grep 模式 文件</code>：查找匹配行；<code>-i</code> 忽略大小写；<code>-n</code> 显示行号；<code>-v</code> 反向查找</li><li><code>grep -r 模式 目录</code>：递归搜索目录</li><li><code>grep -E &#39;正则表达式&#39;</code>：使用扩展正则表达式</li><li><code>egrep</code>：等同于 <code>grep -E</code></li><li><code>awk &#39;&#123;print $1,$3&#125;&#39; 文件</code>：按空格分列，打印第 1、3 列</li><li><code>cut -d&#39;:&#39; -f1 /etc/passwd</code>：以 <code>:</code> 分割，取第一列</li><li><code>sed &#39;s/old/new/g&#39; 文件</code>：替换（默认只输出到标准输出）；加 <code>-i</code> 直接修改文件</li><li><code>sed -n &#39;1,10p&#39; 文件</code>：只显示第 1-10 行</li></ul><pre class="line-numbers language-language-bash"><code class="language-language-bash">grep -n "ERROR" server.log                    # 查找错误日志，显示行号grep -r "TODO" ./src                          # 递归搜索源代码中的 TODOgrep -E '^[0-9]&#123;3&#125;-[0-9]&#123;4&#125;<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span></span></code></pre></li><li><p><strong>排序与去重</strong></p><ul><li><code>sort 文件</code>：排序；<code>sort -n</code> 数值排序；<code>-r</code> 逆序；<code>-k n</code> 指定第 n 列排序</li><li><code>uniq 文件</code>：去除相邻重复；<code>uniq -c</code> 统计次数；常与 <code>sort</code> 管道配合：<pre class="line-numbers language-language-bash"><code class="language-language-bash">sort abc.txt | uniq -c<span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre></li><li><code>comm 文件1 文件2</code>：比较两个已排序文件的异同</li></ul></li><li><p><strong>统计与比较</strong></p><ul><li><code>wc -l 文件</code>：统计行数；<code>-m</code> 字符数；<code>-c</code> 字节数；<code>-L</code> 最长行长度；<code>-w</code> 单词数</li><li><code>diff 文件1 文件2</code>：比较文件差异</li><li><code>diff -u</code>：以统一格式显示差异</li><li><code>cmp 文件1 文件2</code>：二进制比较文件</li></ul></li><li><p><strong>字符转换</strong></p><ul><li><code>tr &#39;a-z&#39; &#39;A-Z&#39; &lt; 文件</code>：小写转大写</li><li><code>tr -d &#39;0-9&#39;</code>：删除所有数字</li><li><code>tr -s &#39; &#39;</code>：压缩连续空格为单个空格</li></ul><pre class="line-numbers language-language-bash"><code class="language-language-bash">echo "hello world" | tr 'a-z' 'A-Z'          # 转换为大写: HELLO WORLDecho "user123pass456" | tr -d '0-9'          # 删除数字: userpassecho "too    many    spaces" | tr -s ' '      # 压缩空格: too many spacescat file.txt | tr '\n' ' '                    # 将换行符替换为空格<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span></span></code></pre></li></ol><hr><h2 id="三、权限与拥有者"><a href="#三、权限与拥有者" class="headerlink" title="三、权限与拥有者"></a>三、权限与拥有者</h2><ol><li><p><strong>查看权限</strong></p><ul><li><code>ls -l</code> 第一列如 <code>-rwxr-xr--</code>：分别是文件类型、用户&#x2F;组&#x2F;其他用户的读(r)&#x2F;写(w)&#x2F;执行(x) 权限</li><li><code>stat 文件</code>：查看文件详细状态信息</li></ul></li><li><p><strong>修改权限</strong></p><ul><li><code>chmod u+rw 文件</code>：用户添加读写权限；也可用数字模式，如 <code>chmod 755 文件</code></li><li><code>chmod g-w 文件</code>：组移除写权限</li><li><code>chmod o+x 文件</code>：其他用户添加执行权限</li><li><code>chmod -R 755 目录</code>：递归修改目录及子目录权限</li></ul><pre class="line-numbers language-language-bash"><code class="language-language-bash">chmod 644 file.txt                   # 设置 rw-r--r-- 权限chmod u+x script.sh                  # 给所有者添加执行权限chmod -R 755 /var/www/html          # 递归设置 web 目录权限chmod a-x sensitive.dat             # 移除所有用户的执行权限<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span></span></code></pre></li><li><p><strong>修改拥有者&#x2F;所属组</strong></p><ul><li><code>chown user:group 文件</code>：同时修改用户与组</li><li><code>chown user 文件</code> 或 <code>chown :group 文件</code></li><li><code>chown -R user:group 目录</code>：递归修改目录权限</li></ul></li><li><p><strong>特殊权限</strong></p><ul><li><code>chmod u+s 文件</code>：设置 SUID 权限</li><li><code>chmod g+s 目录</code>：设置 SGID 权限</li><li><code>chmod +t 目录</code>：设置粘滞位</li><li><code>umask</code>：查看默认权限掩码</li><li><code>umask 022</code>：设置默认权限掩码</li></ul></li><li><p><strong>文件属性</strong></p><ul><li><code>lsattr 文件</code>：查看文件特殊属性</li><li><code>chattr +i 文件</code>：设置不可修改属性</li><li><code>chattr +a 文件</code>：设置只能追加属性</li></ul><pre class="line-numbers language-language-bash"><code class="language-language-bash">chattr +i /etc/resolv.conf           # 防止文件被修改chattr +a /var/log/secure           # 只允许追加内容lsattr /etc/resolv.conf             # 查看文件属性chattr -i /etc/resolv.conf          # 移除不可修改属性<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span></span></code></pre></li></ol><hr><h2 id="四、进程与作业管理"><a href="#四、进程与作业管理" class="headerlink" title="四、进程与作业管理"></a>四、进程与作业管理</h2><ol><li><p><strong>查看进程</strong></p><ul><li><code>ps -ef</code>：列出所有进程；常与 <code>grep</code> 结合过滤</li><li><code>ps aux</code>：显示详细进程信息</li><li><code>pstree</code>：以树状图显示进程关系</li><li><code>top</code> &#x2F; <code>htop</code>：动态监控 CPU&#x2F;内存&#x2F;进程（按 q 退出）</li><li><code>pgrep 进程名</code>：按名称查找进程 ID</li></ul></li><li><p><strong>杀死进程</strong></p><ul><li><code>kill PID</code>：温和终止（发送 SIGTERM 信号）</li><li><code>kill -9 PID</code>：强制终止（发送 SIGKILL 信号）</li><li><code>kill -l</code>：列出所有信号</li><li><code>pkill 进程名</code> &#x2F; <code>killall 进程名</code>：按名杀死</li><li><code>killall -u 用户名</code>：杀死指定用户的所有进程</li></ul></li><li><p><strong>进程优先级</strong></p><ul><li><code>nice -n 10 命令</code>：以较低优先级运行命令</li><li><code>renice +10 -p PID</code>：调整运行中进程的优先级</li></ul></li><li><p><strong>后台与作业控制</strong></p><ul><li><code>command &amp;</code>：后台运行</li><li><code>jobs</code>：查看后台作业，<code>fg %1</code> 将第 1 个作业拉到前台，<code>bg %1</code> 让其后台运行</li><li><code>nohup command &amp;</code>：后台运行且忽略挂断信号（退出终端后继续运行）</li><li><code>Ctrl+Z</code>：挂起当前进程</li><li><code>Ctrl+C</code>：终止当前进程</li></ul></li></ol><hr><h2 id="五、网络与远程操作"><a href="#五、网络与远程操作" class="headerlink" title="五、网络与远程操作"></a>五、网络与远程操作</h2><ol><li><p><strong>网络诊断</strong></p><ul><li><code>ping 主机</code>：连通性测试</li><li><code>ping -c 4</code>：只发送 4 个数据包</li><li><code>traceroute 主机</code>：路由追踪</li><li><code>mtr 主机</code>：结合 ping 和 traceroute 功能</li><li><code>netstat -anp</code>：查看端口、连接；常与 <code>grep</code> 结合</li><li><code>ss -tulnp</code>：更现代的端口查看工具</li><li><code>nmap 主机</code>：端口扫描（需要安装）</li></ul></li><li><p><strong>DNS 查询</strong></p><ul><li><code>nslookup 域名</code>：查询 DNS 记录</li><li><code>dig 域名</code>：详细 DNS 查询</li><li><code>host 域名</code>：简单 DNS 查询</li></ul><pre class="line-numbers language-language-bash"><code class="language-language-bash">nslookup google.com                  # 查询域名的 IP 地址dig @8.8.8.8 example.com            # 使用指定 DNS 服务器查询dig example.com MX                   # 查询邮件服务器记录host -t AAAA ipv6.google.com        # 查询 IPv6 地址<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span></span></code></pre></li><li><p><strong>网络配置</strong></p><ul><li><code>ifconfig</code>：查看网络接口（较旧）</li><li><code>ip addr show</code>：查看 IP 地址（现代替代 ifconfig）</li><li><code>ip route show</code>：查看路由表</li><li><code>hostname</code>：显示主机名</li><li><code>hostname -I</code>：显示所有 IP 地址</li></ul><pre class="line-numbers language-language-bash"><code class="language-language-bash">ip addr show eth0                    # 显示特定网卡信息ip route add 192.168.1.0/24 via 192.168.1.1  # 添加静态路由ip link set eth0 up                  # 启用网卡ifconfig eth0 192.168.1.100         # 设置 IP 地址（旧方式）sudo hostnamectl set-hostname newname  # 修改主机名<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span></span></code></pre></li><li><p><strong>文件传输与远程登录</strong></p><ul><li><code>ssh user@host</code>：远程登录</li><li><code>ssh -p 端口 user@host</code>：指定端口登录</li><li><code>scp 本地 远端</code> &#x2F; <code>scp user@host:远端 本地</code>：安全复制</li><li><code>sftp user@host</code>：安全文件传输</li><li><code>rsync -avz 源 目标</code>：增量同步</li><li><code>rsync -avz --delete 源 目标</code>：同步并删除目标中源没有的文件</li></ul></li><li><p><strong>下载工具</strong></p><ul><li><code>wget URL</code>：下载文件</li><li><code>wget -c URL</code>：断点续传</li><li><code>curl URL</code>：发送网络请求</li><li><code>curl -O URL</code>：下载文件</li><li><code>curl -H &quot;Header: Value&quot; URL</code>：添加请求头</li></ul></li><li><p><strong>查看公网 IP</strong></p><ul><li><code>curl -4 ifconfig.co</code> 或 <code>curl ipinfo.io/ip</code></li><li><code>curl icanhazip.com</code></li></ul></li></ol><hr><h2 id="六、磁盘与存储"><a href="#六、磁盘与存储" class="headerlink" title="六、磁盘与存储"></a>六、磁盘与存储</h2><ol><li><p><strong>磁盘使用情况</strong></p><ul><li><code>df -h</code>：查看各分区总量与剩余空间</li><li><code>df -i</code>：查看 inode 使用情况</li><li><code>du -sh 目录</code>：查看目录总占用；<code>du -h --max-depth=1</code> 查看子目录分布</li><li><code>du -h | sort -h</code>：按大小排序显示</li><li><code>ncdu</code>：交互式磁盘使用分析（需要安装）</li></ul></li><li><p><strong>块设备管理</strong></p><ul><li><code>lsblk</code>：列出块设备信息</li><li><code>blkid</code>：显示块设备属性</li><li><code>fdisk -l</code>：列出磁盘分区信息</li><li><code>parted -l</code>：列出分区信息（支持 GPT）</li></ul><pre class="line-numbers language-language-bash"><code class="language-language-bash">lsblk -f                             # 显示文件系统类型blkid /dev/sda1                      # 显示分区 UUID 和类型sudo fdisk -l /dev/sda               # 查看磁盘分区表sudo parted /dev/sda print           # 显示分区信息<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span></span></code></pre></li><li><p><strong>文件系统操作</strong></p><ul><li><code>mount 设备 挂载点</code>：挂载文件系统</li><li><code>umount 设备/挂载点</code>：卸载文件系统</li><li><code>mount -o remount,rw /</code>：重新挂载为读写模式</li><li><code>fsck 设备</code>：文件系统检查和修复</li><li><code>mkfs.ext4 设备</code>：创建 ext4 文件系统</li></ul></li><li><p><strong>打包压缩</strong></p><ul><li><code>tar -czvf archive.tar.gz 目录/文件</code>：打包并 gzip 压缩</li><li><code>tar -xzvf archive.tar.gz</code>：解压</li><li><code>tar -tf archive.tar</code>：查看压缩包内容而不解压</li><li><code>zip -r archive.zip 目录</code> &#x2F; <code>unzip archive.zip</code></li><li><code>gzip 文件</code> &#x2F; <code>gunzip 文件.gz</code></li><li><code>bzip2 文件</code> &#x2F; <code>bunzip2 文件.bz2</code></li><li><code>xz 文件</code> &#x2F; <code>unxz 文件.xz</code></li></ul></li><li><p><strong>数据复制与备份</strong></p><ul><li><code>dd if=源 of=目标 bs=块大小</code>：数据复制</li><li><code>dd if=/dev/zero of=file bs=1M count=100</code>：创建100M空文件</li><li><code>cp --sparse=always 文件 目标</code>：复制稀疏文件</li></ul></li></ol><hr><h2 id="七、查找与批处理"><a href="#七、查找与批处理" class="headerlink" title="七、查找与批处理"></a>七、查找与批处理</h2><ol><li><p><strong>查找文件</strong></p><ul><li><code>find . -name &#39;*.log&#39;</code>：当前目录及子目录查找</li><li><code>find /path -type f -mtime -7</code>：查找 7 天内修改的文件</li><li><code>find . -type f -name &#39;xiaohub.log.2024-06*&#39; -delete</code>：批量删除</li><li><code>find . -size +100M</code>：查找大于 100M 的文件</li><li><code>find . -empty</code>：查找空文件或空目录</li><li><code>find . -perm 777</code>：查找权限为 777 的文件</li></ul></li><li><p><strong>快速定位</strong></p><ul><li><code>locate 文件名</code>：快速查找文件（基于数据库）</li><li><code>updatedb</code>：更新 locate 数据库</li><li><code>which 命令</code>：查找命令的完整路径</li><li><code>whereis 命令</code>：查找二进制、源代码和手册页位置</li><li><code>type 命令</code>：显示命令类型（别名、内置、外部命令）</li></ul></li><li><p><strong>批量执行</strong></p><ul><li>与 <code>find</code> + <code>-exec</code>：<pre class="line-numbers language-language-bash"><code class="language-language-bash">find . -name '*.sh' -exec chmod +x &#123;&#125; \;find /var/log -name '*.log' -exec cp &#123;&#125; &#123;&#125;.bak \;find . -type f -exec md5sum &#123;&#125; \; > checksums.txt<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span></span></code></pre></li><li><code>xargs</code>：<pre class="line-numbers language-language-bash"><code class="language-language-bash">find . -name '*.txt' | xargs grep '关键字'find . -name '*.tmp' | xargs rm -fls *.jpg | xargs -I &#123;&#125; convert &#123;&#125; &#123;&#125;.png<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span></span></code></pre></li><li><code>parallel</code>：并行执行命令（需要安装）<pre class="line-numbers language-language-bash"><code class="language-language-bash">find . -name '*.jpg' | parallel convert &#123;&#125; &#123;.&#125;.pngcat urls.txt | parallel wget &#123;&#125;seq 1 10 | parallel -j4 'echo "Process &#123;&#125;"'<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span></span></code></pre></li></ul></li></ol><hr><h2 id="八、Shell-环境与脚本"><a href="#八、Shell-环境与脚本" class="headerlink" title="八、Shell 环境与脚本"></a>八、Shell 环境与脚本</h2><ol><li><p><strong>环境变量</strong></p><ul><li><code>export VAR=value</code>：临时设置；写入 <code>~/.bashrc</code> 或 <code>~/.profile</code> 实现持久</li><li><code>echo $VAR</code>：显示变量值</li><li><code>env</code>：显示所有环境变量</li><li><code>set</code>：显示所有变量（包括局部变量）</li><li><code>unset VAR</code>：删除变量</li><li><code>source 文件</code> 或 <code>.</code>：重新加载配置</li></ul></li><li><p><strong>Shell 配置</strong></p><ul><li><code>~/.bashrc</code>：bash shell 配置文件</li><li><code>~/.bash_profile</code>：登录 shell 配置文件</li><li><code>~/.bash_history</code>：命令历史记录</li></ul></li><li><p><strong>常见提示</strong></p><ul><li><code>history</code>：查看历史命令；<code>!n</code> 重复第 n 条，<code>!!</code> 重复上一条</li><li><code>history -c</code>：清除历史记录</li><li><code>Ctrl+R</code>：反向搜索历史命令</li><li>Tab 自动补全</li><li><code>alias ll=&#39;ls -l&#39;</code>：自定义快捷命令，写入 <code>~/.bashrc</code> 生效</li><li><code>unalias 别名</code>：删除别名</li></ul></li><li><p><strong>目录操作</strong></p><ul><li><code>pushd 目录</code>：将目录压入堆栈并切换</li><li><code>popd</code>：从堆栈弹出目录并切换</li><li><code>dirs</code>：显示目录堆栈</li></ul></li><li><p><strong>脚本规范</strong></p><ul><li>首行 <code>#!/bin/bash</code> 或 <code>#!/usr/bin/env bash</code></li><li>脚本执行前加执行权限：<code>chmod +x script.sh</code></li><li>参数获取：<code>$1,$2,…</code>；循环 <code>for arg in &quot;$@&quot;; do …; done</code></li><li><code>$0</code>：脚本名称</li><li><code>$#</code>：参数个数</li><li><code>$?</code>：上个命令的退出状态</li><li><code>test</code> 或 <code>[ ]</code>：条件测试</li><li><code>[[ ]]</code>：扩展的条件测试（支持正则）</li></ul></li></ol><hr><h2 id="九、系统管理"><a href="#九、系统管理" class="headerlink" title="九、系统管理"></a>九、系统管理</h2><ol><li><p><strong>服务与日志</strong></p><ul><li><code>systemctl status 服务名</code>：查看服务状态</li><li><code>systemctl start/stop/restart 服务名</code>：启停服务</li><li><code>systemctl enable/disable 服务名</code>：开机自启设置</li><li><code>journalctl -u 服务名</code>：查看 systemd 日志</li><li><code>journalctl -f</code>：实时查看系统日志</li></ul></li><li><p><strong>定时任务</strong></p><ul><li><code>crontab -e</code>：编辑当前用户 crontab</li><li><code>crontab -l</code>：列出当前用户的定时任务</li><li>格式：<code>* * * * * command</code>（分 时 日 月 周）</li><li><code>/etc/crontab</code>：系统级定时任务</li></ul></li><li><p><strong>用户与组管理</strong></p><ul><li><code>useradd 用户名</code> &#x2F; <code>usermod -aG group 用户名</code> &#x2F; <code>userdel 用户名</code></li><li><code>passwd 用户名</code>：设置用户密码</li><li><code>groups 用户名</code>：查看用户所属组</li><li><code>id 用户名</code>：显示用户和组 ID</li><li><code>su - 用户名</code>：切换用户</li><li><code>sudo 命令</code>：以 root 权限执行命令</li></ul></li><li><p><strong>系统监控</strong></p><ul><li><code>free -h</code>：查看内存使用情况</li><li><code>uptime</code>：系统运行时间和负载</li><li><code>dmesg</code>：查看内核消息</li><li><code>lsof</code>：列出打开的文件</li><li><code>lsof -i :端口</code>：查看端口占用情况</li><li><code>vmstat</code>：虚拟内存统计</li><li><code>iostat</code>：IO 统计</li><li><code>sar</code>：系统活动报告（需要安装 sysstat）</li></ul><pre class="line-numbers language-language-bash"><code class="language-language-bash">free -h                              # 显示人性化的内存使用信息uptime                               # 显示运行时间和负载dmesg | tail -20                     # 查看最近的内核消息lsof -i :80                          # 查看 80 端口占用lsof -p 1234                         # 查看进程 1234 打开的文件vmstat 2 5                           # 每 2 秒更新一次，共 5 次iostat -x 1                          # 每秒显示详细 IO 统计sar -u 1 5                           # CPU 使用率，每秒更新，共 5 次<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre></li></ol><hr><h2 id="十、软件包管理"><a href="#十、软件包管理" class="headerlink" title="十、软件包管理"></a>十、软件包管理</h2><ol><li><p><strong>Debian&#x2F;Ubuntu（APT）</strong></p><ul><li><code>apt update</code>：更新软件包列表</li><li><code>apt upgrade</code>：升级已安装软件包</li><li><code>apt install 软件包</code>：安装软件</li><li><code>apt remove 软件包</code>：删除软件</li><li><code>apt search 关键字</code>：搜索软件包</li><li><code>apt show 软件包</code>：显示软件包信息</li><li><code>apt autoremove</code>：删除不需要的依赖包</li></ul></li><li><p><strong>RHEL&#x2F;CentOS（YUM&#x2F;DNF）</strong></p><ul><li><code>yum update</code>：更新软件包</li><li><code>yum install 软件包</code>：安装软件</li><li><code>yum remove 软件包</code>：删除软件</li><li><code>yum search 关键字</code>：搜索软件包</li><li><code>yum info 软件包</code>：显示软件包信息</li><li><code>dnf</code>：新版本的 Fedora&#x2F;RHEL 使用 dnf 替代 yum</li></ul></li><li><p><strong>常用工具安装</strong></p><ul><li><code>apt install net-tools</code>：安装传统网络工具（ifconfig 等）</li><li><code>apt install vim</code>：安装 vim 编辑器</li><li><code>apt install htop</code>：安装 htop 进程监控工具</li><li><code>apt install ncdu</code>：安装磁盘使用分析工具</li></ul></li></ol><hr><h2 id="十一、快捷键与技巧"><a href="#十一、快捷键与技巧" class="headerlink" title="十一、快捷键与技巧"></a>十一、快捷键与技巧</h2><ol><li><p><strong>终端快捷键</strong></p><ul><li><code>Ctrl+A</code>：移到行首</li><li><code>Ctrl+E</code>：移到行尾</li><li><code>Ctrl+U</code>：删除光标前的内容</li><li><code>Ctrl+K</code>：删除光标后的内容</li><li><code>Ctrl+W</code>：删除光标前的单词</li><li><code>Ctrl+L</code>：清屏（等同于 clear）</li><li><code>Ctrl+D</code>：退出当前 shell</li></ul></li><li><p><strong>命令行技巧</strong></p><ul><li><code>!!</code>：重复执行上一条命令</li><li>&#96;!## 一、文件与目录操作</li></ul></li><li><p><strong>列出目录内容</strong></p><ul><li><code>ls</code>：列出当前目录</li><li><code>ls -l</code>：显示详细信息（权限、拥有者、大小、修改时间）</li><li><code>ls -a</code>：包括隐藏文件（<code>.</code> 开头）</li><li><code>ls -lh</code>：人性化显示文件大小（K, M, G）</li><li><code>ls -lt</code>：按修改时间排序，最新在前</li><li><code>ls -lS</code>：按文件大小排序，最大在前</li></ul><pre class="line-numbers language-language-bash"><code class="language-language-bash">ls -la /etc          # 列出 /etc 目录的所有文件（包括隐藏文件）ls -lh ~/Downloads   # 显示下载目录文件，以人性化方式显示大小ls -lt *.log         # 按时间排序显示所有日志文件<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span></span></code></pre></li><li><p><strong>目录切换与查看</strong></p><ul><li><code>pwd</code>：显示当前所在目录的完整路径</li><li><code>cd 目录</code>：切换目录</li><li><code>cd ..</code>：返回上级目录</li><li><code>cd -</code>：返回上次所在目录</li><li><code>cd ~</code>：切换到用户主目录</li></ul><pre class="line-numbers language-language-bash"><code class="language-language-bash">pwd                  # 显示当前工作目录cd /var/log          # 切换到系统日志目录cd ../..             # 返回上两级目录cd -                 # 快速返回上一个访问的目录cd ~/Documents       # 切换到用户文档目录<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span></span></code></pre></li><li><p><strong>复制&#x2F;移动&#x2F;删除</strong></p><ul><li><code>cp 源 目标</code>：复制文件或目录（加 <code>-r</code> 递归）</li><li><code>cp -i</code>：覆盖前询问</li><li><code>cp -p</code>：保留源文件属性（时间戳、权限等）</li><li><code>mv 源 目标</code>：移动或重命名</li><li><code>mv -i</code>：覆盖前询问</li><li><code>rm 文件</code>：删除文件；<code>rm -r 目录</code>：递归删除目录</li><li><code>rm -i</code>：删除前询问确认</li><li><code>rm -f</code>：强制删除，不询问</li></ul><pre class="line-numbers language-language-bash"><code class="language-language-bash">cp file1.txt file2.txt              # 复制文件cp -r dir1/ dir2/                   # 递归复制目录cp -ip old.conf new.conf            # 复制文件并保留属性，覆盖前询问mv oldname.txt newname.txt          # 重命名文件mv *.jpg ~/Pictures/                # 移动所有图片到目录rm -rf temp/                        # 强制删除目录及内容（慎用）<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre></li><li><p><strong>创建文件与目录</strong></p><ul><li><code>mkdir 目录名</code>：创建目录</li><li><code>mkdir -p 路径/目录</code>：创建多级目录</li><li><code>touch 文件名</code>：创建空文件或更新时间戳</li><li><code>rmdir 目录名</code>：删除空目录</li><li><code>tree</code>：以树状图显示目录结构（若未安装可 <code>sudo apt install tree</code>）</li></ul></li><li><p><strong>链接操作</strong></p><ul><li><code>ln -s 源文件 软链接</code>：创建软链接（符号链接）</li><li><code>ln 源文件 硬链接</code>：创建硬链接</li><li><code>readlink 链接</code>：查看链接指向的实际路径</li></ul><pre class="line-numbers language-language-bash"><code class="language-language-bash">ln -s /usr/bin/python3 ~/bin/python           # 创建 Python 软链接ln important.txt backup_hard_link.txt         # 创建硬链接readlink /bin/sh                              # 查看链接指向的实际文件ls -l /bin | grep '^l'                        # 查看所有符号链接<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span></span></code></pre></li><li><p><strong>查看文件内容</strong></p><ul><li><code>cat 文件</code>：一次性显示全文</li><li><code>cat -n</code>：显示行号</li><li><code>more/less 文件</code>：分页查看，<code>/ + 关键字</code> 搜索，<code>n</code> 跳到下一个匹配</li><li><code>head -n 10 文件</code>：查看前 10 行；<code>tail -n 10 文件</code>：后 10 行</li><li><code>tail -f 文件</code>：实时追踪文件新增内容，常用于日志监控</li><li><code>file 文件</code>：查看文件类型</li></ul></li></ol><hr><h2 id="二、文本处理与过滤-1"><a href="#二、文本处理与过滤-1" class="headerlink" title="二、文本处理与过滤"></a>二、文本处理与过滤</h2><ol><li><p><strong>过滤与查找</strong></p><ul><li><code>grep 模式 文件</code>：查找匹配行；<code>-i</code> 忽略大小写；<code>-n</code> 显示行号；<code>-v</code> 反向查找</li><li><code>grep -r 模式 目录</code>：递归搜索目录</li><li><code>grep -E &#39;正则表达式&#39;</code>：使用扩展正则表达式</li><li><code>egrep</code>：等同于 <code>grep -E</code></li><li><code>awk &#39;&#123;print $1,$3&#125;&#39; 文件</code>：按空格分列，打印第 1、3 列</li><li><code>cut -d&#39;:&#39; -f1 /etc/passwd</code>：以 <code>:</code> 分割，取第一列</li><li><code>sed &#39;s/old/new/g&#39; 文件</code>：替换（默认只输出到标准输出）；加 <code>-i</code> 直接修改文件</li><li><code>sed -n &#39;1,10p&#39; 文件</code>：只显示第 1-10 行</li></ul><pre class="line-numbers language-language-bash"><code class="language-language-bash">grep -n "ERROR" server.log                    # 查找错误日志，显示行号grep -r "TODO" ./src                          # 递归搜索源代码中的 TODOgrep -E '^[0-9]&#123;3&#125;-[0-9]&#123;4&#125;<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span></span></code></pre></li><li><p><strong>排序与去重</strong></p><ul><li><code>sort 文件</code>：排序；<code>sort -n</code> 数值排序；<code>-r</code> 逆序；<code>-k n</code> 指定第 n 列排序</li><li><code>uniq 文件</code>：去除相邻重复；<code>uniq -c</code> 统计次数；常与 <code>sort</code> 管道配合：<pre class="line-numbers language-language-bash"><code class="language-language-bash">sort abc.txt | uniq -c<span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre></li><li><code>comm 文件1 文件2</code>：比较两个已排序文件的异同</li></ul></li><li><p><strong>统计与比较</strong></p><ul><li><code>wc -l 文件</code>：统计行数；<code>-m</code> 字符数；<code>-c</code> 字节数；<code>-L</code> 最长行长度；<code>-w</code> 单词数</li><li><code>diff 文件1 文件2</code>：比较文件差异</li><li><code>diff -u</code>：以统一格式显示差异</li><li><code>cmp 文件1 文件2</code>：二进制比较文件</li></ul></li><li><p><strong>字符转换</strong></p><ul><li><code>tr &#39;a-z&#39; &#39;A-Z&#39; &lt; 文件</code>：小写转大写</li><li><code>tr -d &#39;0-9&#39;</code>：删除所有数字</li><li><code>tr -s &#39; &#39;</code>：压缩连续空格为单个空格</li></ul><pre class="line-numbers language-language-bash"><code class="language-language-bash">echo "hello world" | tr 'a-z' 'A-Z'          # 转换为大写: HELLO WORLDecho "user123pass456" | tr -d '0-9'          # 删除数字: userpassecho "too    many    spaces" | tr -s ' '      # 压缩空格: too many spacescat file.txt | tr '\n' ' '                    # 将换行符替换为空格<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span></span></code></pre></li></ol><hr><h2 id="三、权限与拥有者-1"><a href="#三、权限与拥有者-1" class="headerlink" title="三、权限与拥有者"></a>三、权限与拥有者</h2><ol><li><p><strong>查看权限</strong></p><ul><li><code>ls -l</code> 第一列如 <code>-rwxr-xr--</code>：分别是文件类型、用户&#x2F;组&#x2F;其他用户的读(r)&#x2F;写(w)&#x2F;执行(x) 权限</li><li><code>stat 文件</code>：查看文件详细状态信息</li></ul></li><li><p><strong>修改权限</strong></p><ul><li><code>chmod u+rw 文件</code>：用户添加读写权限；也可用数字模式，如 <code>chmod 755 文件</code></li><li><code>chmod g-w 文件</code>：组移除写权限</li><li><code>chmod o+x 文件</code>：其他用户添加执行权限</li><li><code>chmod -R 755 目录</code>：递归修改目录及子目录权限</li></ul><pre class="line-numbers language-language-bash"><code class="language-language-bash">chmod 644 file.txt                   # 设置 rw-r--r-- 权限chmod u+x script.sh                  # 给所有者添加执行权限chmod -R 755 /var/www/html          # 递归设置 web 目录权限chmod a-x sensitive.dat             # 移除所有用户的执行权限<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span></span></code></pre></li><li><p><strong>修改拥有者&#x2F;所属组</strong></p><ul><li><code>chown user:group 文件</code>：同时修改用户与组</li><li><code>chown user 文件</code> 或 <code>chown :group 文件</code></li><li><code>chown -R user:group 目录</code>：递归修改目录权限</li></ul></li><li><p><strong>特殊权限</strong></p><ul><li><code>chmod u+s 文件</code>：设置 SUID 权限</li><li><code>chmod g+s 目录</code>：设置 SGID 权限</li><li><code>chmod +t 目录</code>：设置粘滞位</li><li><code>umask</code>：查看默认权限掩码</li><li><code>umask 022</code>：设置默认权限掩码</li></ul></li><li><p><strong>文件属性</strong></p><ul><li><code>lsattr 文件</code>：查看文件特殊属性</li><li><code>chattr +i 文件</code>：设置不可修改属性</li><li><code>chattr +a 文件</code>：设置只能追加属性</li></ul><pre class="line-numbers language-language-bash"><code class="language-language-bash">chattr +i /etc/resolv.conf           # 防止文件被修改chattr +a /var/log/secure           # 只允许追加内容lsattr /etc/resolv.conf             # 查看文件属性chattr -i /etc/resolv.conf          # 移除不可修改属性<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span></span></code></pre></li></ol><hr><h2 id="四、进程与作业管理-1"><a href="#四、进程与作业管理-1" class="headerlink" title="四、进程与作业管理"></a>四、进程与作业管理</h2><ol><li><p><strong>查看进程</strong></p><ul><li><code>ps -ef</code>：列出所有进程；常与 <code>grep</code> 结合过滤</li><li><code>ps aux</code>：显示详细进程信息</li><li><code>pstree</code>：以树状图显示进程关系</li><li><code>top</code> &#x2F; <code>htop</code>：动态监控 CPU&#x2F;内存&#x2F;进程（按 q 退出）</li><li><code>pgrep 进程名</code>：按名称查找进程 ID</li></ul></li><li><p><strong>杀死进程</strong></p><ul><li><code>kill PID</code>：温和终止（发送 SIGTERM 信号）</li><li><code>kill -9 PID</code>：强制终止（发送 SIGKILL 信号）</li><li><code>kill -l</code>：列出所有信号</li><li><code>pkill 进程名</code> &#x2F; <code>killall 进程名</code>：按名杀死</li><li><code>killall -u 用户名</code>：杀死指定用户的所有进程</li></ul></li><li><p><strong>进程优先级</strong></p><ul><li><code>nice -n 10 命令</code>：以较低优先级运行命令</li><li><code>renice +10 -p PID</code>：调整运行中进程的优先级</li></ul></li><li><p><strong>后台与作业控制</strong></p><ul><li><code>command &amp;</code>：后台运行</li><li><code>jobs</code>：查看后台作业，<code>fg %1</code> 将第 1 个作业拉到前台，<code>bg %1</code> 让其后台运行</li><li><code>nohup command &amp;</code>：后台运行且忽略挂断信号（退出终端后继续运行）</li><li><code>Ctrl+Z</code>：挂起当前进程</li><li><code>Ctrl+C</code>：终止当前进程</li></ul></li></ol><hr><h2 id="五、网络与远程操作-1"><a href="#五、网络与远程操作-1" class="headerlink" title="五、网络与远程操作"></a>五、网络与远程操作</h2><ol><li><p><strong>网络诊断</strong></p><ul><li><code>ping 主机</code>：连通性测试</li><li><code>ping -c 4</code>：只发送 4 个数据包</li><li><code>traceroute 主机</code>：路由追踪</li><li><code>mtr 主机</code>：结合 ping 和 traceroute 功能</li><li><code>netstat -anp</code>：查看端口、连接；常与 <code>grep</code> 结合</li><li><code>ss -tulnp</code>：更现代的端口查看工具</li><li><code>nmap 主机</code>：端口扫描（需要安装）</li></ul></li><li><p><strong>DNS 查询</strong></p><ul><li><code>nslookup 域名</code>：查询 DNS 记录</li><li><code>dig 域名</code>：详细 DNS 查询</li><li><code>host 域名</code>：简单 DNS 查询</li></ul><pre class="line-numbers language-language-bash"><code class="language-language-bash">nslookup google.com                  # 查询域名的 IP 地址dig @8.8.8.8 example.com            # 使用指定 DNS 服务器查询dig example.com MX                   # 查询邮件服务器记录host -t AAAA ipv6.google.com        # 查询 IPv6 地址<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span></span></code></pre></li><li><p><strong>网络配置</strong></p><ul><li><code>ifconfig</code>：查看网络接口（较旧）</li><li><code>ip addr show</code>：查看 IP 地址（现代替代 ifconfig）</li><li><code>ip route show</code>：查看路由表</li><li><code>hostname</code>：显示主机名</li><li><code>hostname -I</code>：显示所有 IP 地址</li></ul><pre class="line-numbers language-language-bash"><code class="language-language-bash">ip addr show eth0                    # 显示特定网卡信息ip route add 192.168.1.0/24 via 192.168.1.1  # 添加静态路由ip link set eth0 up                  # 启用网卡ifconfig eth0 192.168.1.100         # 设置 IP 地址（旧方式）sudo hostnamectl set-hostname newname  # 修改主机名<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span></span></code></pre></li><li><p><strong>文件传输与远程登录</strong></p><ul><li><code>ssh user@host</code>：远程登录</li><li><code>ssh -p 端口 user@host</code>：指定端口登录</li><li><code>scp 本地 远端</code> &#x2F; <code>scp user@host:远端 本地</code>：安全复制</li><li><code>sftp user@host</code>：安全文件传输</li><li><code>rsync -avz 源 目标</code>：增量同步</li><li><code>rsync -avz --delete 源 目标</code>：同步并删除目标中源没有的文件</li></ul></li><li><p><strong>下载工具</strong></p><ul><li><code>wget URL</code>：下载文件</li><li><code>wget -c URL</code>：断点续传</li><li><code>curl URL</code>：发送网络请求</li><li><code>curl -O URL</code>：下载文件</li><li><code>curl -H &quot;Header: Value&quot; URL</code>：添加请求头</li></ul></li><li><p><strong>查看公网 IP</strong></p><ul><li><code>curl -4 ifconfig.co</code> 或 <code>curl ipinfo.io/ip</code></li><li><code>curl icanhazip.com</code></li></ul></li></ol><hr><h2 id="六、磁盘与存储-1"><a href="#六、磁盘与存储-1" class="headerlink" title="六、磁盘与存储"></a>六、磁盘与存储</h2><ol><li><p><strong>磁盘使用情况</strong></p><ul><li><code>df -h</code>：查看各分区总量与剩余空间</li><li><code>df -i</code>：查看 inode 使用情况</li><li><code>du -sh 目录</code>：查看目录总占用；<code>du -h --max-depth=1</code> 查看子目录分布</li><li><code>du -h | sort -h</code>：按大小排序显示</li><li><code>ncdu</code>：交互式磁盘使用分析（需要安装）</li></ul></li><li><p><strong>块设备管理</strong></p><ul><li><code>lsblk</code>：列出块设备信息</li><li><code>blkid</code>：显示块设备属性</li><li><code>fdisk -l</code>：列出磁盘分区信息</li><li><code>parted -l</code>：列出分区信息（支持 GPT）</li></ul><pre class="line-numbers language-language-bash"><code class="language-language-bash">lsblk -f                             # 显示文件系统类型blkid /dev/sda1                      # 显示分区 UUID 和类型sudo fdisk -l /dev/sda               # 查看磁盘分区表sudo parted /dev/sda print           # 显示分区信息<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span></span></code></pre></li><li><p><strong>文件系统操作</strong></p><ul><li><code>mount 设备 挂载点</code>：挂载文件系统</li><li><code>umount 设备/挂载点</code>：卸载文件系统</li><li><code>mount -o remount,rw /</code>：重新挂载为读写模式</li><li><code>fsck 设备</code>：文件系统检查和修复</li><li><code>mkfs.ext4 设备</code>：创建 ext4 文件系统</li></ul></li><li><p><strong>打包压缩</strong></p><ul><li><code>tar -czvf archive.tar.gz 目录/文件</code>：打包并 gzip 压缩</li><li><code>tar -xzvf archive.tar.gz</code>：解压</li><li><code>tar -tf archive.tar</code>：查看压缩包内容而不解压</li><li><code>zip -r archive.zip 目录</code> &#x2F; <code>unzip archive.zip</code></li><li><code>gzip 文件</code> &#x2F; <code>gunzip 文件.gz</code></li><li><code>bzip2 文件</code> &#x2F; <code>bunzip2 文件.bz2</code></li><li><code>xz 文件</code> &#x2F; <code>unxz 文件.xz</code></li></ul></li><li><p><strong>数据复制与备份</strong></p><ul><li><code>dd if=源 of=目标 bs=块大小</code>：数据复制</li><li><code>dd if=/dev/zero of=file bs=1M count=100</code>：创建100M空文件</li><li><code>cp --sparse=always 文件 目标</code>：复制稀疏文件</li></ul></li></ol><hr><h2 id="七、查找与批处理-1"><a href="#七、查找与批处理-1" class="headerlink" title="七、查找与批处理"></a>七、查找与批处理</h2><ol><li><p><strong>查找文件</strong></p><ul><li><code>find . -name &#39;*.log&#39;</code>：当前目录及子目录查找</li><li><code>find /path -type f -mtime -7</code>：查找 7 天内修改的文件</li><li><code>find . -type f -name &#39;xiaohub.log.2024-06*&#39; -delete</code>：批量删除</li><li><code>find . -size +100M</code>：查找大于 100M 的文件</li><li><code>find . -empty</code>：查找空文件或空目录</li><li><code>find . -perm 777</code>：查找权限为 777 的文件</li></ul></li><li><p><strong>快速定位</strong></p><ul><li><code>locate 文件名</code>：快速查找文件（基于数据库）</li><li><code>updatedb</code>：更新 locate 数据库</li><li><code>which 命令</code>：查找命令的完整路径</li><li><code>whereis 命令</code>：查找二进制、源代码和手册页位置</li><li><code>type 命令</code>：显示命令类型（别名、内置、外部命令）</li></ul></li><li><p><strong>批量执行</strong></p><ul><li>与 <code>find</code> + <code>-exec</code>：<pre class="line-numbers language-language-bash"><code class="language-language-bash">find . -name '*.sh' -exec chmod +x &#123;&#125; \;find /var/log -name '*.log' -exec cp &#123;&#125; &#123;&#125;.bak \;find . -type f -exec md5sum &#123;&#125; \; > checksums.txt<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span></span></code></pre></li><li><code>xargs</code>：<pre class="line-numbers language-language-bash"><code class="language-language-bash">find . -name '*.txt' | xargs grep '关键字'find . -name '*.tmp' | xargs rm -fls *.jpg | xargs -I &#123;&#125; convert &#123;&#125; &#123;&#125;.png<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span></span></code></pre></li><li><code>parallel</code>：并行执行命令（需要安装）<pre class="line-numbers language-language-bash"><code class="language-language-bash">find . -name '*.jpg' | parallel convert &#123;&#125; &#123;.&#125;.pngcat urls.txt | parallel wget &#123;&#125;seq 1 10 | parallel -j4 'echo "Process &#123;&#125;"'<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span></span></code></pre></li></ul></li></ol><hr><h2 id="八、Shell-环境与脚本-1"><a href="#八、Shell-环境与脚本-1" class="headerlink" title="八、Shell 环境与脚本"></a>八、Shell 环境与脚本</h2><ol><li><p><strong>环境变量</strong></p><ul><li><code>export VAR=value</code>：临时设置；写入 <code>~/.bashrc</code> 或 <code>~/.profile</code> 实现持久</li><li><code>echo $VAR</code>：显示变量值</li><li><code>env</code>：显示所有环境变量</li><li><code>set</code>：显示所有变量（包括局部变量）</li><li><code>unset VAR</code>：删除变量</li><li><code>source 文件</code> 或 <code>.</code>：重新加载配置</li></ul></li><li><p><strong>Shell 配置</strong></p><ul><li><code>~/.bashrc</code>：bash shell 配置文件</li><li><code>~/.bash_profile</code>：登录 shell 配置文件</li><li><code>~/.bash_history</code>：命令历史记录</li></ul></li><li><p><strong>常见提示</strong></p><ul><li><code>history</code>：查看历史命令；<code>!n</code> 重复第 n 条，<code>!!</code> 重复上一条</li><li><code>history -c</code>：清除历史记录</li><li><code>Ctrl+R</code>：反向搜索历史命令</li><li>Tab 自动补全</li><li><code>alias ll=&#39;ls -l&#39;</code>：自定义快捷命令，写入 <code>~/.bashrc</code> 生效</li><li><code>unalias 别名</code>：删除别名</li></ul></li><li><p><strong>目录操作</strong></p><ul><li><code>pushd 目录</code>：将目录压入堆栈并切换</li><li><code>popd</code>：从堆栈弹出目录并切换</li><li><code>dirs</code>：显示目录堆栈</li></ul></li><li><p><strong>脚本规范</strong></p><ul><li>首行 <code>#!/bin/bash</code> 或 <code>#!/usr/bin/env bash</code></li><li>脚本执行前加执行权限：<code>chmod +x script.sh</code></li><li>参数获取：<code>$1,$2,…</code>；循环 <code>for arg in &quot;$@&quot;; do …; done</code></li><li><code>$0</code>：脚本名称</li><li><code>$#</code>：参数个数</li><li><code>$?</code>：上个命令的退出状态</li><li><code>test</code> 或 <code>[ ]</code>：条件测试</li><li><code>[[ ]]</code>：扩展的条件测试（支持正则）</li></ul></li></ol><hr><h2 id="九、系统管理-1"><a href="#九、系统管理-1" class="headerlink" title="九、系统管理"></a>九、系统管理</h2><ol><li><p><strong>服务与日志</strong></p><ul><li><code>systemctl status 服务名</code>：查看服务状态</li><li><code>systemctl start/stop/restart 服务名</code>：启停服务</li><li><code>systemctl enable/disable 服务名</code>：开机自启设置</li><li><code>journalctl -u 服务名</code>：查看 systemd 日志</li><li><code>journalctl -f</code>：实时查看系统日志</li></ul></li><li><p><strong>定时任务</strong></p><ul><li><code>crontab -e</code>：编辑当前用户 crontab</li><li><code>crontab -l</code>：列出当前用户的定时任务</li><li>格式：<code>* * * * * command</code>（分 时 日 月 周）</li><li><code>/etc/crontab</code>：系统级定时任务</li></ul></li><li><p><strong>用户与组管理</strong></p><ul><li><code>useradd 用户名</code> &#x2F; <code>usermod -aG group 用户名</code> &#x2F; <code>userdel 用户名</code></li><li><code>passwd 用户名</code>：设置用户密码</li><li><code>groups 用户名</code>：查看用户所属组</li><li><code>id 用户名</code>：显示用户和组 ID</li><li><code>su - 用户名</code>：切换用户</li><li><code>sudo 命令</code>：以 root 权限执行命令</li></ul></li><li><p><strong>系统监控</strong></p><ul><li><code>free -h</code>：查看内存使用情况</li><li><code>uptime</code>：系统运行时间和负载</li><li><code>dmesg</code>：查看内核消息</li><li><code>lsof</code>：列出打开的文件</li><li><code>lsof -i :端口</code>：查看端口占用情况</li><li><code>vmstat</code>：虚拟内存统计</li><li><code>iostat</code>：IO 统计</li><li><code>sar</code>：系统活动报告（需要安装 sysstat）</li></ul><pre class="line-numbers language-language-bash"><code class="language-language-bash">free -h                              # 显示人性化的内存使用信息uptime                               # 显示运行时间和负载dmesg | tail -20                     # 查看最近的内核消息lsof -i :80                          # 查看 80 端口占用lsof -p 1234                         # 查看进程 1234 打开的文件vmstat 2 5                           # 每 2 秒更新一次，共 5 次iostat -x 1                          # 每秒显示详细 IO 统计sar -u 1 5                           # CPU 使用率，每秒更新，共 5 次<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre></li></ol><hr><h2 id="十、软件包管理-1"><a href="#十、软件包管理-1" class="headerlink" title="十、软件包管理"></a>十、软件包管理</h2><ol><li><p><strong>Debian&#x2F;Ubuntu（APT）</strong></p><ul><li><code>apt update</code>：更新软件包列表</li><li><code>apt upgrade</code>：升级已安装软件包</li><li><code>apt install 软件包</code>：安装软件</li><li><code>apt remove 软件包</code>：删除软件</li><li><code>apt search 关键字</code>：搜索软件包</li><li><code>apt show 软件包</code>：显示软件包信息</li><li><code>apt autoremove</code>：删除不需要的依赖包</li></ul></li><li><p><strong>RHEL&#x2F;CentOS（YUM&#x2F;DNF）</strong></p><ul><li><code>yum update</code>：更新软件包</li><li><code>yum install 软件包</code>：安装软件</li><li><code>yum remove 软件包</code>：删除软件</li><li><code>yum search 关键字</code>：搜索软件包</li><li><code>yum info 软件包</code>：显示软件包信息</li><li><code>dnf</code>：新版本的 Fedora&#x2F;RHEL 使用 dnf 替代 yum</li></ul></li><li><p><strong>常用工具安装</strong></p><ul><li><code>apt install net-tools</code>：安装传统网络工具（ifconfig 等）</li><li><code>apt install vim</code>：安装 vim 编辑器</li><li><code>apt install htop</code>：安装 htop 进程监控工具</li><li><code>apt install ncdu</code>：安装磁盘使用分析工具</li></ul></li></ol><hr><h2 id="十一、快捷键与技巧-1"><a href="#十一、快捷键与技巧-1" class="headerlink" title="十一、快捷键与技巧"></a>十一、快捷键与技巧</h2><ol><li><strong>终端快捷键</strong><ul><li><code>Ctrl+A</code>：移到行首</li><li><code>Ctrl+E</code>：移到行尾</li><li><code>Ctrl+U</code>：删除光标前的内容</li><li><code>Ctrl+K</code>：删除光标后的内容</li><li><code>Ctrl+W</code>：删除光标前的单词</li><li><code>Ctrl+L</code>：清屏（等同于 clear）</li><li><code>Ctrl+D</code>：退出当前 shell</li></ul></li></ol><p>：引用上条命令的最后一个参数</p><ul><li><code>!*</code>：引用上条命令的所有参数</li><li><code>command1 &amp;&amp; command2</code>：前一个命令成功后才执行后一个</li><li><code>command1 || command2</code>：前一个命令失败后才执行后一个</li><li><code>command1; command2</code>：顺序执行，不管是否成功</li><li><code>$(command)</code>：命令替换</li><li><code>`command`</code>：命令替换（旧式）</li></ul><pre class="line-numbers language-language-bash"><code class="language-language-bash">sudo !!                              # 以 root 权限重新执行上条命令cd !$                                # 切换到上条命令的最后一个参数echo !*                              # 显示上条命令的所有参数mkdir test && cd test                # 创建目录并进入ping -c1 google.com || echo "网络不通"  # 网络不通时提示echo "今天是 $(date +%Y-%m-%d)"      # 命令替换显示日期for file in *.txt; do echo $file; done  # 遍历文件<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><ol start="3"><li><p><strong>通配符与正则</strong></p><ul><li><code>*</code>：匹配任意多个字符</li><li><code>?</code>：匹配单个字符</li><li><code>[abc]</code>：匹配中括号内任一字符</li><li><code>[a-z]</code>：匹配范围内任一字符</li><li><code>&#123;a,b,c&#125;</code>：匹配大括号内任一字符串</li></ul></li><li><p><strong>重定向与管道</strong></p><ul><li><code>&gt;</code>：输出重定向（覆盖）</li><li><code>&gt;&gt;</code>：输出重定向（追加）</li><li><code>2&gt;</code>：错误输出重定向</li><li><code>&amp;&gt;</code>：标准输出和错误都重定向</li><li><code>|</code>：管道，将前一个命令的输出作为后一个命令的输入</li><li><code>tee</code>：将输出同时写入文件和标准输出 phone.txt      # 正则匹配电话号码格式<br>ps aux | grep nginx | grep -v grep            # 查找 nginx 进程（排除 grep 自身）<br>awk -F: ‘{print $1,$7}’ &#x2F;etc&#x2F;passwd           # 显示用户名和 shell<br>df -h | awk ‘NR&gt;1{print $5,$6}’              # 显示磁盘使用率和挂载点<br>sed -i ‘s&#x2F;localhost&#x2F;127.0.0.1&#x2F;g’ config.ini   # 直接替换文件内容<br>sed -n ‘&#x2F;start&#x2F;,&#x2F;end&#x2F;p’ log.txt               # 显示两个标记之间的行</li></ul><pre><code></code></pre></li><li><p><strong>排序与去重</strong></p><ul><li><code>sort 文件</code>：排序；<code>sort -n</code> 数值排序；<code>-r</code> 逆序；<code>-k n</code> 指定第 n 列排序</li><li><code>uniq 文件</code>：去除相邻重复；<code>uniq -c</code> 统计次数；常与 <code>sort</code> 管道配合：<pre class="line-numbers language-language-bash"><code class="language-language-bash">sort abc.txt | uniq -c<span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre></li><li><code>comm 文件1 文件2</code>：比较两个已排序文件的异同</li></ul></li><li><p><strong>统计与比较</strong></p><ul><li><code>wc -l 文件</code>：统计行数；<code>-m</code> 字符数；<code>-c</code> 字节数；<code>-L</code> 最长行长度；<code>-w</code> 单词数</li><li><code>diff 文件1 文件2</code>：比较文件差异</li><li><code>diff -u</code>：以统一格式显示差异</li><li><code>cmp 文件1 文件2</code>：二进制比较文件</li></ul></li><li><p><strong>字符转换</strong></p><ul><li><code>tr &#39;a-z&#39; &#39;A-Z&#39; &lt; 文件</code>：小写转大写</li><li><code>tr -d &#39;0-9&#39;</code>：删除所有数字</li><li><code>tr -s &#39; &#39;</code>：压缩连续空格为单个空格</li></ul></li></ol><hr><h2 id="三、权限与拥有者-2"><a href="#三、权限与拥有者-2" class="headerlink" title="三、权限与拥有者"></a>三、权限与拥有者</h2><ol><li><p><strong>查看权限</strong></p><ul><li><code>ls -l</code> 第一列如 <code>-rwxr-xr--</code>：分别是文件类型、用户&#x2F;组&#x2F;其他用户的读(r)&#x2F;写(w)&#x2F;执行(x) 权限</li><li><code>stat 文件</code>：查看文件详细状态信息</li></ul></li><li><p><strong>修改权限</strong></p><ul><li><code>chmod u+rw 文件</code>：用户添加读写权限；也可用数字模式，如 <code>chmod 755 文件</code></li><li><code>chmod g-w 文件</code>：组移除写权限</li><li><code>chmod o+x 文件</code>：其他用户添加执行权限</li><li><code>chmod -R 755 目录</code>：递归修改目录及子目录权限</li></ul></li><li><p><strong>修改拥有者&#x2F;所属组</strong></p><ul><li><code>chown user:group 文件</code>：同时修改用户与组</li><li><code>chown user 文件</code> 或 <code>chown :group 文件</code></li><li><code>chown -R user:group 目录</code>：递归修改目录权限</li></ul></li><li><p><strong>特殊权限</strong></p><ul><li><code>chmod u+s 文件</code>：设置 SUID 权限</li><li><code>chmod g+s 目录</code>：设置 SGID 权限</li><li><code>chmod +t 目录</code>：设置粘滞位</li><li><code>umask</code>：查看默认权限掩码</li><li><code>umask 022</code>：设置默认权限掩码</li></ul></li><li><p><strong>文件属性</strong></p><ul><li><code>lsattr 文件</code>：查看文件特殊属性</li><li><code>chattr +i 文件</code>：设置不可修改属性</li><li><code>chattr +a 文件</code>：设置只能追加属性</li></ul></li></ol><hr><h2 id="四、进程与作业管理-2"><a href="#四、进程与作业管理-2" class="headerlink" title="四、进程与作业管理"></a>四、进程与作业管理</h2><ol><li><p><strong>查看进程</strong></p><ul><li><code>ps -ef</code>：列出所有进程；常与 <code>grep</code> 结合过滤</li><li><code>ps aux</code>：显示详细进程信息</li><li><code>pstree</code>：以树状图显示进程关系</li><li><code>top</code> &#x2F; <code>htop</code>：动态监控 CPU&#x2F;内存&#x2F;进程（按 q 退出）</li><li><code>pgrep 进程名</code>：按名称查找进程 ID</li></ul></li><li><p><strong>杀死进程</strong></p><ul><li><code>kill PID</code>：温和终止（发送 SIGTERM 信号）</li><li><code>kill -9 PID</code>：强制终止（发送 SIGKILL 信号）</li><li><code>kill -l</code>：列出所有信号</li><li><code>pkill 进程名</code> &#x2F; <code>killall 进程名</code>：按名杀死</li><li><code>killall -u 用户名</code>：杀死指定用户的所有进程</li></ul></li><li><p><strong>进程优先级</strong></p><ul><li><code>nice -n 10 命令</code>：以较低优先级运行命令</li><li><code>renice +10 -p PID</code>：调整运行中进程的优先级</li></ul></li><li><p><strong>后台与作业控制</strong></p><ul><li><code>command &amp;</code>：后台运行</li><li><code>jobs</code>：查看后台作业，<code>fg %1</code> 将第 1 个作业拉到前台，<code>bg %1</code> 让其后台运行</li><li><code>nohup command &amp;</code>：后台运行且忽略挂断信号（退出终端后继续运行）</li><li><code>Ctrl+Z</code>：挂起当前进程</li><li><code>Ctrl+C</code>：终止当前进程</li></ul></li></ol><hr><h2 id="五、网络与远程操作-2"><a href="#五、网络与远程操作-2" class="headerlink" title="五、网络与远程操作"></a>五、网络与远程操作</h2><ol><li><p><strong>网络诊断</strong></p><ul><li><code>ping 主机</code>：连通性测试</li><li><code>ping -c 4</code>：只发送 4 个数据包</li><li><code>traceroute 主机</code>：路由追踪</li><li><code>mtr 主机</code>：结合 ping 和 traceroute 功能</li><li><code>netstat -anp</code>：查看端口、连接；常与 <code>grep</code> 结合</li><li><code>ss -tulnp</code>：更现代的端口查看工具</li><li><code>nmap 主机</code>：端口扫描（需要安装）</li></ul></li><li><p><strong>DNS 查询</strong></p><ul><li><code>nslookup 域名</code>：查询 DNS 记录</li><li><code>dig 域名</code>：详细 DNS 查询</li><li><code>host 域名</code>：简单 DNS 查询</li></ul></li><li><p><strong>网络配置</strong></p><ul><li><code>ifconfig</code>：查看网络接口（较旧）</li><li><code>ip addr show</code>：查看 IP 地址（现代替代 ifconfig）</li><li><code>ip route show</code>：查看路由表</li><li><code>hostname</code>：显示主机名</li><li><code>hostname -I</code>：显示所有 IP 地址</li></ul></li><li><p><strong>文件传输与远程登录</strong></p><ul><li><code>ssh user@host</code>：远程登录</li><li><code>ssh -p 端口 user@host</code>：指定端口登录</li><li><code>scp 本地 远端</code> &#x2F; <code>scp user@host:远端 本地</code>：安全复制</li><li><code>sftp user@host</code>：安全文件传输</li><li><code>rsync -avz 源 目标</code>：增量同步</li><li><code>rsync -avz --delete 源 目标</code>：同步并删除目标中源没有的文件</li></ul></li><li><p><strong>下载工具</strong></p><ul><li><code>wget URL</code>：下载文件</li><li><code>wget -c URL</code>：断点续传</li><li><code>curl URL</code>：发送网络请求</li><li><code>curl -O URL</code>：下载文件</li><li><code>curl -H &quot;Header: Value&quot; URL</code>：添加请求头</li></ul></li><li><p><strong>查看公网 IP</strong></p><ul><li><code>curl -4 ifconfig.co</code> 或 <code>curl ipinfo.io/ip</code></li><li><code>curl icanhazip.com</code></li></ul></li></ol><hr><h2 id="六、磁盘与存储-2"><a href="#六、磁盘与存储-2" class="headerlink" title="六、磁盘与存储"></a>六、磁盘与存储</h2><ol><li><p><strong>磁盘使用情况</strong></p><ul><li><code>df -h</code>：查看各分区总量与剩余空间</li><li><code>df -i</code>：查看 inode 使用情况</li><li><code>du -sh 目录</code>：查看目录总占用；<code>du -h --max-depth=1</code> 查看子目录分布</li><li><code>du -h | sort -h</code>：按大小排序显示</li><li><code>ncdu</code>：交互式磁盘使用分析（需要安装）</li></ul></li><li><p><strong>块设备管理</strong></p><ul><li><code>lsblk</code>：列出块设备信息</li><li><code>blkid</code>：显示块设备属性</li><li><code>fdisk -l</code>：列出磁盘分区信息</li><li><code>parted -l</code>：列出分区信息（支持 GPT）</li></ul></li><li><p><strong>文件系统操作</strong></p><ul><li><code>mount 设备 挂载点</code>：挂载文件系统</li><li><code>umount 设备/挂载点</code>：卸载文件系统</li><li><code>mount -o remount,rw /</code>：重新挂载为读写模式</li><li><code>fsck 设备</code>：文件系统检查和修复</li><li><code>mkfs.ext4 设备</code>：创建 ext4 文件系统</li></ul></li><li><p><strong>打包压缩</strong></p><ul><li><code>tar -czvf archive.tar.gz 目录/文件</code>：打包并 gzip 压缩</li><li><code>tar -xzvf archive.tar.gz</code>：解压</li><li><code>tar -tf archive.tar</code>：查看压缩包内容而不解压</li><li><code>zip -r archive.zip 目录</code> &#x2F; <code>unzip archive.zip</code></li><li><code>gzip 文件</code> &#x2F; <code>gunzip 文件.gz</code></li><li><code>bzip2 文件</code> &#x2F; <code>bunzip2 文件.bz2</code></li><li><code>xz 文件</code> &#x2F; <code>unxz 文件.xz</code></li></ul></li><li><p><strong>数据复制与备份</strong></p><ul><li><code>dd if=源 of=目标 bs=块大小</code>：数据复制</li><li><code>dd if=/dev/zero of=file bs=1M count=100</code>：创建100M空文件</li><li><code>cp --sparse=always 文件 目标</code>：复制稀疏文件</li></ul></li></ol><hr><h2 id="七、查找与批处理-2"><a href="#七、查找与批处理-2" class="headerlink" title="七、查找与批处理"></a>七、查找与批处理</h2><ol><li><p><strong>查找文件</strong></p><ul><li><code>find . -name &#39;*.log&#39;</code>：当前目录及子目录查找</li><li><code>find /path -type f -mtime -7</code>：查找 7 天内修改的文件</li><li><code>find . -type f -name &#39;xiaohub.log.2024-06*&#39; -delete</code>：批量删除</li><li><code>find . -size +100M</code>：查找大于 100M 的文件</li><li><code>find . -empty</code>：查找空文件或空目录</li><li><code>find . -perm 777</code>：查找权限为 777 的文件</li></ul></li><li><p><strong>快速定位</strong></p><ul><li><code>locate 文件名</code>：快速查找文件（基于数据库）</li><li><code>updatedb</code>：更新 locate 数据库</li><li><code>which 命令</code>：查找命令的完整路径</li><li><code>whereis 命令</code>：查找二进制、源代码和手册页位置</li><li><code>type 命令</code>：显示命令类型（别名、内置、外部命令）</li></ul></li><li><p><strong>批量执行</strong></p><ul><li>与 <code>find</code> + <code>-exec</code>：<pre class="line-numbers language-language-bash"><code class="language-language-bash">find . -name '*.sh' -exec chmod +x &#123;&#125; \;<span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre></li><li><code>xargs</code>：<pre class="line-numbers language-language-bash"><code class="language-language-bash">find . -name '*.txt' | xargs grep '关键字'<span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre></li><li><code>parallel</code>：并行执行命令（需要安装）<pre class="line-numbers language-language-bash"><code class="language-language-bash">find . -name '*.jpg' | parallel convert &#123;&#125; &#123;.&#125;.png<span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre></li></ul></li></ol><hr><h2 id="八、Shell-环境与脚本-2"><a href="#八、Shell-环境与脚本-2" class="headerlink" title="八、Shell 环境与脚本"></a>八、Shell 环境与脚本</h2><ol><li><p><strong>环境变量</strong></p><ul><li><code>export VAR=value</code>：临时设置；写入 <code>~/.bashrc</code> 或 <code>~/.profile</code> 实现持久</li><li><code>echo $VAR</code>：显示变量值</li><li><code>env</code>：显示所有环境变量</li><li><code>set</code>：显示所有变量（包括局部变量）</li><li><code>unset VAR</code>：删除变量</li><li><code>source 文件</code> 或 <code>.</code>：重新加载配置</li></ul></li><li><p><strong>Shell 配置</strong></p><ul><li><code>~/.bashrc</code>：bash shell 配置文件</li><li><code>~/.bash_profile</code>：登录 shell 配置文件</li><li><code>~/.bash_history</code>：命令历史记录</li></ul></li><li><p><strong>常见提示</strong></p><ul><li><code>history</code>：查看历史命令；<code>!n</code> 重复第 n 条，<code>!!</code> 重复上一条</li><li><code>history -c</code>：清除历史记录</li><li><code>Ctrl+R</code>：反向搜索历史命令</li><li>Tab 自动补全</li><li><code>alias ll=&#39;ls -l&#39;</code>：自定义快捷命令，写入 <code>~/.bashrc</code> 生效</li><li><code>unalias 别名</code>：删除别名</li></ul></li><li><p><strong>目录操作</strong></p><ul><li><code>pushd 目录</code>：将目录压入堆栈并切换</li><li><code>popd</code>：从堆栈弹出目录并切换</li><li><code>dirs</code>：显示目录堆栈</li></ul></li><li><p><strong>脚本规范</strong></p><ul><li>首行 <code>#!/bin/bash</code> 或 <code>#!/usr/bin/env bash</code></li><li>脚本执行前加执行权限：<code>chmod +x script.sh</code></li><li>参数获取：<code>$1,$2,…</code>；循环 <code>for arg in &quot;$@&quot;; do …; done</code></li><li><code>$0</code>：脚本名称</li><li><code>$#</code>：参数个数</li><li><code>$?</code>：上个命令的退出状态</li><li><code>test</code> 或 <code>[ ]</code>：条件测试</li><li><code>[[ ]]</code>：扩展的条件测试（支持正则）</li></ul></li></ol><hr><h2 id="九、系统管理-2"><a href="#九、系统管理-2" class="headerlink" title="九、系统管理"></a>九、系统管理</h2><ol><li><p><strong>服务与日志</strong></p><ul><li><code>systemctl status 服务名</code>：查看服务状态</li><li><code>systemctl start/stop/restart 服务名</code>：启停服务</li><li><code>systemctl enable/disable 服务名</code>：开机自启设置</li><li><code>journalctl -u 服务名</code>：查看 systemd 日志</li><li><code>journalctl -f</code>：实时查看系统日志</li></ul></li><li><p><strong>定时任务</strong></p><ul><li><code>crontab -e</code>：编辑当前用户 crontab</li><li><code>crontab -l</code>：列出当前用户的定时任务</li><li>格式：<code>* * * * * command</code>（分 时 日 月 周）</li><li><code>/etc/crontab</code>：系统级定时任务</li></ul></li><li><p><strong>用户与组管理</strong></p><ul><li><code>useradd 用户名</code> &#x2F; <code>usermod -aG group 用户名</code> &#x2F; <code>userdel 用户名</code></li><li><code>passwd 用户名</code>：设置用户密码</li><li><code>groups 用户名</code>：查看用户所属组</li><li><code>id 用户名</code>：显示用户和组 ID</li><li><code>su - 用户名</code>：切换用户</li><li><code>sudo 命令</code>：以 root 权限执行命令</li></ul></li><li><p><strong>系统监控</strong></p><ul><li><code>free -h</code>：查看内存使用情况</li><li><code>uptime</code>：系统运行时间和负载</li><li><code>dmesg</code>：查看内核消息</li><li><code>lsof</code>：列出打开的文件</li><li><code>lsof -i :端口</code>：查看端口占用情况</li><li><code>vmstat</code>：虚拟内存统计</li><li><code>iostat</code>：IO 统计</li><li><code>sar</code>：系统活动报告（需要安装 sysstat）</li></ul></li></ol><hr><h2 id="十、软件包管理-2"><a href="#十、软件包管理-2" class="headerlink" title="十、软件包管理"></a>十、软件包管理</h2><ol><li><p><strong>Debian&#x2F;Ubuntu（APT）</strong></p><ul><li><code>apt update</code>：更新软件包列表</li><li><code>apt upgrade</code>：升级已安装软件包</li><li><code>apt install 软件包</code>：安装软件</li><li><code>apt remove 软件包</code>：删除软件</li><li><code>apt search 关键字</code>：搜索软件包</li><li><code>apt show 软件包</code>：显示软件包信息</li><li><code>apt autoremove</code>：删除不需要的依赖包</li></ul></li><li><p><strong>RHEL&#x2F;CentOS（YUM&#x2F;DNF）</strong></p><ul><li><code>yum update</code>：更新软件包</li><li><code>yum install 软件包</code>：安装软件</li><li><code>yum remove 软件包</code>：删除软件</li><li><code>yum search 关键字</code>：搜索软件包</li><li><code>yum info 软件包</code>：显示软件包信息</li><li><code>dnf</code>：新版本的 Fedora&#x2F;RHEL 使用 dnf 替代 yum</li></ul></li><li><p><strong>常用工具安装</strong></p><ul><li><code>apt install net-tools</code>：安装传统网络工具（ifconfig 等）</li><li><code>apt install vim</code>：安装 vim 编辑器</li><li><code>apt install htop</code>：安装 htop 进程监控工具</li><li><code>apt install ncdu</code>：安装磁盘使用分析工具</li></ul></li></ol><hr><h2 id="十一、快捷键与技巧-2"><a href="#十一、快捷键与技巧-2" class="headerlink" title="十一、快捷键与技巧"></a>十一、快捷键与技巧</h2><ol><li><p><strong>终端快捷键</strong></p><ul><li><code>Ctrl+A</code>：移到行首</li><li><code>Ctrl+E</code>：移到行尾</li><li><code>Ctrl+U</code>：删除光标前的内容</li><li><code>Ctrl+K</code>：删除光标后的内容</li><li><code>Ctrl+W</code>：删除光标前的单词</li><li><code>Ctrl+L</code>：清屏（等同于 clear）</li><li><code>Ctrl+D</code>：退出当前 shell</li></ul></li><li><p><strong>命令行技巧</strong></p><ul><li><code>!!</code>：重复执行上一条命令</li><li><code>!$</code>：引用上条命令的最后一个参数</li><li><code>!*</code>：引用上条命令的所有参数</li><li><code>command1 &amp;&amp; command2</code>：前一个命令成功后才执行后一个</li><li><code>command1 || command2</code>：前一个命令失败后才执行后一个</li><li><code>command1; command2</code>：顺序执行，不管是否成功</li><li><code>$(command)</code>：命令替换</li><li><code>`command`</code>：命令替换（旧式）</li></ul></li><li><p><strong>通配符与正则</strong></p><ul><li><code>*</code>：匹配任意多个字符</li><li><code>?</code>：匹配单个字符</li><li><code>[abc]</code>：匹配中括号内任一字符</li><li><code>[a-z]</code>：匹配范围内任一字符</li><li><code>&#123;a,b,c&#125;</code>：匹配大括号内任一字符串</li></ul></li><li><p><strong>重定向与管道</strong></p><ul><li><code>&gt;</code>：输出重定向（覆盖）</li><li><code>&gt;&gt;</code>：输出重定向（追加）</li><li><code>2&gt;</code>：错误输出重定向</li><li><code>&amp;&gt;</code>：标准输出和错误都重定向</li><li><code>|</code>：管道，将前一个命令的输出作为后一个命令的输入</li><li><code>tee</code>：将输出同时写入文件和标准输出</li></ul></li></ol>]]></content>
      
      
      <categories>
          
          <category> 笔记 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> Linux </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>Docker 命令完整笔记</title>
      <link href="/2024/07/15/docker-bi-ji/"/>
      <url>/2024/07/15/docker-bi-ji/</url>
      
        <content type="html"><![CDATA[<h2 id="一、Docker-基础配置"><a href="#一、Docker-基础配置" class="headerlink" title="一、Docker 基础配置"></a>一、Docker 基础配置</h2><ol><li><p><strong>安装后配置</strong></p><pre class="line-numbers language-language-bash"><code class="language-language-bash"># 将当前用户添加到docker组（避免每次使用sudo）sudo usermod -aG docker $USER# 配置Docker开机自启sudo systemctl enable dockersudo systemctl start docker# 查看Docker版本docker versiondocker info<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre></li><li><p><strong>配置镜像加速器</strong></p><pre class="line-numbers language-language-bash"><code class="language-language-bash"># 编辑Docker配置文件sudo vim /etc/docker/daemon.json# 添加镜像加速器配置&#123;  "registry-mirrors": [    "https://docker.m.daocloud.io",    "https://dockerproxy.com",    "https://docker.mirrors.ustc.edu.cn",    "https://docker.nju.edu.cn",    "https://iju9kaj2.mirror.aliyuncs.com",    "http://hub-mirror.c.163.com",    "https://cr.console.aliyun.com",    "https://hub.docker.com",    "http://mirrors.ustc.edu.cn"  ]&#125;# 重启Docker服务sudo systemctl daemon-reloadsudo systemctl restart docker<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre></li></ol><h2 id="二、镜像管理"><a href="#二、镜像管理" class="headerlink" title="二、镜像管理"></a>二、镜像管理</h2><ol><li><p><strong>搜索和拉取镜像</strong></p><pre class="line-numbers language-language-bash"><code class="language-language-bash">docker search nginx                 # 搜索镜像docker pull nginx                   # 拉取最新版本docker pull nginx:1.21              # 拉取指定版本docker pull ubuntu:20.04            # 拉取Ubuntu 20.04<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span></span></code></pre></li><li><p><strong>查看本地镜像</strong></p><pre class="line-numbers language-language-bash"><code class="language-language-bash">docker images                       # 列出本地镜像docker images -a                    # 显示所有镜像（包括中间层）docker images nginx                 # 查看特定镜像docker images --format "&#123;&#123;.ID&#125;&#125;: &#123;&#123;.Repository&#125;&#125;"  # 自定义格式输出<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span></span></code></pre></li><li><p><strong>镜像详细信息</strong></p><pre class="line-numbers language-language-bash"><code class="language-language-bash">docker inspect nginx                # 查看镜像详细信息docker history nginx                # 查看镜像历史docker image prune                  # 清理未使用的镜像docker rmi nginx:1.21               # 删除指定镜像docker rmi $(docker images -q)      # 删除所有镜像<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span></span></code></pre></li><li><p><strong>保存和加载镜像</strong></p><pre class="line-numbers language-language-bash"><code class="language-language-bash">docker save -o nginx.tar nginx:latest     # 保存镜像到tar文件docker load -i nginx.tar                  # 从tar文件加载镜像docker save nginx:latest | gzip > nginx.tar.gz  # 压缩保存<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span></span></code></pre></li><li><p><strong>构建镜像</strong></p><pre class="line-numbers language-language-bash"><code class="language-language-bash">docker build -t myapp:1.0 .              # 从Dockerfile构建docker build -t myapp:1.0 -f Dockerfile.dev .  # 指定Dockerfiledocker build --no-cache -t myapp:1.0 .   # 不使用缓存构建<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span></span></code></pre></li></ol><h2 id="三、容器管理"><a href="#三、容器管理" class="headerlink" title="三、容器管理"></a>三、容器管理</h2><ol><li><p><strong>运行容器</strong></p><pre class="line-numbers language-language-bash"><code class="language-language-bash">docker run nginx                    # 运行nginx容器docker run -d nginx                 # 后台运行docker run -p 8080:80 nginx         # 端口映射docker run --name mynginx nginx     # 指定容器名称docker run -it ubuntu bash          # 交互式运行docker run -e MYSQL_ROOT_PASSWORD=123456 mysql  # 设置环境变量docker run -v /host/data:/container/data nginx  # 挂载数据卷docker run --rm nginx               # 容器退出后自动删除<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre></li><li><p><strong>查看容器</strong></p><pre class="line-numbers language-language-bash"><code class="language-language-bash">docker ps                           # 查看运行中的容器docker ps -a                        # 查看所有容器docker ps -q                        # 只显示容器IDdocker ps --format "table &#123;&#123;.ID&#125;&#125;\t&#123;&#123;.Names&#125;&#125;\t&#123;&#123;.Status&#125;&#125;"<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span></span></code></pre></li><li><p><strong>容器操作</strong></p><pre class="line-numbers language-language-bash"><code class="language-language-bash">docker start container_id           # 启动容器docker stop container_id            # 停止容器docker restart container_id         # 重启容器docker pause container_id           # 暂停容器docker unpause container_id         # 恢复容器docker rm container_id              # 删除容器docker rm -f container_id           # 强制删除运行中的容器docker container prune              # 清理停止的容器<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre></li><li><p><strong>容器交互</strong></p><pre class="line-numbers language-language-bash"><code class="language-language-bash">docker exec -it container_id bash   # 进入运行中的容器docker exec container_id ls /app    # 在容器中执行命令docker attach container_id          # 附加到容器docker cp file.txt container_id:/app/  # 复制文件到容器docker cp container_id:/app/file.txt ./  # 从容器复制文件<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span></span></code></pre></li><li><p><strong>查看容器信息</strong></p><pre class="line-numbers language-language-bash"><code class="language-language-bash">docker logs container_id            # 查看容器日志docker logs -f container_id         # 实时查看日志docker logs --tail 100 container_id # 查看最后100行docker top container_id             # 查看容器进程docker stats                        # 查看容器资源使用docker inspect container_id         # 查看容器详细信息<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre></li></ol><h2 id="四、网络管理"><a href="#四、网络管理" class="headerlink" title="四、网络管理"></a>四、网络管理</h2><ol><li><p><strong>网络操作</strong></p><pre class="line-numbers language-language-bash"><code class="language-language-bash">docker network ls                   # 列出网络docker network create mynet         # 创建网络docker network inspect bridge       # 查看网络详情docker network rm mynet             # 删除网络<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span></span></code></pre></li><li><p><strong>容器网络</strong></p><pre class="line-numbers language-language-bash"><code class="language-language-bash">docker run --network=mynet nginx    # 指定网络运行容器docker network connect mynet container_id    # 连接容器到网络docker network disconnect mynet container_id  # 断开连接<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span></span></code></pre></li><li><p><strong>端口映射</strong></p><pre class="line-numbers language-language-bash"><code class="language-language-bash">docker run -p 8080:80 nginx         # 映射端口8080到容器80docker run -p 127.0.0.1:8080:80 nginx  # 只绑定本地地址docker run -P nginx                 # 随机映射端口docker port container_id            # 查看端口映射<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span></span></code></pre></li></ol><h2 id="五、数据卷管理"><a href="#五、数据卷管理" class="headerlink" title="五、数据卷管理"></a>五、数据卷管理</h2><ol><li><p><strong>创建和管理数据卷</strong></p><pre class="line-numbers language-language-bash"><code class="language-language-bash">docker volume create mydata         # 创建数据卷docker volume ls                    # 列出数据卷docker volume inspect mydata        # 查看数据卷详情docker volume rm mydata             # 删除数据卷docker volume prune                 # 清理未使用的数据卷<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span></span></code></pre></li><li><p><strong>使用数据卷</strong></p><pre class="line-numbers language-language-bash"><code class="language-language-bash">docker run -v mydata:/app nginx     # 挂载命名数据卷docker run -v /host/path:/container/path nginx  # 挂载主机目录docker run --mount source=mydata,target=/app nginx  # 使用--mountdocker run -v $(pwd):/app nginx     # 挂载当前目录<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span></span></code></pre></li></ol><h2 id="六、Docker-Compose"><a href="#六、Docker-Compose" class="headerlink" title="六、Docker Compose"></a>六、Docker Compose</h2><ol><li><p><strong>基本命令</strong></p><pre class="line-numbers language-language-bash"><code class="language-language-bash">docker-compose up                   # 启动服务docker-compose up -d                # 后台启动docker-compose down                 # 停止并删除容器docker-compose ps                   # 查看服务状态docker-compose logs                 # 查看日志docker-compose logs -f service_name # 查看特定服务日志<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre></li><li><p><strong>服务管理</strong></p><pre class="line-numbers language-language-bash"><code class="language-language-bash">docker-compose start                # 启动服务docker-compose stop                 # 停止服务docker-compose restart              # 重启服务docker-compose build                # 构建服务docker-compose pull                 # 拉取服务镜像<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span></span></code></pre></li><li><p><strong>docker-compose.yml示例</strong></p><pre class="line-numbers language-language-yaml"><code class="language-language-yaml">version: '3'services:  web:    image: nginx:latest    ports:      - "80:80"    volumes:      - ./html:/usr/share/nginx/html    networks:      - webnet    db:    image: mysql:5.7    environment:      MYSQL_ROOT_PASSWORD: password    volumes:      - db_data:/var/lib/mysql    networks:      - webnetvolumes:  db_data:networks:  webnet:<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre></li></ol><h2 id="七、Dockerfile编写"><a href="#七、Dockerfile编写" class="headerlink" title="七、Dockerfile编写"></a>七、Dockerfile编写</h2><ol><li><p><strong>基础指令</strong></p><pre class="line-numbers language-language-dockerfile"><code class="language-language-dockerfile"># 基础镜像FROM node:14-alpine# 维护者信息LABEL maintainer="name@example.com"# 设置工作目录WORKDIR /app# 复制文件COPY package*.json ./COPY . .# 运行命令RUN npm install# 环境变量ENV NODE_ENV=productionENV PORT=3000# 暴露端口EXPOSE 3000# 启动命令CMD ["npm", "start"]<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre></li><li><p><strong>多阶段构建</strong></p><pre class="line-numbers language-language-dockerfile"><code class="language-language-dockerfile"># 构建阶段FROM node:14 AS builderWORKDIR /appCOPY package*.json ./RUN npm installCOPY . .RUN npm run build# 生产阶段FROM nginx:alpineCOPY --from=builder /app/dist /usr/share/nginx/htmlEXPOSE 80CMD ["nginx", "-g", "daemon off;"]<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre></li><li><p><strong>最佳实践</strong></p><pre class="line-numbers language-language-dockerfile"><code class="language-language-dockerfile"># 使用特定版本的基础镜像FROM node:14.17.0-alpine# 使用非root用户RUN addgroup -S appgroup && adduser -S appuser -G appgroupUSER appuser# 利用构建缓存COPY package*.json ./RUN npm installCOPY . .# 减少层数RUN apt-get update && apt-get install -y \    package1 \    package2 \    && rm -rf /var/lib/apt/lists/*<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre></li></ol><h2 id="八、镜像仓库操作"><a href="#八、镜像仓库操作" class="headerlink" title="八、镜像仓库操作"></a>八、镜像仓库操作</h2><ol><li><p><strong>登录和推送</strong></p><pre class="line-numbers language-language-bash"><code class="language-language-bash">docker login                        # 登录Docker Hubdocker login registry.example.com   # 登录私有仓库docker tag myapp:1.0 username/myapp:1.0  # 标记镜像docker push username/myapp:1.0      # 推送镜像<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span></span></code></pre></li><li><p><strong>私有仓库</strong></p><pre class="line-numbers language-language-bash"><code class="language-language-bash"># 运行私有仓库docker run -d -p 5000:5000 --name registry registry:2# 标记并推送到私有仓库docker tag myapp:1.0 localhost:5000/myapp:1.0docker push localhost:5000/myapp:1.0# 从私有仓库拉取docker pull localhost:5000/myapp:1.0<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre></li></ol><h2 id="九、容器资源限制"><a href="#九、容器资源限制" class="headerlink" title="九、容器资源限制"></a>九、容器资源限制</h2><ol><li><p><strong>CPU限制</strong></p><pre class="line-numbers language-language-bash"><code class="language-language-bash">docker run --cpus=2 nginx           # 限制使用2个CPUdocker run --cpu-shares=512 nginx   # CPU共享权重docker run --cpuset-cpus="0,1" nginx  # 指定CPU核心<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span></span></code></pre></li><li><p><strong>内存限制</strong></p><pre class="line-numbers language-language-bash"><code class="language-language-bash">docker run -m 512m nginx            # 限制内存512MBdocker run --memory-swap=1g nginx   # 限制总内存(含swap)docker run --oom-kill-disable nginx # 禁用OOM killer<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span></span></code></pre></li><li><p><strong>其他资源限制</strong></p><pre class="line-numbers language-language-bash"><code class="language-language-bash">docker run --device-read-bps /dev/sda:1mb nginx  # 限制磁盘读取速度docker run --device-write-bps /dev/sda:1mb nginx # 限制磁盘写入速度docker run --pids-limit 100 nginx   # 限制进程数<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span></span></code></pre></li></ol><h2 id="十、Docker健康检查"><a href="#十、Docker健康检查" class="headerlink" title="十、Docker健康检查"></a>十、Docker健康检查</h2><ol><li><p><strong>Dockerfile中定义</strong></p><pre class="line-numbers language-language-dockerfile"><code class="language-language-dockerfile">HEALTHCHECK --interval=30s --timeout=3s \  CMD curl -f http://localhost/ || exit 1<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span></span></code></pre></li><li><p><strong>运行时指定</strong></p><pre class="line-numbers language-language-bash"><code class="language-language-bash">docker run -d --health-cmd="curl -f http://localhost/ || exit 1" \           --health-interval=30s \           --health-timeout=3s \           --health-retries=3 \           nginx<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span></span></code></pre></li><li><p><strong>查看健康状态</strong></p><pre class="line-numbers language-language-bash"><code class="language-language-bash">docker inspect --format='&#123;&#123;.State.Health.Status&#125;&#125;' container_iddocker ps --filter health=healthy<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span></span></code></pre></li></ol><h2 id="十一、日志管理"><a href="#十一、日志管理" class="headerlink" title="十一、日志管理"></a>十一、日志管理</h2><ol><li><p><strong>日志驱动配置</strong></p><pre class="line-numbers language-language-bash"><code class="language-language-bash"># 配置JSON文件日志驱动docker run --log-driver=json-file \           --log-opt max-size=10m \           --log-opt max-file=3 \           nginx# 配置syslog日志驱动docker run --log-driver=syslog \           --log-opt syslog-address=tcp://192.168.0.42:123 \           nginx<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre></li><li><p><strong>查看日志</strong></p><pre class="line-numbers language-language-bash"><code class="language-language-bash">docker logs container_id            # 查看容器日志docker logs -f --tail 100 container_id  # 实时查看最后100行docker logs --since 30m container_id    # 查看最近30分钟的日志<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span></span></code></pre></li></ol><h2 id="十二、清理和维护"><a href="#十二、清理和维护" class="headerlink" title="十二、清理和维护"></a>十二、清理和维护</h2><ol><li><p><strong>系统清理</strong></p><pre class="line-numbers language-language-bash"><code class="language-language-bash">docker system df                    # 查看Docker磁盘使用docker system prune                 # 清理未使用的数据docker system prune -a              # 清理所有未使用的数据docker system prune --volumes       # 同时清理数据卷<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span></span></code></pre></li><li><p><strong>资源清理</strong></p><pre class="line-numbers language-language-bash"><code class="language-language-bash">docker container prune              # 清理停止的容器docker image prune                  # 清理未使用的镜像docker volume prune                 # 清理未使用的数据卷docker network prune                # 清理未使用的网络<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span></span></code></pre></li></ol><h2 id="十三、故障排查"><a href="#十三、故障排查" class="headerlink" title="十三、故障排查"></a>十三、故障排查</h2><ol><li><p><strong>容器调试</strong></p><pre class="line-numbers language-language-bash"><code class="language-language-bash">docker logs container_id            # 查看容器日志docker inspect container_id         # 查看容器详细信息docker exec -it container_id sh     # 进入容器shelldocker diff container_id            # 查看容器文件变化docker events                       # 查看Docker事件<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span></span></code></pre></li><li><p><strong>网络调试</strong></p><pre class="line-numbers language-language-bash"><code class="language-language-bash">docker network inspect bridge       # 查看网络详情docker exec container_id ping other_container  # 测试容器间连通性docker exec container_id nslookup other_container  # DNS解析测试<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span></span></code></pre></li><li><p><strong>性能分析</strong></p><pre class="line-numbers language-language-bash"><code class="language-language-bash">docker stats                        # 实时查看资源使用docker top container_id             # 查看容器进程docker inspect -f '&#123;&#123;.State.Pid&#125;&#125;' container_id  # 获取容器PID<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span></span></code></pre></li></ol><h2 id="十四、安全最佳实践"><a href="#十四、安全最佳实践" class="headerlink" title="十四、安全最佳实践"></a>十四、安全最佳实践</h2><ol><li><p><strong>运行时安全</strong></p><pre class="line-numbers language-language-bash"><code class="language-language-bash"># 以只读模式运行容器docker run --read-only nginx# 限制容器capabilitiesdocker run --cap-drop=ALL --cap-add=NET_BIND_SERVICE nginx# 使用非root用户运行docker run --user=1000:1000 nginx<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre></li><li><p><strong>镜像安全</strong></p><pre class="line-numbers language-language-bash"><code class="language-language-bash"># 扫描镜像漏洞docker scan nginx:latest# 使用官方镜像或可信来源docker pull docker.io/library/nginx:latest# 签名验证docker trust inspect nginx:latest<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre></li></ol><h2 id="十五、常用技巧和别名"><a href="#十五、常用技巧和别名" class="headerlink" title="十五、常用技巧和别名"></a>十五、常用技巧和别名</h2><ol><li><p><strong>实用别名</strong></p><pre class="line-numbers language-language-bash"><code class="language-language-bash"># 添加到~/.bashrc或~/.zshrcalias dps='docker ps'alias dpsa='docker ps -a'alias di='docker images'alias drm='docker rm $(docker ps -aq)'alias drmi='docker rmi $(docker images -q)'alias dex='docker exec -it'alias dlog='docker logs -f'<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre></li><li><p><strong>常用组合命令</strong></p><pre class="line-numbers language-language-bash"><code class="language-language-bash"># 停止所有容器docker stop $(docker ps -aq)# 删除所有停止的容器docker rm $(docker ps -aq -f status=exited)# 删除所有未打标签的镜像docker rmi $(docker images -f "dangling=true" -q)# 查看容器IP地址docker inspect -f '&#123;&#123;range .NetworkSettings.Networks&#125;&#125;&#123;&#123;.IPAddress&#125;&#125;&#123;&#123;end&#125;&#125;' container_id# 导出容器文件系统docker export container_id > container.tar<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre></li></ol><h2 id="十六、Docker-Swarm集群管理"><a href="#十六、Docker-Swarm集群管理" class="headerlink" title="十六、Docker Swarm集群管理"></a>十六、Docker Swarm集群管理</h2><ol><li><p><strong>初始化和加入集群</strong></p><pre class="line-numbers language-language-bash"><code class="language-language-bash"># 初始化Swarm集群docker swarm init --advertise-addr 192.168.1.100# 获取加入tokendocker swarm join-token workerdocker swarm join-token manager# 加入集群docker swarm join --token SWMTKN-1-xxx 192.168.1.100:2377<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre></li><li><p><strong>服务管理</strong></p><pre class="line-numbers language-language-bash"><code class="language-language-bash"># 创建服务docker service create --name web --replicas 3 -p 80:80 nginx# 扩展服务docker service scale web=5# 更新服务docker service update --image nginx:1.21 web# 查看服务docker service lsdocker service ps web<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre></li></ol><h2 id="十七、实际应用示例"><a href="#十七、实际应用示例" class="headerlink" title="十七、实际应用示例"></a>十七、实际应用示例</h2><ol><li><p><strong>Web应用部署</strong></p><pre class="line-numbers language-language-bash"><code class="language-language-bash"># 创建网络docker network create webapp-net# 运行数据库docker run -d \  --name db \  --network webapp-net \  -e MYSQL_ROOT_PASSWORD=secret \  -e MYSQL_DATABASE=webapp \  -v mysql-data:/var/lib/mysql \  mysql:5.7# 运行Web应用docker run -d \  --name webapp \  --network webapp-net \  -p 8080:80 \  -e DB_HOST=db \  -e DB_USER=root \  -e DB_PASSWORD=secret \  -e DB_NAME=webapp \  webapp:latest<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre></li><li><p><strong>开发环境搭建</strong></p><pre class="line-numbers language-language-yaml"><code class="language-language-yaml"># docker-compose.ymlversion: '3'services:  frontend:    build: ./frontend    volumes:      - ./frontend:/app      - /app/node_modules    ports:      - "3000:3000"    command: npm start    backend:    build: ./backend    volumes:      - ./backend:/app    ports:      - "5000:5000"    environment:      - NODE_ENV=development    depends_on:      - db    db:    image: postgres:13    volumes:      - pgdata:/var/lib/postgresql/data    environment:      - POSTGRES_PASSWORD=secret      - POSTGRES_DB=myappvolumes:  pgdata:<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre></li><li><p><strong>CI&#x2F;CD集成</strong></p><pre class="line-numbers language-language-bash"><code class="language-language-bash"># Jenkinsfile示例pipeline &#123;  agent &#123; docker &#123; image 'node:14' &#125; &#125;  stages &#123;    stage('Build') &#123;      steps &#123;        sh 'npm install'        sh 'npm run build'      &#125;    &#125;    stage('Test') &#123;      steps &#123;        sh 'npm test'      &#125;    &#125;    stage('Docker Build') &#123;      steps &#123;        sh 'docker build -t myapp:$&#123;BUILD_NUMBER&#125; .'      &#125;    &#125;    stage('Deploy') &#123;      steps &#123;        sh 'docker push myapp:$&#123;BUILD_NUMBER&#125;'      &#125;    &#125;  &#125;&#125;<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre></li></ol>]]></content>
      
      
      <categories>
          
          <category> 笔记 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> Docker </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>Redis基础巩固</title>
      <link href="/2024/05/04/redis/"/>
      <url>/2024/05/04/redis/</url>
      
        <content type="html"><![CDATA[<h2 id="Redis-是什么"><a href="#Redis-是什么" class="headerlink" title="Redis 是什么"></a>Redis 是什么</h2><p>Redis 是一种高性能、基于内存的开源键值存储数据库系统，它主要用于<code>缓存</code>、<code>会话管理</code>和<code>实时分析</code>等用途。</p><h3 id="关键特点"><a href="#关键特点" class="headerlink" title="关键特点"></a>关键特点</h3><ol><li><strong>键值存储</strong>：Redis 以键值对的形式存储数据。每个键都是一个唯一的标识符，与一个值相关联。</li><li><strong>基于内存存储</strong>：Redis 所有的数据存储在内存中，这意味着它提供极高的读写速度，使得它非常适合用作缓存层，能够快速响应读取请求。</li><li><strong>持久性</strong>：Redis 支持数据持久性，可以将数据保存到磁盘上，以便在重启后恢复数据。</li><li><strong>多数据结构支持</strong>：Redis 支持各种数据结构，包括如字符串（string）、列表（list）、集合（set）、有序集合（sorted set）、哈希表（hash）、位图（bitmap）、超日志（hyperloglog）和地理空间索引（geospatial index）。等。这些数据结构可以用于不同的应用场景。</li><li><strong>发布-订阅模式</strong>：Redis 支持发布-订阅消息模式，允许客户端订阅特定的频道，从而实现高效的消息通信。这对于实现实时通信和事件驱动应用程序非常有用。</li><li><strong>事务</strong>：Redis 支持事务，可以一次执行多个命令，并保证这些命令在执行期间不会受到其他客户端的干扰。</li><li><strong>分布式和高可用性</strong>：通过使用哨兵（Sentinel）和集群，Redis 可以提供高可用性。哨兵用于监控 Redis 服务器的健康状况并自动执行故障转移。集群则提供数据分片和自动分区，以支持更大规模的数据存储。</li><li><strong>分片</strong>：Redis 支持数据分片，可以水平扩展存储容量和吞吐量。</li><li><strong>Lua脚本</strong>：Redis 允许使用 Lua 脚本执行高级操作，使得在服务器端可以进行复杂的逻辑，减少网络往返次数。</li><li><strong>社区支持</strong>：Redis 社区活跃，提供了许多扩展和插件，使其适用于各种不同的用例。</li></ol><h3 id="数据类型"><a href="#数据类型" class="headerlink" title="数据类型"></a>数据类型</h3><ol><li>字符串（String）<ul><li><strong>结构</strong>：字符串是Redis最基本的数据类型。Redis中的字符串是二进制安全的，这意味着它们可以包含任何数据，比如JPEG图像或序列化对象。</li><li><strong>实现</strong>：字符串使用简单的<strong>动态字符串</strong>（SDS，Simple Dynamic String）实现，允许快速追加操作，与Java中的<code>StringBuffer</code>或<code>StringBuilder</code>类似，都支持动态修改，如追加、修改等操作，而不需要每次操作都创建一个新的字符串实例。</li></ul></li><li>列表（List）<ul><li><strong>结构</strong>：列表是字符串元素的集合，按插入顺序排序。</li><li><strong>实现</strong>：Redis列表用双向链表或压缩列表（ziplist）实现。较小的列表通常使用压缩列表以节省空间，而较大的列表则使用双向链表。</li></ul></li><li>集合（Set）<ul><li><strong>结构</strong>：集合是无序的字符串集合，每个元素都是唯一的。</li><li><strong>实现</strong>：小的集合使用压缩列表（ziplist）实现，较大的集合使用散列（hash table）实现。</li></ul></li><li>有序集合（Sorted Set）<ul><li><strong>结构</strong>：有序集合类似于集合，但每个元素都关联一个分数。这些元素按分数有序排列。</li><li><strong>实现</strong>：有序集合通过跳跃表（skiplist）和散列结构组合实现。跳跃表用于按分数排序和范围查询，而散列用于快速访问。</li></ul></li><li>哈希（Hash）<ul><li><strong>结构</strong>：哈希是键值对的集合，类似于Java中的HashMap或Python中的字典。</li><li><strong>实现</strong>：小的哈希使用压缩列表实现，大的哈希使用散列结构。</li></ul></li><li>位图（Bitmap）<ul><li><strong>结构</strong>：位图不是独立的数据类型，而是在字符串上操作单个位（binary digit）。</li><li><strong>实现</strong>：通过对字符串类型的特殊操作实现，允许设置和查询字符串值的特定位。</li></ul></li><li>HyperLogLog<ul><li><strong>结构</strong>：用于高效地执行基数计数（比如计算一个集合中不同元素的数量）。</li><li><strong>实现</strong>：使用近似算法，牺牲了精度以换取极高的空间效率。</li></ul></li><li>地理空间索引（Geospatial）<ul><li><strong>结构</strong>：用于存储地理位置信息，并进行各种地理相关的计算，如两点之间的距离。</li><li><strong>实现</strong>：基于有序集合，利用Z-order曲线在一维值中编码二维经纬度。</li></ul></li></ol><h3 id="应用场景"><a href="#应用场景" class="headerlink" title="应用场景"></a>应用场景</h3><ol><li><p>缓存系统</p><p>：</p><ul><li><strong>场景</strong>：减少数据库的负载，加速数据检索。</li><li><strong>实现</strong>：将经常查询的数据，如用户信息、商品详情等存储在 Redis 中。当数据被请求时，首先查询 Redis，如果找不到，再查询数据库，并将结果存回 Redis。</li></ul></li><li><p>会话存储（Session Store）</p><p>：</p><ul><li><strong>场景</strong>：用于 Web 应用的用户会话管理。</li><li><strong>实现</strong>：将用户的会话信息存储在 Redis 中，由于 Redis 的读写速度快，可以快速处理大量并发的会话数据。</li></ul></li><li><p>消息队列</p><p>：</p><ul><li><strong>场景</strong>：应用程序之间的消息传递和异步处理。</li><li><strong>实现</strong>：使用 Redis 的发布&#x2F;订阅功能或列表结构实现消息队列，支持生产者-消费者模型，实现数据的异步处理。</li></ul></li><li><p>排行榜&#x2F;计数器</p><p>：</p><ul><li><strong>场景</strong>：用于实现社交网络、游戏等应用的排行榜功能。</li><li><strong>实现</strong>：利用 Redis 的有序集合（sorted set），可以快速添加、更新和获取排行榜数据。</li></ul></li><li><p>实时分析</p><p>：</p><ul><li><strong>场景</strong>：网站的实时访问数据统计。</li><li><strong>实现</strong>：使用Redis的计数器功能，例如HyperLogLog来估计唯一访问者数量。</li></ul></li><li><p>地理空间数据处理</p><p>：</p><ul><li><strong>场景</strong>：例如实现基于位置的服务，如查找附近的商店或用户。</li><li><strong>实现</strong>：使用Redis的地理空间索引功能，可以存储地理位置信息，并进行范围查询和距离计算。</li></ul></li><li><p>分布式锁</p><p>：</p><ul><li><strong>场景</strong>：在分布式系统中同步不同进程或服务器之间的操作。</li><li><strong>实现</strong>：通过Redis的SETNX命令实现锁的机制，确保同一时间只有一个进程能执行特定的代码段。</li></ul></li><li><p>数据过期处理</p><p>：</p><ul><li><strong>场景</strong>：自动删除过期的数据，如临时令牌或验证码。</li><li><strong>实现</strong>：利用Redis的键过期功能，可以为存储的数据设置生存时间。</li></ul></li></ol><h3 id="持久化机制"><a href="#持久化机制" class="headerlink" title="持久化机制"></a>持久化机制</h3><p>Redis 支持两种持久化机制，分别是RDB（Redis Database）和 AOF（Append Only File）。这两种机制可以单独使用，也可以同时使用，以便在不同的场景下平衡性能和数据安全性。</p><h3 id="RDB（默认持久化机制）"><a href="#RDB（默认持久化机制）" class="headerlink" title="RDB（默认持久化机制）"></a>RDB（默认持久化机制）</h3><ul><li><p><strong>介绍</strong>：</p><p>RDB 持久化是通过<strong>创建数据集</strong>的快照来实现的。</p></li><li><p><strong>工作原理</strong>：</p><ul><li>在指定的时间间隔内，Redis自动创建当前数据的快照，并将其保存在一个紧凑的二进制文件中（默认为 <code>dump.rdb</code>）。Redis 在默认情况下只有一个 dump.rdb 文件，意味着每次创建新的RDB快照时，都会覆盖现有的<code>dump.rdb</code>文件。</li><li>这个 dump.rdb 就是当前redis的备份快照数据。这个RDB就是在redis启动的时候，它发现有这个rdb，就会载入到内存中，也就是恢复数据。需要注意的是，redis启动的时候，如果rdb文件很大，那么会堵塞，直到数据全部恢复到内存里。</li><li>快照的创建可以通过自动或手动触发。自动触发基于配置的时间间隔和数据变化的次数。</li><li>RDB 是每隔一段时间做备份的机制。如果因为服务器宕机死机重启，那么内存中的数据就没了，但是他会从rdb中进行恢复。</li></ul></li><li><p><strong>优点</strong>：</p><ul><li><strong>高效性能</strong>：RDB是一个非常高效的方式来保存大量数据的快照。</li><li><strong>灾难恢复</strong>：由于RDB文件是压缩的二进制文件，适用于需要<code>定期备份数据</code>的情况，非常适合灾难恢复。</li></ul></li><li><p><strong>缺点</strong>：</p><ul><li><strong>数据丢失风险</strong>：如果Redis崩溃，自上次快照以来的所有数据都可能丢失。</li><li><strong>性能开销</strong>：在大数据集的情况下，保存快照可能会对性能产生短暂的影响。</li></ul><p>在 RDB 持久性机制下，Redis 确实提供了两种快照（snapshot）保存方式：<code>SAVE</code> 和 <code>BFSAVE</code>。这两种命令都用于生成当前 Redis 数据库状态的快照，但它们在执行方式上有显著的不同。</p></li></ul><ol><li>SAVE<ul><li><strong>执行方式</strong>：<code>SAVE</code>命令会创建一个快照并将其保存在磁盘上，但这个过程是同步进行的。这意味着在 <code>SAVE</code>命令执行期间，Redis将停止处理其他命令。</li><li><strong>使用场景</strong>：由于<code>SAVE</code>会堵塞所有其他客户端请求，它通常不推荐在生产环境中使用。它更适用于低流量的时段或维护期间，例如，当需要确保数据完全同步到磁盘时。</li></ul></li><li>BGSAVE<ul><li><strong>执行方式</strong>：<code>BGSAVE</code>命令会在后台创建一个快照。具体来说，Redis会先创建一个子进程，然后子进程负责将快照写入磁盘，而父进程（即原始的Redis服务器进程）可以继续处理客户端请求。</li><li><strong>使用场景</strong>：由于<code>BGSAVE</code>不会堵塞主服务进程，它更适合生产环境中使用，尤其是在需要定期快照但又不希望影响服务性能的场合。</li></ul></li></ol><h3 id="AOF"><a href="#AOF" class="headerlink" title="AOF"></a>AOF</h3><ul><li><p><strong>介绍</strong>：</p><p>AOF（Append-Only File）是一种将Redis操作命令以追加方式写入日志文件的机制，是追加式备份。它以文本格式记录Redis的写操作（新增、修改、删除），都会记录在这个AOF日志里。</p><p>需要注意的是，redis是先执行写操作指令，随后再把指令追加进AOF文件中。</p></li><li><p><strong>工作原理</strong>：</p><ul><li>每个写操作命令都会追加到AOF文件的末尾。</li><li>类似于记录日志，把所有的写操作追加到文件。追加的形式是append，逐个命令追加，不是修改。<ul><li>比如说 <code>set key1 abc</code>, <code>set key1 123</code>，虽然两次设置key1的值，但不会合并，而是追加命令。</li><li>redis恢复的时候先恢复AOF，如果AOF有问题（比如破损），则再恢复RDB。</li><li>redis恢复的时候是读取AOF中的命令，从头到尾读一遍，然后数据恢复。</li></ul></li><li>Redis启动时，通过重新执行这些命令来重建原始数据。</li><li>AOF 是通过Redis主线程执行的，因此每个写操作都会导致磁盘I&#x2F;O，当然这是为了确保数据的持久性。</li></ul></li><li><p><strong>优点</strong>：</p><ul><li><strong>数据完整性</strong>：与RDB相比，AOF可以提供更好的数据完整性和安全性。</li><li><strong>易于阅读</strong>：AOF文件以文本格式存储，易于阅读和维护。</li><li><strong>灵活性</strong>：提供多种同步策略，如<code>每秒同步</code>、<code>每修改同步</code>等。</li></ul></li><li><p><strong>缺点</strong>：</p><ul><li><strong>文件大小</strong>：AOF文件可能会比RDB文件大很多，因为它保存了所有的写操作。</li><li><strong>性能开销</strong>：特别是在每次修改同步的配置下，可能会对写入性能产生影响。</li></ul></li></ul><p><strong>重写机制</strong>：</p><p>AOF 的重写机制是Redis用来优化AOF文件大小和性能的重要机制。随着操作的不断累积，AOF文件可能会变得非常大，包含许多已经不再需要的命令。<strong>AOF重写机制就会创建一个新的AOF文件，其中包含了与当前数据库相同的数据，但是采用更紧凑的格式，通常比原始AOF文件要小得多。这有助于减少AOF文件的大小，提高Redis性能，以及降低恢复速度。</strong></p><p><strong>工作原理</strong>：</p><ul><li><strong>创建新的AOF文件</strong>：在AOF重写过程中，Redis会创建一个新的AOF文件。这个文件不是通过重放旧的AOF文件中的命令来生成的，而是直接从当前数据库的内存状态到处。</li><li><strong>最小命令集</strong>：新的AOF文件仅包含使数据库达到当前状态的最小命令集。例如，如果一个键被修改多次，新的AOF文件只会包含这个键的最终状态。</li></ul><p><strong>重写模式</strong>：</p><p>AOF重写有两种模式，其中一种是<code>混合模式</code>，另一种是<code>纯AOF模式</code>。</p><ul><li><p><strong>混合模式（Mixed Mode）:</strong></p><ul><li>在混合模式下，AOF重写生成的新AOF文件既包含AOF格式的写命令，也包含RDB快照的数据。</li><li>首先，redis会把当前所有的数据以rdb形式存入到AOF文件中，这些都是二进制文件，数据量小，随后新的数据会以AOF格式追加到这个AOF文件中。</li><li>恢复过程会更快，因为只需要加载一个文件。</li><li>纯AOF模式：<ul><li>AOF重写生成的新AOF文件仅包含AOF格式的写命令，不包含RDB快照的数据。但是会将一些重复的，没有意义的指令给去除掉，减少文件体积。</li></ul></li></ul></li><li><p><strong>触发机制</strong></p><ul><li><strong>手动触发</strong>：可以通过执行<code>BGREWRITEAOF</code>命令手动触发AOF重写。</li><li><strong>自动触发</strong>：Redis还可以配置为在AOF文件增长到一定大小时自动触发重写。这是通过配置文件中的<code>auto-aof-rewrite-percentage</code> 和 <code>auto-aof-rewrite-min-size</code> 指令来控制的。</li></ul></li><li><p><strong>过程细节</strong></p><ul><li><strong>使用子进程</strong>：类似于<code>BGSAVE</code>命令，AOF重写也是在一个子进程中进行的，以避免堵塞主进程。</li><li><strong>追加写入期间的命令</strong>：在重写过程中，对Redis数据库进行的所有写操作同时会被追加到旧的和新的AOF文件中，确保数据一致性。</li><li><strong>切换文件</strong>：一旦新的AOF文件创建完成，Redis会使用新文件替换旧的AOF文件，并从此刻开始只向新文件追加新的写命令。</li></ul></li><li><p><strong>优点</strong></p><ul><li><strong>减少磁盘占用</strong>：通过删除命令，AOF重写能显著减少AOF文件的大小。</li><li><strong>提高重启速度</strong>：更小的AOF文件意味着重启时重放命令的速度更快。</li></ul></li><li><p><strong>注意事项</strong></p><ul><li><strong>性能影响</strong>：尽管AOF重写是非堵塞的，但它可能会增加磁盘I&#x2F;O负担，因此在高负载的系统上运行时需要小心。</li><li><strong>内存影响</strong>：与<code>BGSAVE</code>类似，AOF重写也会临时增加Redis的内存使用，因为它需要创建一个当前数据库状态的副本。</li></ul><p><strong>AOF小结</strong>：</p></li></ul><ol><li><p>AOF写入</p><p>：</p><ul><li><p>AOF操作本身是将每个写命令追加到AOF文件的过程。这种追加操作通常是非堵塞的，但它的行为取决于具体的配置。</p></li><li><p>在AOF配置中，有一个</p><pre><code>appendfsync</code></pre><p>选项，它控制着操作系统刷新数据到磁盘的时机，这个选项有三个设置：</p><ul><li><strong>always</strong>（每修改同步）：每个写命令都同步写入磁盘，这可能导致堵塞，尤其是在磁盘I&#x2F;O性能较差的时候。</li><li><strong>everysec</strong>（每秒同步）：在默认情况下，大多数Redis设置会使用这个选项。大约每秒同步一次，这是一种平衡性能和数据安全性的做法，通常不会引起显著的堵塞。</li><li><code>no</code>：交给操作系统决定何时进行数据写入，这种方式下写入操作是非堵塞的，但在系统崩溃的情况下可能会丢失更多数据。</li></ul></li></ul></li><li><p>AOF重写</p><p>：</p><ul><li>AOF重写操作是非堵塞的。在执行AOF重写时，Redis会启动一个子进程来进行重写工作，而主进程继续处理客户端的请求。</li><li>由于AOF重写是在子进程中完成的，它不会堵塞正在进行的客户端命令处理。不过，它可能会对系统的整体性能产生影响，主要是因为磁盘I&#x2F;O和额外的CPU负载。</li></ul></li></ol><h3 id="两种持久化机制如何选择"><a href="#两种持久化机制如何选择" class="headerlink" title="两种持久化机制如何选择"></a>两种持久化机制如何选择</h3><p>选择RDB还是AOF持久化取决于应用的需求。通常情况下，两者可以结合使用以获得更好的性能和持久性。例如，可以启用AOF来记录最近的写操作，并同时使用RDB来提供定期的全数据快照。</p><p>总的来说，RDB适合对<code>定期备份敏感</code>、<code>数据集较大</code>的场景，而AOF适合对<code>实时性要求较高</code>、<code>数据恢复性要求非常高</code>的场景。具体选择应该根据应用程序的性质和需求来确定。</p><h3 id="淘汰策略"><a href="#淘汰策略" class="headerlink" title="淘汰策略"></a>淘汰策略</h3><p>Redis 的数据淘汰策略是<strong>指当内存使用达到一定阈值时，Redis如何选择删除一些数据以释放内存的方法</strong>。这些策略主要用于当Redis被用作缓存时，帮助管理内存的使用。</p><ol><li><strong>noeviction</strong>（无淘汰策略）：当内存使用达到限制时，对写入操作返回错误，但允许读操作。这是<strong>默认策略</strong>。</li><li><strong>allkeys-lru</strong>（最近最少使用）：在内存达到限制时，在所有键中移除最近最少使用的键。适用于通用缓存场景。</li><li><strong>volatile-lru</strong>（过期时间中最少使用）：仅淘汰设置了过期时间的键中的最近最少使用的键。</li><li><strong>allkeys-random</strong>（随机）：在内存达到限制时，在所有键中随机移除键。</li><li><strong>volatile-random</strong>（过期时间中随机）：仅随机移除设置了过期时间的键。</li><li><strong>allkeys-lfu</strong>：在所有键中移除最不经常使用的键。</li><li><strong>volatile-lfu</strong>（最近最少频繁使用）：从已设置过期时间的键中，移除最不经常使用的键。</li><li><strong>volatile-ttl</strong>（最短剩余时间）：从已设置过期的键中，移除即将到期的键。</li></ol><p><strong>应用场景：</strong></p><p>选择哪种淘汰策略取决于具体的使用场景和需求。例如，如果使用Redis作为缓存，并且希望在内存不足时自动删除老旧数据，可以选择<strong>allkeys-lru</strong>策略。</p><p>对于关键数据，可能更倾向于使用<strong>noeviction</strong>策略，并在应用层面控制内存使用。</p><h3 id="非阻塞I-O模型"><a href="#非阻塞I-O模型" class="headerlink" title="非阻塞I&#x2F;O模型"></a>非阻塞I&#x2F;O模型</h3><p>在此之前，我们先了解下什么是I&#x2F;O模型。I&#x2F;O（输入&#x2F;输出）模型描述的是程序如何处理输入和输出操作。在计算机系统中，I&#x2F;O操作通常是指与外部设备（如硬盘、网络接口等）的数据交换。I&#x2F;O模型决定了程序在等待I&#x2F;O操作完成时的行为，这对程序的性能和响应能力有重要影响。</p><p>主要有以下几种I&#x2F;O模型：</p><ol><li><p>堵塞I&#x2F;O（Blocking I&#x2F;O）</p><p>：</p><ul><li>在这种模型中，应用程序发起I&#x2F;O请求后，必须等待数据准备就绪并完成操作，期间应用程序被堵塞，不能执行其他任务。</li><li>例如，读取文件操作会一直等待，直到有数据可以读取。</li></ul></li><li><p>非堵塞I&#x2F;O（New I&#x2F;O）</p><p>：</p><ul><li>应用程序发起I&#x2F;O请求后，如果数据未准备好，操作系统会立即返回一个错误（通常是“资源暂时不可用”），应用程序可以继续执行其他任务。</li><li>应用程序需要不断地询问操作系统数据是否准备好，这个过程为“轮询（polling）”。</li></ul></li><li><p>I&#x2F;O复用（I&#x2F;O Multiplexing）</p><p>：</p><ul><li>应用程序通过一个API（如select、poll、epoll）监控多个I&#x2F;O流，一旦其中一个或多个I&#x2F;O流准备好，操作系统通知应用程序。</li><li>这种模型允许单个线程同时管理多个I&#x2F;O操作，而不是为每个I&#x2F;O操作创建单独的线程。</li></ul></li><li><p>信号驱动I&#x2F;O（Signal-driver I&#x2F;O）</p><p>：</p><ul><li>应用程序告诉操作系统启动一个操作，并让操作系统在数据准备好时通过信号来通知它。</li><li>与非堵塞I&#x2F;O不同，信号驱动I&#x2F;O不需要应用程序不断地检查数据是否准备好。</li></ul></li><li><p>异步I&#x2F;O（Asynchronous I&#x2F;O）</p><p>：</p><ul><li>应用程序发起I&#x2F;O操作后，可以立即开始执行下一个指令。操作系统将完成整个I&#x2F;O操作（包括数据传输）并在操作完成后通知应用程序。</li><li>这种模型下，应用程序无需等待I&#x2F;O操作的完成。</li></ul></li></ol><p>接下来让我们通过一个关于Redis如何利用非阻塞I&#x2F;O处理客户端请求的例子来更好地理解非堵塞I&#x2F;O模型概念。</p><p><strong>场景：客户端请求处理</strong></p><p><strong>传统堵塞I&#x2F;O模型的限制</strong></p><p>在传统的堵塞I&#x2F;O模型下，当Redis服务器接收来自一个客户端的请求时，它必须等待整个请求的处理完全完成（包括等待所有必要的数据被读取或写入），在此期间，它不能处理来自其他客户端的任何其他请求。这意味着如果某个请求的处理需要一些时间（例如，一个复杂的查询或大量数据的读取），其他客户端必须等待，这降低了整体的响应性和吞吐量。</p><p><strong>Redis的非堵塞I&#x2F;O模型</strong></p><p>现在再来看看Redis是如何使用非堵塞I&#x2F;O来优化这个过程的：</p><ol><li><p><strong>多个客户端同时连接</strong>：多个客户端同时向Redis服务器发送请求。</p></li><li><p>非堵塞I&#x2F;O操作</p><p>：</p><ul><li>当Redis服务器接收到一个请求时，它会开始处理这个请求。如果在处理过程中需要进行I&#x2F;O操作（比如读取磁盘上的数据），Redis服务器不会在这个操作完成前被堵塞。</li><li>相反，如果数据尚未准备好，Redis可以暂时停止处理这个请求，并转而处理其他客户端的请求。</li></ul></li><li><p>I&#x2F;O多路复用</p><p>：</p><ul><li>在后台，Redis使用I&#x2F;O多路复用技术（如epoll）来有效地监控所有活跃的客户端连接。</li><li>一旦某个请求的I&#x2F;O操作完成（例如，所需数据已准备好读取），I&#x2F;O多路复用机制会通知Redis服务器，然后Redis可以继续处理这个请求。</li></ul></li><li><p>高效并发处理</p><p>：</p><ul><li>通过这种方式，Redis可以在单个线程中高效地处理多个并发请求，而无需为每个请求或连接创建单独的线程。</li><li>这提高了服务器的响应性和吞吐量，即使在面对大量并发请求时也能保持高性能。</li></ul></li></ol><p><strong>结论</strong>：Redis 正是使用了<strong>非堵塞I&#x2F;O</strong>和<strong>I&#x2F;O多路复用</strong>，才能够快速、高效地处理成千上万的并发连接和请求，而无需创建和管理多个线程，从而大大提高了资源利用率和性能。</p><h3 id="事件驱动模型"><a href="#事件驱动模型" class="headerlink" title="事件驱动模型"></a>事件驱动模型</h3><ul><li><p><strong>非堵塞的事件循环模型</strong>：</p></li><li><p>Redis 采用了</p><p>非堵塞的事件循环模型</p><p>，允许多个客户端并发请求。虽然Redis在任何给定时间点只能处理一个请求，但它可以快速轮询多个客户端请求，以确保高吞吐量。</p><ul><li><p>事件驱动</p><p>：</p><ul><li>Redis的<strong>核心运行机制</strong>是<code>基于事件驱动</code>的。意味着Redis的主要功能是接收和处理客户端请求、执行命令、数据持久化等，都是通过响应各种事件来完成的。</li><li>在事件驱动模型中，Redis不需要为每个任务或请求创建新的线程，而是在单线程中异步处理这些事件。这种方式使得Redis能够高效地处理大量并发请求，同时保持简单的架构和低延迟。</li></ul></li><li><p><strong>事件循环</strong>：Redis的核心是一个<code>事件循环</code>，也称为<code>事件驱动循环</code>。这个事件循环不断地检查并处理发生的事件，而不会堵塞整个系统。它会轮询各个已注册的事件，如客户端连接事件、套接字可读事件、套接字可写事件等。</p></li><li><p><strong>事件监听</strong>：Redis使用操作系统提供的多路复用机制，如<code>epoll（Linux）</code>、<code>kqueue（BSD）</code>、<code>select</code>等，来监听多个套接字上的事件。这使得Redis能够同时处理多个客户端连接而无需为每个连接创建一个新线程。</p></li><li><p><strong>协程和事件处理</strong>：在一些版本的Redis中，引入了协程（Coroutine）和事件处理机制，可以更有效地处理多个客户端请求和数据库操作，提高了并发性能。</p></li></ul></li></ul><h3 id="Redis的操作是同步还是异步"><a href="#Redis的操作是同步还是异步" class="headerlink" title="Redis的操作是同步还是异步"></a>Redis的操作是同步还是异步</h3><p>先说结论，<strong>基于内存操作是同步，基于网络I&#x2F;O或磁盘I&#x2F;O是异步</strong>。</p><p><strong>同步</strong></p><ul><li>当Redis接收到像<code>get key1, set key1</code>这样的命令时，如果数据在内存中（即不需要从磁盘加载），Redis会立即处理这个命令并同步返回结果。即使是在这种同步情况下，操作也是非常迅速的，因为它是在内存中进行的，几乎没有什么延迟。</li><li>因此，对于大多数常规操作，Redis的处理是足够快的，以至于即使这些操作都是同步进行的，也不会对性能造成显著影响。</li></ul><p><strong>异步</strong></p><ul><li>在网络I&#x2F;O方面，Redis使用<code>非堵塞I/O</code>机制。这意味着Redis可以在等待一个网络请求的数据准备好时，同时处理其他网络请求或内部任务。</li><li>在磁盘I&#x2F;O方面，需要区分不同类型的操作：<ul><li><strong>RDB持久化</strong>：当执行如<code>BGSAVE</code>命令进行RDB持久化时，Redis会在后台创建一个数据快照。这是一个异步操作，不会堵塞主事件循环。</li><li><strong>AOF持久化</strong>：对于AOF持久化，其行为取决于配置。如果配置为<code>appendfsync always</code>，则每次写入都会同步到磁盘，这可能是同步的。如果配置为<code>appendfsync everysec</code>或<code>appendfsync no</code>，则写入操作是异步的，因为实际的磁盘写入是延迟或由操作系统管理的。</li><li><strong>磁盘读取</strong>：对于磁盘读取（如重启时从RDB或AOF恢复数据），这通常是同步进行的，因为Redis需要这些数据来恢复其状态。</li></ul></li></ul><h3 id="Redis-单线程为什么这么快"><a href="#Redis-单线程为什么这么快" class="headerlink" title="Redis 单线程为什么这么快"></a>Redis 单线程为什么这么快</h3><p>Redis 采用单线程模型的优势在于它能够避免多线程带来的复杂性，降低了线程切换和锁竞争的开销，以及更容易实现一些关键操作的原子性。</p><ol><li>内存操作<ul><li><strong>快速数据访问</strong>：Redis是一个基于内存的数据存储系统。内存操作比磁盘操作快得多，避免了磁盘寻址和磁盘I&#x2F;O的开销。</li></ul></li><li>高效的数据结构<ul><li><strong>优化的实现</strong>：Redis内部使用高效的数据结构（如哈希表、跳跃表等），这些结构经过优化，能够快速执行数据操作，如添加、删除、查找和访问。</li></ul></li><li>单线程模型<ul><li><strong>避免上下文切换</strong>：多线程程序需要处理上下文切换的开销。Redis的单线程模型避免了这种开销，从而提高了效率。</li><li><strong>无需锁机制</strong>：Redis是单线程的，不需要担心数据同步和锁的问题。</li></ul></li><li>非堵塞I&#x2F;O<ul><li><strong>I&#x2F;O多路复用</strong>：Redis利用I&#x2F;O多路复用技术（如epoll、kqueue）来同时监听多个网络连接，从而提高网络通信效率。</li><li><strong>事件驱动模型</strong>：Redis使用基于非堵塞I&#x2F;O的事件驱动模型。这意味着即使在执行I&#x2F;O操作（如网络请求）时，Redis也不会被堵塞，而是能够继续处理其他任务。</li></ul></li><li>优化的命令执行<ul><li><strong>快速命令处理</strong>：Redis的大多数命令非常简单，可以在常数时间内完成（例如O(1)或O(log n)）。</li><li><strong>管道化和批量操作</strong>：Redis支持管道化，允许客户端一次性发送多个命令，然后Redis以此快速处理，减少了网络往返延迟。</li></ul></li></ol><h3 id="缓存雪崩、缓存击穿、缓存穿透"><a href="#缓存雪崩、缓存击穿、缓存穿透" class="headerlink" title="缓存雪崩、缓存击穿、缓存穿透"></a>缓存雪崩、缓存击穿、缓存穿透</h3><h3 id="缓存雪崩"><a href="#缓存雪崩" class="headerlink" title="缓存雪崩"></a>缓存雪崩</h3><p><strong>原理</strong>：缓存雪崩是指在缓存系统中，大量的缓存数据几乎同时失效（过期），导致所有的请求都直接落到数据库上，从而可能引起数据库压力过大、甚至宕机的问题。 <strong>解决方法</strong></p><ol><li><strong>设置不同的过期时间</strong>：为缓存数据设置略微不同的过期时间，防止大量数据同时过期。</li><li><strong>使用持久化</strong>：确保缓存层有持久化机制，这样即使缓存服务器重启，也可以从持久化存储中恢复数据。</li><li><strong>设置备用缓存</strong>：建立备用缓存或多级缓存策略，当主缓存不可用时，可以使用备用缓存。</li><li><strong>限流和降级</strong>：在系统架构中实现限流策略，以及在高负载时启用服务降级策略。</li></ol><h3 id="缓存击穿"><a href="#缓存击穿" class="headerlink" title="缓存击穿"></a>缓存击穿</h3><p><strong>原理</strong>：缓存击穿是指对某个热点 key 非常频繁的访问，在这个 key 突然失效的瞬间，大量请求直接达到数据库上，可能导致数据库短时间内承受巨大压力。 <strong>解决方法</strong></p><ol><li><strong>设置热点数据永不过期</strong>：对于这些非常热门的数据，可以将它们设置为永不过期。</li><li><strong>使用互斥锁</strong>：当缓存失效时，不是所有请求都去数据库加载数据，而是使用某种互斥锁机制确保只有一个请求去请求数据库加载数据库并回填到缓存中。</li><li><strong>提前更新</strong>：监控这些热点key的访问频率和模式，根据预测在它们即将过期时提前更新它们的值。</li></ol><h3 id="缓存穿透"><a href="#缓存穿透" class="headerlink" title="缓存穿透"></a>缓存穿透</h3><p><strong>原理</strong>：缓存穿透是指查询一个<strong>一定不存在</strong>的数据，由于缓存不会命中，每次都要到数据库去查询，可能会被恶意利用，对数据库造成压力。 <strong>解决方法</strong></p><ol><li><strong>布隆过滤器</strong>：在缓存之前使用布隆过滤器，它可以快速判断一个数据是否在数据集中，如果不存在，则无需查询数据库，直接返回空响应即可。</li><li><strong>缓存空对象</strong>：即使某个数据在数据库中不存在，也将这个“空”结果缓存起来，避免对同一个不存在的数据发起多次查询。</li><li><strong>参数校验</strong>：增加严格的参数校验，避免非法参数查询。</li></ol><h3 id="布隆过滤器是什么"><a href="#布隆过滤器是什么" class="headerlink" title="布隆过滤器是什么"></a>布隆过滤器是什么</h3><p>布隆过滤器是一种空间效率很高的概率型数据结构，用于测试一个元素是否是一个集合的成员。它的主要特点是：</p><ol><li><strong>如果布隆过滤器判断元素不存在</strong>：那么该元素一定不存在于集合中。</li><li><strong>如果布隆过滤器判断元素存在</strong>：则该元素可能存在于集合中。也就是说，存在一定的误判概率，即布隆过滤器可能会错误地判断某个不存在的元素为存在（称为假阳性）。</li></ol><p>布隆过滤器的这种特性使其非常适合用于那些不需要100%准确性但对空间效率有较高要求的场景，如网络应用中的缓存穿透问题、垃圾邮件检测等。</p><p><strong>原理简述</strong></p><p>布隆过滤器通过多个独立的哈希函数对元素进行处理。当添加一个元素时，它会被所有的哈希函数分别哈希，然后在对应的位置上做标记。在查询时，会对元素使用相同的哈希函数，检查所有对应的位置是否都被标记过。如果所有位置都被标记，布隆过滤器判断元素“<code>可能存在</code>”；如果任何一个位置未被标记，则元素“<code>一定不存在</code>”。</p><p><strong>场景</strong></p><p><strong>应用：缓存穿透问题</strong></p><pre><code>**问题**：缓存穿透是指缓存和数据库中都没有的数据，但请求者故意进行重复请求的现象。如这些请求数据由于不存在，每次请求都要访问数据库然后返回，这将导致数据库压力过大。**措施**：布隆过滤器可以用来防止缓存穿透。方法是将所有可能查询的数据哈希到一个足够大的布隆过滤器中。查询时，先查询布隆过滤器，如果布隆过滤器说数据不存在，那么肯定不存在，请求可以拒绝，从而避免对底层数据源的查询压力。如果布隆过滤器认为数据可能存在，请求才会被进一步的查询数据库或缓存系统。</code></pre><h3 id="Redis和数据库如何做到一致性"><a href="#Redis和数据库如何做到一致性" class="headerlink" title="Redis和数据库如何做到一致性"></a>Redis和数据库如何做到一致性</h3><ol><li>缓存失效策略<ul><li><strong>主动失效</strong>：每当数据库更新时，立即删除或更新缓存中的相应数据。</li><li><strong>延迟双删</strong>：在更新数据库之前和之后的适当时间间隔内，两次删除缓存中的数据。第一次删除是为了防止在更新数据库过程中有新的读请求得到旧的缓存数据，第二次删除是为了处理在更新数据库与第一次删除缓存间隙期间产生的旧缓存数据。</li></ul></li><li>读写分离和最终一致性<ul><li>对于某些非关键性应用，可以接受最终一致性而不是强一致性。</li><li>通过设置合理的缓存过期时间，可以在一定时间内自动更新缓存，减少数据不一致的时间窗口。</li></ul></li><li>事务和锁机制<ul><li>在更新数据时使用事务和锁来确保数据库操作和缓存操作的原子性。</li><li>这种方法适用于要求严格一致性的场景，但可能会影响系统的性能。</li></ul></li></ol><h3 id="主从复制（读写分离）"><a href="#主从复制（读写分离）" class="headerlink" title="主从复制（读写分离）"></a>主从复制（读写分离）</h3><p>&#x2F;&#x2F; TODO</p><h3 id="哨兵模式"><a href="#哨兵模式" class="headerlink" title="哨兵模式"></a>哨兵模式</h3><p>&#x2F;&#x2F; TODO</p><h3 id="Redis-分布式锁"><a href="#Redis-分布式锁" class="headerlink" title="Redis 分布式锁"></a>Redis 分布式锁</h3><h3 id="实现分布式锁"><a href="#实现分布式锁" class="headerlink" title="实现分布式锁"></a>实现分布式锁</h3><p>Redis 分布式锁底层实现的关键点在于<strong>Redis的事务性操作和原子性保证</strong>。</p><p>Redis 分布式锁的原理主要基于它的命令， <code>SETNX</code> （SET if not exists），Redis 使用单线程处理命令，因此在执行 SETNX 命令期间不会发生竞态条件（线程竞争），即使多个客户端同时尝试设置同一个键，Redis也会确保只有一个客户端成功设置。这使得 SETNX 命令成为实现分布式锁的理想选择，因为它可以安全地用于多个客户端之间的协调。</p><ol><li><p><strong>SETNX（SET if Not exists）命令</strong>：Redis中通常使用 SETNX 命令来尝试设置一个键的值，但仅在该键不存在时才设置成功。这一特性使得可以将键视为锁，当 SETNX 成功时标识锁被获取。</p></li><li><p>内部执行过程</p><p>：</p><ul><li><strong>检查键是否存在</strong>：在执行 <code>SETNX</code> 命令时，Redis首先会检查指定的键是否已经存在于数据库中。</li><li><strong>如果键不存在，设置键的值</strong>：如果检查发现键不存在，Redis会执行设置操作，将指定的键设置为指定的值。这个设置操作是原子的，即Redis确保在多个客户端同时尝试设置相同键时，只有一个客户端会成功设置，而其他客户端将失败。</li><li><strong>返回结果</strong>：SETNX命令会根据操作的结果返回一个<code>布尔值</code>，通常是标识为<code>1</code>代表成功获取锁，<code>0</code>代表锁已被其他客户端持有。客户端可以根据这个返回值来确定是否成功获取锁或设置键的值。</li></ul></li><li><p><strong>设置超时时间</strong>：为了防止分布式锁被永远持有，可以为其设置一个超时时间（过期时间），以确保即使持有者在某些情况下崩溃或无法释放锁，锁最终也会自动释放。</p></li><li><p><strong>锁的释放</strong>：锁的持有者完成其任务后应该释放锁，这通常通过删除键来实现：<code>del lock_key</code></p></li></ol><h3 id="为什么Redis适合做分布式锁"><a href="#为什么Redis适合做分布式锁" class="headerlink" title="为什么Redis适合做分布式锁"></a>为什么Redis适合做分布式锁</h3><ul><li><strong>原子性操作</strong>：Redis的<code>SETNX</code>命令和<code>EXPIRE</code>命令是原子操作，这意味着它们在执行时不会受到竞态条件的影响。这使得在多个客户端之间安全地实现分布式锁非常容易。</li><li><strong>高性能</strong>：Redis是一个内存数据库，可以在微秒级别执行操作，因此在获取和释放锁时非常快速。这使得Redis适合用作分布式锁。</li><li><strong>可用性</strong>：Redis支持主从复制和分片，因此即使某个Redis节点发生故障，其他节点仍然可以提供服务。这确保了分布式锁的可用性。</li><li><strong>超时和自动释放</strong>：Redis可以为锁设置超时时间，确保锁在一段时间后自动释放，防止死锁情况的发生。</li><li><strong>简单易用</strong>：Redis的API自带了SETNX和EXPIRE命令，创建锁和管理锁非常容易。</li></ul><h3 id="Redis-6-0-多线程的改动"><a href="#Redis-6-0-多线程的改动" class="headerlink" title="Redis 6.0 多线程的改动"></a>Redis 6.0 多线程的改动</h3><p>从 Redis 6.0版本开始，Redis开始引入了多线程模型来处理网络I&#x2F;O。这是Redis架构中的一个重要变化，但需要注意的是，这个多线程模型主要用于网络请求的读写操作，并不涉及到数据的实际读写操作，也就是说，数据的实际读写还是单线程在处理。</p><p><strong>Redis多线程模型的特点</strong></p><ol><li><strong>限于网络I&#x2F;O</strong>：<strong>多线程在Redis中主要用于处理客户端请求的接受和响应的发送，即网络I&#x2F;O操作</strong>。数据的读取和写入仍然在主线程中单线程执行，以保证原子性和一致性。</li><li><strong>配置可调整</strong>：用户可以配置线程数量，以优化网络I&#x2F;O的性能。默认情况下，多线程不会启用，需要用户配置。</li></ol><p><strong>为什么采用这种多线程设计</strong></p><p>通过使用多线程处理网络I&#x2F;O，Redis可以更好地利用现代多核CPU的能力，提高在高并发情况下的性能，尤其是在处理大量网络请求时。</p>]]></content>
      
      
      <categories>
          
          <category> 数据库 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> Redis </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>MySQL基础巩固</title>
      <link href="/2024/05/03/mysql/"/>
      <url>/2024/05/03/mysql/</url>
      
        <content type="html"><![CDATA[<h2 id="MySQL索引，以及数据结构是什么？"><a href="#MySQL索引，以及数据结构是什么？" class="headerlink" title="MySQL索引，以及数据结构是什么？"></a>MySQL索引，以及数据结构是什么？</h2><p>由于数据库的索引是保存到磁盘上的，因此当我们通过索引查找某行数据的时候，就需要先从磁盘读取索引到内存，再通过索引从磁盘中找到某行数据，然后读入到内存，也就是说查询过程中会发生多次磁盘 I&#x2F;O，而磁盘 I&#x2F;O 次数越多，所消耗的时间也就越大。</p><h3 id="索引的目的"><a href="#索引的目的" class="headerlink" title="索引的目的"></a>索引的目的</h3><p><strong>加速查询</strong>：索引允许数据库快速定位到特定的行，显著提高了查询的效率，避免全表扫描。</p><p><strong>影响更新操作</strong>：索引需要在数据插入、更新、删除时进行维护，这可能会影响写操作的性能。</p><h3 id="索引的优势和劣势"><a href="#索引的优势和劣势" class="headerlink" title="索引的优势和劣势"></a>索引的优势和劣势</h3><p><strong>优势</strong>：</p><ol><li><strong>快速定位数据</strong>。</li><li><strong>优化排序和分组操作，因为B+树索引是有序的</strong>。</li><li><strong>提高大型表的查询效率</strong>。</li></ol><p><strong>劣势</strong>：</p><ol><li><strong>维护成本</strong>：影响数据的插入、更新、删除性能。</li><li><strong>存储开销</strong>：索引需要额外的存储空间。</li></ol><h3 id="索引的适用场景"><a href="#索引的适用场景" class="headerlink" title="索引的适用场景"></a>索引的适用场景</h3><ul><li>频繁作为查询条件的字段，特别是当查询返回的结果集为表中较小的子集时。</li></ul><h3 id="MySQL索引的数据结构："><a href="#MySQL索引的数据结构：" class="headerlink" title="MySQL索引的数据结构："></a>MySQL索引的数据结构：</h3><ol><li><p>B+Tree（B+ 树）索引：</p><ol><li>MySQL主要的索引类型。用于 InnoDB、MyISAM、Memory 等存储引擎。</li><li>支持全值匹配、范围查询和前缀查找。</li><li>主键索引是聚簇索引，数据直接存储在索引的叶子节点上。</li></ol></li><li><p>Hash（哈希）索引：</p><ol><li>基于哈希表，适用于等值查询。</li><li>适用于 Memory 存储引擎。<strong>当某个索引值被频繁访问时，InnoDB会在B-Tree索引上再创建一个Hash 索引，这使得某些查找操作更加高效</strong>。</li><li><strong>查找速度非常快，但缺点是数据插入和删除的速度较慢，且占用更多的内存</strong>。</li></ol></li></ol><h3 id="SQL语句可能不使用索引的情况"><a href="#SQL语句可能不使用索引的情况" class="headerlink" title="SQL语句可能不使用索引的情况"></a>SQL语句可能不使用索引的情况</h3><ol><li>使用函数或者算术运算</li><li>在 WHERE 子句中，如果在 OR 前的条件列是索引列，而在 OR 后的条件列不是索引列，那么索引会失效。</li><li>查询优化器评估全表扫描比索引扫描更高效</li><li>表的数据量小，全表扫描会更快</li><li>like 查询中，使用前置通配符，即like在前。（like ‘%value’）<ul><li><strong>当%在前时</strong>：由于通配符在前，查询需要检查所有的记录来查找匹配项，因为<strong>索引是基于字段值的顺序构建的</strong>，所以当查询的开始部分是不确定的，数据库无法利用索引快速定位数据，只能执行全表扫描来查找匹配的行，导致索引失效。</li><li><strong>当%在后时</strong>：通配符在后，查询只需要匹配以<strong>关键字开头</strong>的任意字符，这种情况下，数据库可以利用索引快速定位到关键词开始的第一条记录，然后顺序扫描，直到不再匹配为止。</li></ul></li><li>数据类型不匹配：<ul><li>如 <code>WHERE column = &#39;123&#39;</code> 而不是 <code>WHERE column = 123</code>，这可能导致索引不被使用。</li></ul></li><li>NULL 值查询：<ul><li>查询涉及 <code>IS NULL</code> 或 <code>IS NOT NULL</code> 时，索引的使用可能会受到限制，尤其是在某些数据库配置下。</li></ul></li></ol><p><img src="https://prod-files-secure.s3.us-west-2.amazonaws.com/4d514fab-2492-4877-a269-a017b8992bb6/4bdad6eb-7547-4e92-9cd1-28fc5505191b/Untitled.png" alt="Untitled"></p><p>下面是对不同 <code>COUNT</code> 用法的性能分析和排序：</p><ol><li><p><code>COUNT(*)</code>：</p><ul><li><code>COUNT(*)</code> 统计表中的行数，不忽略任何行（包括含有 NULL 值的行）。它不关注表中的任何特定列，只是简单地计数所有行。</li><li>在多数数据库系统中，<code>COUNT(*)</code> 被特别优化，因为它只需要遍历索引或数据行来计算总行数，不需要查看列值。</li><li>统计所有行，包括包含 NULL 的行。</li></ul></li><li><p><code>COUNT(1)</code>：</p><ul><li><code>COUNT(1)</code> 实质上与 <code>COUNT(*)</code> 功能相同，因为 <code>1</code> 是一个常量表达式，表示“对每行计数”，与 <code>COUNT(*)</code> 一样，它不涉及任何列的内容。</li><li>在大多数现代数据库中，<code>COUNT(1)</code> 和 <code>COUNT(*)</code> 的性能非常接近，因为优化器识别这种计数模式并执行相同的操作。</li><li>统计所有行，包括包含 NULL 的行。</li></ul></li><li><p><code>COUNT(主键字段)</code>：</p><ul><li><code>COUNT(主键字段)</code> 统计主键字段非 NULL 的行数。由于主键字段不允许有 NULL 值，因此 <code>COUNT(主键字段)</code> 实际上与 <code>COUNT(*)</code> 一样，都是统计所有行。</li><li>这种方式的性能通常与 <code>COUNT(*)</code> 接近，但如果数据库优化器不充分识别这一点，可能略微有额外开销，因为它需要检查主键字段。</li><li>由于主键字段不能为 NULL，所以其结果和 <code>COUNT(*)</code> 相同，即统计所有行。</li></ul></li><li><p><code>COUNT(字段)</code>：</p></li></ol><ul><li><code>COUNT(字段)</code> 统计指定字段非 NULL 的行数。这需要访问具体的列数据，并检查每个列值是否为 NULL。<ul><li>如果该字段不是索引的一部分，这可能导致较慢的性能，因为数据库需要加载每一行的实际数据来检查该字段。</li></ul></li><li>只统计那些指定字段不为 NULL 的行。</li></ul><h2 id="MySQL的索引结构为什么要选B-树？"><a href="#MySQL的索引结构为什么要选B-树？" class="headerlink" title="MySQL的索引结构为什么要选B+树？"></a>MySQL的索引结构为什么要选B+树？</h2><ol><li><p><strong>二分查找树</strong>是一个天然的二分结构，能很好的利用二分查找快速定位数据，但是它存在一种极端的情况，每当插入的元素都是树内最大&#x2F;最小的元素，就会导致二分查找树退化成一个链表，此时查询复杂度就会从O(logn)降低为O(n)。</p></li><li><p><strong>自平衡二叉树</strong>保证了查询操作的时间复杂度就会一直维持在O(logn)。但是它本质上还是一个二叉树，每个节点只能有2个子节点，随着元素的增多，树的高度会越来越高。</p><blockquote><p>树的高度通常决定了查询时潜在的磁盘I&#x2F;O操作次数，因为树结构是存储在磁盘上的，并且访问树中的每个节点都可能对应一次磁盘I&#x2F;O操作，尤其是当节点数据不在内存中时。因此，树的高度越高，每次查询可能涉及的磁盘I&#x2F;O次数越多，从而可能影响查询的性能。然而，使用内存缓冲等技术可以减少这种影响。</p></blockquote><p>而B树和B+树都是通过多叉树的方式，会将树的高度变矮，所以这两个数据结构非常适合检索存于磁盘中的数据。</p><p>但是MySQL默认的存储引擎InnoDB采用的是B+树作为索引的数据结构，原因有：</p><ul><li>B+树的非叶子节点不存放实际的记录数据，仅存放索引，因此在数据量相同的情况下，相比存储即存索引又存记录的B树，B+树的非叶子节点可以存放更多的索引，因此B+树可以比B树更[矮胖]，查询底层节点的磁盘I&#x2F;O次数会更少。</li><li>B+树有大量的冗余节点（所有非叶子节点可以存放更多的索引），这些冗余索引让B+树在输入、删除的效率都更高，比如删除根节点的时候，不会像B树那样发生复杂的树的变化。</li><li>B+树叶子节点之间用链表连接了起来，有利于范围查询，而B树要实现范围查询，因此只能通过树的遍历来完成范围查询，这会涉及到多个节点的磁盘I&#x2F;O操作，范围查询效率不如B+树。</li></ul></li></ol><h2 id="聚簇索引和非聚簇索引的区别"><a href="#聚簇索引和非聚簇索引的区别" class="headerlink" title="聚簇索引和非聚簇索引的区别"></a>聚簇索引和非聚簇索引的区别</h2><h3 id="聚簇索引-VS-非聚簇索引"><a href="#聚簇索引-VS-非聚簇索引" class="headerlink" title="聚簇索引 VS 非聚簇索引"></a>聚簇索引 VS 非聚簇索引</h3><ol><li>聚簇索引<ul><li>将数据行直接存储在索引的叶子节点上。</li><li>一个表只能有一个聚簇索引，通常是主键。</li></ul></li><li>非聚簇索引<ul><li>索引和数据行分开存储，索引项包含指向数据行的指针。</li><li>一个表可以有多个非聚簇索引。</li><li>查询可能会导致回表操作，即通过索引找到数据行的实际位置。</li></ul></li></ol><h2 id="MySQL的全表扫描"><a href="#MySQL的全表扫描" class="headerlink" title="MySQL的全表扫描"></a>MySQL的全表扫描</h2><p>全表扫描是指<strong>数据库执行查询操作时，不通过索引，逐一读取表中的每一行来确定哪些行符合查询条件</strong>。</p><p><strong>何时会触发全表扫描</strong>：</p><ol><li>表中没有建立索引或者查询的时候没有使用到索引；</li><li>使用了函数或表达式；</li><li>查询优化器觉得全表扫描更高效。</li></ol><p><strong>全表扫描的优势</strong>：</p><ol><li><strong>简单</strong>：不需要考虑索引维护和构建的复杂性。</li><li><strong>适用于小表</strong>：对于非常小的表，全表扫描很可能比建立和维护索引更快。</li><li><strong>避免索引的开销</strong>：没有索引，就没有更新索引的开销。</li></ol><p><strong>全表扫描的劣势</strong>：</p><ol><li><strong>对于大表来讲，效率较低</strong></li><li><strong>I&#x2F;O开销大，全表扫描会导致大量的磁盘I&#x2F;O</strong>。</li></ol><h2 id="MySQL-回表"><a href="#MySQL-回表" class="headerlink" title="MySQL 回表"></a>MySQL 回表</h2><p><strong>场景</strong>：当通过非聚簇索引查询数据时，从返回的数据里面，无法获取所需的全部数据（即查询的列不是索引的一部分），<strong>系统就需要再次通过主键索引（聚簇索引）去查询剩下这部分数据</strong>。这个<code>过程</code>被称为”回表“。回表是一个附加的步骤，可能会导致额外的I&#x2F;O操作。</p><p><strong>性能影响</strong>：回表操作涉及至少两次磁盘访问，第一次是通过非聚簇索引查询数据时，第二次是通过聚簇索引（即主键索引）查询数据时。在数据行分散或索引不是完全覆盖查询需求的情况下，回表操作可能成为性能瓶颈，尤其在数据量大或查询复杂时。</p><p><strong>发生回表的场景</strong>：</p><ul><li>当查询的列不在索引中时，即查询的列超出了索引所覆盖的范围。</li><li>使用 <code>select *</code> 查询时，因为表示所有列，而非聚簇索引只包含索引列和主键列，所有需要回表获取其他列的数据。</li><li>当查询条件（WHERE子句）使用了非聚簇索引进行筛选，但返回的结果集（SELECT子句）中包含了非索引列。</li></ul><h3 id="避免和解决回表问题"><a href="#避免和解决回表问题" class="headerlink" title="避免和解决回表问题"></a>避免和解决回表问题</h3><ul><li>优化索引设计，使用覆盖索引：覆盖索引是非聚簇索引，它包含了查询所有列。<strong>当查询只涉及索引中的列时，就可以直接从索引中获取数据，无需回表</strong>。例如，如果你经常查询name和age，你可以创建一个包含name、age和id(主键)的索引。</li></ul><p>在使用覆盖索引时，列的顺序很重要，它影响了索引的使用方式和效率。如果你为 <code>age</code> 和 <code>name</code> 建立了一个复合索引，索引的创建顺序会影响查询的性能。这里是几个关键点：</p><ol><li><strong>索引的顺序</strong>：如果索引是按 <code>(age, name)</code> 的顺序建立的，那么在查询时首先使用 <code>age</code> 作为过滤条件的查询将能高效地利用这个索引。例如，<code>SELECT age, name FROM table WHERE age = 30</code> 能够充分利用该索引。但如果查询主要基于 <code>name</code> 而非 <code>age</code>，如 <code>SELECT age, name FROM table WHERE name = &#39;John&#39;</code>，那么这个索引可能不会被优化器选择，因为 <code>name</code> 是索引的第二部分。</li><li><strong>最左前缀原则</strong>：在使用复合索引时，数据库遵循最左前缀原则，这意味着查询条件需要从索引的最左边开始匹配。如果索引是 <code>(age, name)</code>，那么只有当 <code>age</code> 部分在 WHERE 子句中被使用时，索引才能被有效地使用。如果查询直接使用 <code>name</code> 而忽略 <code>age</code>，则这个索引的效用会大大降低。（又或者age和name同时使用时，age必须在第一个where条件中，否者同样不会生效）</li><li><strong>多条件查询</strong>：如果查询涉及多个条件且这些条件对应于索引中的列，那么索引的效率取决于这些条件是如何使用索引列的。例如，<code>SELECT age, name FROM table WHERE age = 30 AND name = &#39;John&#39;</code> 可以完美地利用 <code>(age, name)</code> 索引。</li></ol><ul><li>限制查询的列：避免使用 select * ，而是明确指定所需的列，并且如果这些列都包含在索引中，就可以避免回表。</li><li>使用聚簇索引查询：如果可能，直接使用主键（聚簇索引）进行查询，这样可以直接获取所有列的数据，无需回表。</li></ul><p>注：在 InnoDB 存储引擎中，每个表都有一个聚簇索引，通常是主键。如果你没有明确指定一个主键，InnoDB 会选择一个唯一的非空索引作为聚簇索引。如果表中没有这样的索引，InnoDB会为表生成一个隐藏的、包含6字节长度的聚簇索引。</p><h2 id="MySQL-页"><a href="#MySQL-页" class="headerlink" title="MySQL 页"></a>MySQL 页</h2><p>在 MySQL 中，“页” 通常是指<strong>数据库存储引擎中数据存储的基本单位</strong>。在 InnoDB 存储引擎中，页的默认大小是 16KB。<strong>数据页用于存储表中的行数据，索引页用于存储索引数据。</strong></p><ol><li><p>数据页和事务日志：</p><ul><li>InnoDB 存储引擎将数据存储在数据页中。每当数据被修改（如通过 insert、update或delete操作）时，InnoDB 不仅会更改磁盘上的数据页，而且还会在事务日志（称为redo log）中记录这些更改。这是为了确保在系统崩溃后能够恢复数据。</li></ul></li><li><p>回滚段（Undo Logs）：</p><ul><li>当事务进行修改时，原始数据会存储在所谓的回滚段中。这些回滚段实际上也存储在数据页中。它们允许数据库在事务失败或明确地回滚时恢复到原始状态。同时，回滚段支持MVCC，使得不同的事务可以看到数据的不同历史版本。</li></ul></li><li><p>事务的一致性视图：</p><ul><li>InnoDB 通过在每个事务开始时创建一个一致性视图来实现 MVCC。这意味着每个事务可以看到在其启动时刻之前已经提交的数据的快照。这个机制依赖于回滚段中的数据来提供旧版本的数据，允许对同一数据的并发读写操作。</li></ul></li><li><p>锁定和并发控制：</p><ul><li>页面级的锁定（虽然 InnoDB 主要使用行级锁）可以用于管理对共享数据的并发访问。这有助于处理死锁和提高并发事务的性能。</li></ul></li></ol><h2 id="MySQL-的-InnoDB-和-MyISAM-的区别"><a href="#MySQL-的-InnoDB-和-MyISAM-的区别" class="headerlink" title="MySQL 的 InnoDB 和 MyISAM 的区别"></a>MySQL 的 InnoDB 和 MyISAM 的区别</h2><table><thead><tr><th>区别点</th><th>InnoDB</th><th>MyISAM</th></tr></thead><tbody><tr><td>事务支持</td><td>支持ACID事务，有提交和崩溃回滚功能</td><td>不支持</td></tr><tr><td>锁定机制</td><td>采用行级锁，进行数据修改时只锁定所涉及的行</td><td>采用表级锁，进行写操作时会锁定整个表</td></tr><tr><td>外键</td><td>支持外键</td><td>不支持</td></tr><tr><td>崩溃恢复</td><td>由于其事务日志、双写缓冲区和自动崩溃恢复功能，InnoDB在系统崩溃后可以恢复到一致的状态</td><td>没有事务日志，因此在崩溃后可能需要修复或重建表</td></tr><tr><td>性能</td><td>通常在需要高并发写入的应用中表现更好，因为它使用行级锁定</td><td>在只读或大量读的应用中可能会更快</td></tr><tr><td>MVCC (多版本并发控制)</td><td>支持</td><td>不支持</td></tr></tbody></table><p><strong>总结</strong>：因为MyISAM相对简单所以在效率上要优于InnoDB，如果系统读多写少，同时表数据量不是很大，并对原⼦性要求低，那么MyISAM最好的选择。且MyISAM恢复速度快。可直接⽤备份覆盖恢复。如果系统读少，写多的时候，尤其是并发写⼊⾼的时候。InnoDB就是⾸选了。</p><h2 id="MySQL-的主备同步（主从复制）"><a href="#MySQL-的主备同步（主从复制）" class="headerlink" title="MySQL 的主备同步（主从复制）"></a>MySQL 的主备同步（主从复制）</h2><p>主从复制是一种常用的数据备份和读取扩展策略。它允许数据从一个 MySQL 数据库服务器（主服务器）复制到一个或多个MySQL 数据库服务器（从服务器）。</p><p>MySQL 主备复制实现分成三个步骤：</p><ol><li>master 将所有数据更改（如 INSERT、UPDATE、DELETE 命令）都会记录在二进制日志中（binary log）中</li><li>slave 将 master 的binary log，简称binlog，拷贝到它的中继日志（relay log）</li><li>salve 重做中继日志的事件，将改变反映它自己的数据</li></ol><p><img src="http://www.hyxiaoblog.com/images/25/mysql.png" alt="img"></p><h2 id="SQL-语句执⾏顺序"><a href="#SQL-语句执⾏顺序" class="headerlink" title="SQL 语句执⾏顺序"></a>SQL 语句执⾏顺序</h2><p>记忆法：FOJW GHSD OL 佛教我更合适的欧拉</p><ol><li><p><strong>FROM</strong> 子句</p><ul><li>首先执行FROM子句，确定查询的数据源，可能是一张表、多张表的连接或子查询。</li></ul></li><li><p><strong>ON</strong> 子句</p><ul><li>如果涉及JOIN操作，接下来将执行ON子句以确定如何连接表。</li></ul></li><li><p><strong>JOIN</strong> 子句</p><ul><li>执行JOIN操作，根据ON子句的条件确定如何连接表。</li></ul></li><li><p><strong>WHERE</strong> 子句</p><ul><li>接着执行WHERE子句，对FROM子句确定的数据源进行行级过滤。</li></ul></li><li><p><strong>GROUP BY</strong> 子句</p><ul><li>执行GROUP BY子句，将数据分组以供聚合函数使用。</li></ul></li><li><p><strong>HAVING</strong> 子句</p><ul><li>在分组后执行HAVING子句，对分组后的数据进行过滤，HAVING子句通常用于聚合函数的条件过滤。</li></ul></li><li><p><strong>SELECT</strong> 子句</p><ul><li>然后执行SELECT子句，选取特定的列。如果使用了聚合函数，此时将计算聚合值。</li></ul></li><li><p><strong>DISTINCT</strong> 子句</p><ul><li>如果使用了DISTINCT关键字，将在此阶段对结果进行去重。</li></ul></li><li><p><strong>ORDER BY</strong> 子句</p><ul><li>执行ORDER BY子句，对结果集进行排序。</li></ul></li><li><p><strong>LIMIT &#x2F; OFFSET</strong> 子句</p><ul><li>最后执行LIMIT&#x2F;OFFSET子句，限制返回的结果数量或跳过一定数量的行。</li></ul><pre class="line-numbers language-language-sql"><code class="language-language-sql">SELECT DISTINCT column1FROM table1JOIN table2 ON table1.id = table2.idWHERE column2 > 10GROUP BY column1HAVING COUNT(*) > 1ORDER BY column1LIMIT 10<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><p>执行顺序为：</p><ol><li>FROM table1</li><li>JOIN table2 ON <a href="http://table1.id/">table1.id</a> &#x3D; <a href="http://table2.id/">table2.id</a></li><li>WHERE column2 &gt; 10</li><li>GROUP BY column1</li><li>HAVING COUNT(*) &gt; 1</li><li>SELECT DISTINCT column1</li><li>ORDER BY column1</li><li>LIMIT 10</li></ol></li></ol><h2 id="SQL优化方法"><a href="#SQL优化方法" class="headerlink" title="SQL优化方法"></a>SQL优化方法</h2><ol><li>避免使用 select * ，只选择需要查询的列</li><li>避免在列上使用函数或者算术运算</li><li>正确使用索引<ul><li>为经常用于查询条件的列创建索引</li><li>定期检查并优化索引，删除不再需要的索引</li><li>避免过度索引，因为索引会增加写操作的开销</li></ul></li><li>限制查询的数目以及返回的结果条数</li><li>使用合适的数据类型，字段尽量使⽤not null，因为NULL值列表会占用 1 字节空间。</li><li>尽量避免在查询中使用子查询，考虑使用连接查询（JOIN）</li><li>调整数据库配置，当表过大时，及时做好数据归档或分库分表</li><li>使用 EXPLAIN 分析查询<ul><li>使用 EXPLAIN 命令可以查看MySQL如何执行特定的SQL查询</li><li>它会查询的执行计划，包括哪些索引被使用、表的扫描方式、估计的行数等</li><li>通过分析EXPLAIN的输出，你可以确定哪些部分的查询可能导致性能问题</li></ul></li><li>监控慢查询日志，找出需要优化的查询。</li></ol><h2 id="MySQL的分库分表"><a href="#MySQL的分库分表" class="headerlink" title="MySQL的分库分表"></a>MySQL的分库分表</h2><p>分库分表是数据库水平扩展的常用策略，用于解决单一数据服务器承载压力过大的问题。</p><h3 id="分库分表的场景"><a href="#分库分表的场景" class="headerlink" title="分库分表的场景"></a>分库分表的场景</h3><ol><li>数据量巨大：当单表的数据量达到数千万、数亿甚至更多时，查询性能可能会下降，此时需要考虑分表</li><li>高并发请求：当数据库的读写请求较高，超出了单一数据库服务器的处理能力，可能需要分库来分散读写压力</li><li>业务扩展</li><li>数据存储限制</li><li>提高数据安全性</li></ol><h3 id="分库分表的策略"><a href="#分库分表的策略" class="headerlink" title="分库分表的策略"></a>分库分表的策略</h3><ol><li>垂直分库&#x2F;分表<ul><li>根据业务功能将表分组，每个组放在不同的数据库中</li><li>例如，用户相关的表放在一个数据库中，订单相关的表放在另一个数据库中</li><li>这种方式可以将不同的业务负载分散在不同的数据库服务器上</li></ul></li><li>水平分库&#x2F;分表<ul><li>将表中的数据按某种规则分散到多个相同结构的表中</li><li>常见的分表键包括：用户ID、订单ID、时间等</li><li>例如，根据用户ID的范围将数据分散到不同的表中</li></ul></li><li>基于范围的分库<ul><li>根据分表键的范围将数据分散到不同的数据库或表中</li><li>例如，根据时间范围将数据分散到不同的表中</li></ul></li></ol><h2 id="事务的ACID属性是什么？"><a href="#事务的ACID属性是什么？" class="headerlink" title="事务的ACID属性是什么？"></a>事务的ACID属性是什么？</h2><p>A：原子性，原子性是指事务是一个不可分割的工作单位，事务中的操作要么都发生，要么都不发生</p><p>C：一致性，事务前后数据的完整性必须保持一致。</p><p>I：隔离性，事务的隔离性是指多个用户并发访问数据库时，一个用户的事务不能被其他用户的事务所干扰，多个并发事务之间数据要相互隔离</p><p>D：持久性，事务一旦被提交，它对数据库中数据的改变就是永久性，接下来即使数据库发生故障也不应该对其有任何影响。</p><pre class="line-numbers language-language-java"><code class="language-language-java">原子性和一致性有点类型，但是两者的侧重点不同，原子性关注状态，要么全部成功，要么全部失败，不存在部分成功的状态。而一致性关注数据的可见性，中间状态的数据对外部不可见，只有最初状态和最终状态的数据对外可见。<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span></span></code></pre><h2 id="什么是死锁？如何预防和解决死锁？"><a href="#什么是死锁？如何预防和解决死锁？" class="headerlink" title="什么是死锁？如何预防和解决死锁？"></a>什么是死锁？如何预防和解决死锁？</h2><p>当涉及到数据库时，死锁通常是指<strong>两个或多个事务在等待对方释放资源，从而导致它们都无法继续执行的情况。</strong></p><h3 id="死锁的四个必要条件"><a href="#死锁的四个必要条件" class="headerlink" title="死锁的四个必要条件"></a>死锁的四个必要条件</h3><ol><li><strong>互斥条件</strong>：资源不能被多个事务同时占用。</li><li><strong>请求与保持条件</strong>：一个事务在请求新的资源时保持对其他资源的占用。</li><li><strong>不剥夺条件</strong>：已经分配给一个事务的资源不能被其他事务强行剥夺，只有该事务使用完毕后才释放资源。</li><li><strong>循环等待条件</strong>：存在一个等待循环，即事务A等待事务B释放资源，事务B等待事务C释放资源，事务C又等待事务A释放资源，形成一个闭环。</li></ol><h3 id="如何预防死锁"><a href="#如何预防死锁" class="headerlink" title="如何预防死锁"></a>如何预防死锁</h3><ol><li><strong>超时</strong>：为事务设置一个超时时间。</li><li><strong>死锁检测</strong>：数据库系统可以定期检查是否存在死锁。</li><li><strong>预先分配</strong>：在事务开始时请求所有必需的资源。</li></ol><h3 id="如何解决死锁"><a href="#如何解决死锁" class="headerlink" title="如何解决死锁"></a>如何解决死锁</h3><ol><li><strong>手动干预</strong>：DBA可以手动终止或回滚某些事务，从而释放资源并打破死锁。</li><li><strong>使用死锁检测工具</strong>：许多数据库系统都提供了死锁检测工具，可以帮助DBA找到并解决死锁问题。</li></ol><h2 id="描述数据库的隔离级别以及它们之间的区别"><a href="#描述数据库的隔离级别以及它们之间的区别" class="headerlink" title="描述数据库的隔离级别以及它们之间的区别"></a>描述数据库的隔离级别以及它们之间的区别</h2><ol><li><strong>未提交读</strong>：事务最低的隔离级别，它允许另外一个事务可以看到另一个事务未提交的数据。这种隔离级别会产生脏读，不可重复读和幻读</li><li><strong>已提交读</strong>：保证一个事务修改的数据提交后才能被另外一个事务读取。另外一个事务不能读取该事务未提交的数据。可能避免脏读，但可能出现不可重复读和幻读。</li><li><strong>可重复读</strong>：可以防止脏读和不可重复读。但是可能出现幻读。除了保证一个事务不能读取另一个事务未提交的数据外，还保证了避免不可重复读。</li><li><strong>可串行化</strong>：最高事务隔离级别。事务被处理为顺序执行，除了防止脏读，不可重复读，还避免了幻读。</li></ol><table><thead><tr><th>隔离级别</th><th>脏读</th><th>不可重复读</th><th>幻读</th></tr></thead><tbody><tr><td>未提交读</td><td>可能</td><td>可能</td><td>可能</td></tr><tr><td>已提交读</td><td>不可能</td><td>可能</td><td>可能</td></tr><tr><td>可重复读</td><td>不可能</td><td>不可能</td><td>可能</td></tr><tr><td>可串行化</td><td>不可能</td><td>不可能</td><td>不可能</td></tr></tbody></table><h2 id="MySQL-的MVCC-是什么"><a href="#MySQL-的MVCC-是什么" class="headerlink" title="MySQL 的MVCC 是什么"></a>MySQL 的MVCC 是什么</h2><p>MVCC 是一种<code>多版本并发控制</code>机制，通过事务的可见性看到自己预期的数据，能降低其系统开销。（RC和RR工作）</p><p>InnoDB 的MVCC，是通过在每行记录后面保存系统版本号（可以理解为事务的ID），每开始一个新的事务，系统版本号就会自动递增，事务开始时刻的系统版本号会作为事务的ID。这样可以确保事务读取的行，要么是在事务开始前已经存在的，要么是事务自身插入或者修改过的，防止幻读的产生。</p><ol><li>MVCC 手段只适用于MySQL隔离级别中的读已提交（Read commited）和可重复读（Repeatable Read）。</li><li>Read uncommited 由于存在脏读，即能读到未提交事务的数据行，所以不适用MVCC。</li><li>简单的select快照读不会加锁，删改及select for update 等需要当前读的场景会加锁。</li></ol><p>原因是MVCC的创建版本和删除版本只要在事务提交后才会产生。客观上，MySQL使用的是乐观锁的一种实现方式，就是每行都有版本号，保存时根据版本号觉得是否成功。InnoDB的MVCC使用到快照存储在Undo日志中，该日志通过回滚指针把一个数据行所有快照连接起来。</p><h2 id="什么是视图（View）？它与普通表有什么不同？"><a href="#什么是视图（View）？它与普通表有什么不同？" class="headerlink" title="什么是视图（View）？它与普通表有什么不同？"></a>什么是视图（View）？它与普通表有什么不同？</h2><p>视图是数据库中的一个虚拟表，是基于一个或多个实际表的结果集的表现形式。视图并不存储数据，只是保存了一个SQL查询。当视图被引用时，该查询会被执行，从而生成视图的数据。</p><table><thead><tr><th>区别</th><th>视图</th><th>普通表</th></tr></thead><tbody><tr><td>数据存储</td><td>不存储数据。它只是一个基于实际表的查询的定义。每次查询视图时，都会执行其定义的查询</td><td>实际存储数据。数据在物理磁盘上有实际的存储位置</td></tr><tr><td>更新性</td><td>不是所有的视图都可以更新。只有当视图基于一个单一的表，并且没有使用某些聚合函数、DISTINCT关键字等时，才可以更新。</td><td>可以直接更新</td></tr><tr><td>复杂性和灵活性</td><td>可以基于多个表，并使用复杂的SQL逻辑，如连接、过滤和聚合。这使得视图可以提供一个简化或特定的数据视图，隐藏复杂的SQL细节</td><td>表示实际的数据结构，通常不包含复杂的逻辑或计算</td></tr><tr><td>用途</td><td>抽象和隐藏复杂的SQL查询</td><td>用于持久存储数据</td></tr><tr><td>性能</td><td>由于视图是在每次查询时动态生成的，所以可能会有性能问题，特别是当视图基于多个表或包含复杂逻辑时</td><td>直接查询普通表通常更快，因为数据是实际存储的</td></tr></tbody></table><h2 id="如何备份和恢复MySQL数据库？以及什么是数据库的冷备份和热备份？"><a href="#如何备份和恢复MySQL数据库？以及什么是数据库的冷备份和热备份？" class="headerlink" title="如何备份和恢复MySQL数据库？以及什么是数据库的冷备份和热备份？"></a>如何备份和恢复MySQL数据库？以及什么是数据库的冷备份和热备份？</h2><h3 id="如何备份MySQL-数据库或表"><a href="#如何备份MySQL-数据库或表" class="headerlink" title="如何备份MySQL 数据库或表"></a>如何备份MySQL 数据库或表</h3><p>使用 mysqldump 工具，mysqldump 是MySQL提供的一个命令行工具，用于导出数据库为SQL文件。</p><p>示例：备份数据库</p><pre class="line-numbers language-language-sql"><code class="language-language-sql">mysqldump -u [username] -p[password] [database_name] > [dump_file.sql]<span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre><p>示例：备份特定的表</p><pre class="line-numbers language-language-sql"><code class="language-language-sql">mysqldump -u [username] -p[password] [database_name] [table_name] > [dump_file.sql]<span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre><h3 id="如何恢复MySQL数据库"><a href="#如何恢复MySQL数据库" class="headerlink" title="如何恢复MySQL数据库"></a>如何恢复MySQL数据库</h3><p>可以使用MySQL命令行客户端直接执行SQL文件来恢复数据库</p><pre class="line-numbers language-language-sql"><code class="language-language-sql">mysql -u [username] -p[password] [database_name] < [dump_file.sql]<span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre><h3 id="冷备份与热备份"><a href="#冷备份与热备份" class="headerlink" title="冷备份与热备份"></a>冷备份与热备份</h3><h3 id="冷备份（Code-Backup）"><a href="#冷备份（Code-Backup）" class="headerlink" title="冷备份（Code Backup）"></a>冷备份（Code Backup）</h3><p><strong>特点</strong></p><ol><li>冷备份是在数据库处于关闭状态时进行的备份。</li><li>在备份期间，数据库不可用，不能进行读写操作。</li><li>冷备份通常更简单，因为它不需要处理并发的数据修改。备份的数据是一致的，不需要额外的日志或恢复步骤。</li></ol><p><strong>优点</strong>：数据一致性得到保证，恢复过程简单快速。</p><p><strong>缺点</strong>：需要停机，可能导致业务中断。</p><p><strong>实现方式</strong>：冷备份的实现相对简单。通常只需停止数据库服务，然后复制数据库文件（例如数据文件、日志文件等）到备份位置。完成后，再重新启动数据库服务。</p><h3 id="热备份（Hot-Backup）"><a href="#热备份（Hot-Backup）" class="headerlink" title="热备份（Hot Backup）"></a>热备份（Hot Backup）</h3><ol><li>热备份是在数据库处于运行状态时进行的备份，不需要停机。</li><li>在备份期间，数据库仍然可用，可用进行读写操作。</li><li>热备份通常需要更复杂的策略，因为需要确保备份的数据一致性。这通常涉及到使用日志文件来记录备份期间的所有更改，以便在恢复时应用这些更改。</li><li>MySQL的InnoDB存储支持热备份。</li></ol><p><strong>优点</strong>：不需要停机，数据库始终可用。可以实现近实时或增量备份，减少备份时间和存储需求。</p><p><strong>缺点</strong>：可能需要额外的存储和计算资源。恢复过程可能比冷备份复杂，特别是当需要应用大量的日志更改时。</p><p><strong>实现方式</strong>：热备份的实现较为复杂。通常需要专门的备份工具或软件。这些工具可以在数据库运行时捕获数据的一致性快照，并记录备份期间的所有更改。恢复时，首先恢复数据快照，然后应用备份期间的所有更改。</p><h3 id="MySQL的InnoDB存储引擎能够支持热备份的原因主要与其内部的设计和特性有关"><a href="#MySQL的InnoDB存储引擎能够支持热备份的原因主要与其内部的设计和特性有关" class="headerlink" title="MySQL的InnoDB存储引擎能够支持热备份的原因主要与其内部的设计和特性有关"></a>MySQL的InnoDB存储引擎能够支持热备份的原因主要与其内部的设计和特性有关</h3><ol><li><strong>事务日志（Redo Logs）</strong>：InnoDB 使用事务日志来确保数据的持久性和恢复能力。当数据发生变化时，这些变化首先被记录在redo日志中，然后再异步地写入磁盘。在热备份期间，即使数据正在变化，也可以使用这些日志来捕获备份开始后的所有更改，确保数据的一致性。</li><li><strong>多版本并发控制（MVCC）</strong>:InnoDB 使用MVCC来支持高并发。这意味着每个事务都看到一个数据的“快照”，而不是实时数据。这使得在热备份期间可以为备份创建一个数据快照，而不影响正在运行的事务。</li><li><strong>一致性非锁定读取</strong>：InnoDB允许在不锁定整个表或数据库的情况下进行一致性读取。这意味着备份过程可以读取数据，而不会堵塞其他事务。</li></ol><p>总的来说，选择冷备份还是热备份取决于业务需求。如果可以承受短时间的停机，冷备份可能是一个简单的选择。如果需要24&#x2F;7的可用性，热备份可能是更好的选择，但可能需要复杂的备份和恢复策略。</p><h2 id="如何确保数据库的高可用性和灾难恢复"><a href="#如何确保数据库的高可用性和灾难恢复" class="headerlink" title="如何确保数据库的高可用性和灾难恢复"></a>如何确保数据库的高可用性和灾难恢复</h2><p><strong>高可用性</strong>是确保数据库在出现故障时仍然可用的能力。</p><p><strong>策略</strong>：</p><ol><li><strong>主从复制</strong>：一个主数据库处理写操作，一个或多个从数据库处理读操作。如果主数据库出现故障，一个从数据库可以被提升为新的主数据库。</li><li><strong>负载均衡</strong>：使用负载均衡器分发数据库请求，确保没有单点故障。</li></ol><p><strong>灾难恢复</strong>是在发生灾难性事件后恢复数据和服务的能力。</p><p><strong>策略</strong>：</p><ol><li><strong>定期备份</strong>：定期将数据库备份到安全的位置。</li><li><strong>异地备份</strong>：将备份存储在与生产数据库不同的地理位置。</li><li><strong>备份验证</strong>：定期验证备份的完整性和可恢复性。</li></ol><h2 id="慢查询"><a href="#慢查询" class="headerlink" title="慢查询"></a>慢查询</h2><p><strong>含义</strong>：慢查询是数据库中查询时间超过指定阈值的SQL，指的是在日志中记录运行比较慢的SQL语句。</p><h3 id="启用慢查询日志"><a href="#启用慢查询日志" class="headerlink" title="启用慢查询日志"></a>启用慢查询日志</h3><ul><li>确保MySQL 数据库的慢查询日志（slow query log）被启用。可以通过设置 slow_query_log 和 long_query_time 参数来开启和配置慢查询日志。</li></ul><h3 id="分析慢查询日志"><a href="#分析慢查询日志" class="headerlink" title="分析慢查询日志"></a>分析慢查询日志</h3><ul><li>日志文件分析：定期检查慢查询日志文件，查找执行时间长、频率高的SQL语句。</li><li>使用工具：使用 mysqldumpslow 或 pt-query-digest 这样的工具来分析MySQL 的慢查询日志。</li></ul><h3 id="实时性能分析"><a href="#实时性能分析" class="headerlink" title="实时性能分析"></a>实时性能分析</h3><ul><li>使用 show processlist：在MySQL中，可以使用 show processlist 命令来查看当前执行的查询及其运行时间。</li></ul><h3 id="导致慢查询的原因"><a href="#导致慢查询的原因" class="headerlink" title="导致慢查询的原因"></a>导致慢查询的原因</h3><ol><li><strong>缺乏适当的索引</strong>：没有为查询中的条件列创建索引，导致数据库执行全表扫描。</li><li><strong>索引不当</strong>：虽然存在索引，但可能不是最优的，所以优化器没有走索引查询。</li><li><strong>查询设计不当</strong>：使用了低效的SQL语句，如使用子查询代替连接。</li><li><strong>数据量巨大</strong>：随着数据的增长，未优化的查询可能会变得越来越慢。</li><li><strong>硬件限制</strong>：如磁盘I&#x2F;O、CPU或内存瓶颈。</li><li><strong>使用了大量的JOIN操作</strong>：特别是在大表上。</li><li><strong>使用了复杂的聚合函数</strong>：如GROUP BY、COUNT、SUM等。</li><li><strong>网络延迟</strong>：尤其是在分布式数据库系统中。</li></ol><h3 id="如何避免慢查询"><a href="#如何避免慢查询" class="headerlink" title="如何避免慢查询"></a>如何避免慢查询</h3><ol><li><strong>优化查询</strong>：确保SQL语句尽可能简单高效。</li><li><strong>使用索引</strong>：为经常用于查询条件的列创建索引。</li><li><em>避免在查询中使用‘</em>’ **：只选择需要的列。</li><li><strong>减少JOIN操作的数据</strong>：尤其是在大表上。</li><li><strong>使用数据库的查询优化工具</strong>：如MySQL的<code>EXPLAIN</code>。</li><li><strong>定时维护数据库</strong>：如优化表、更新统计信息等。</li></ol><h3 id="如何解决慢查询"><a href="#如何解决慢查询" class="headerlink" title="如何解决慢查询"></a>如何解决慢查询</h3><ol><li><strong>分析慢查询日志</strong>：找出最慢的查询。</li><li><strong>使用EXPLAIN命令</strong>：查看查询的执行计划，找出瓶颈。</li><li><strong>优化查询</strong>：根据EXPLAIN的结果，重写SQL语句。</li><li><strong>添加或调整索引</strong>：确保查询使用了最优的索引。</li><li><strong>考虑硬件升级</strong>：如增加内存、使用更快的磁盘或升级CPU。</li><li><strong>考虑使用缓存</strong>：考虑在程序中使用缓存，如redis或memcached，减少对数据库的请求。</li></ol><h2 id="为什么JOIN会影响查询缓慢，导致慢查询（基于大表的情况下）"><a href="#为什么JOIN会影响查询缓慢，导致慢查询（基于大表的情况下）" class="headerlink" title="为什么JOIN会影响查询缓慢，导致慢查询（基于大表的情况下）"></a>为什么JOIN会影响查询缓慢，导致慢查询（基于大表的情况下）</h2><p>首先 JOIN 操作是关系型数据库中的一个核心操作，它允许从两个或多个表中组合数据。</p><ol><li><strong>数据量增加</strong>：当两个表进行 JOIN 操作时，结果集的大小可能会显著增加，特别是在进行笛卡尔积（每个表中的每一行与另一个表中的每一行组合）时。</li><li><strong>全表扫描</strong>：如果没有适当的索引支持JOIN操作，数据库可能需要对一个或两个表进行全表扫描，这在大表上是非常耗时的。</li><li><strong>复杂的数据处理</strong>：JOIN操作可能需要数据库进行复杂的数据处理，如排序、过滤和聚合，这会增加查询的执行时间。</li><li><strong>I&#x2F;O开销</strong>：JOIN操作可能导致大量的磁盘I&#x2F;O，特别是当数据不在内存中时。</li><li><strong>临时表</strong>：某些JOIN操作可能需要数据库创建临时表来处理查询结果，这回增加额外的I&#x2F;O开销和处理时间。</li><li><strong>多表连接</strong>：连接多个表会增加查询的复杂性和处理时间。每增加一个表，都可能导致性能下载。</li></ol><p>为了避免由于JOIN操作导致的性能问题，可以采取以下策略</p><ol><li><strong>使用适当的索引</strong>：确保JOIN操作的列都有索引，并且这些索引是最优的</li><li><strong>减少结果集的大小</strong>：在JOIN操作之前使用WHERE子句过滤数据，以减少需要处理的数据量。</li><li><strong>避免笛卡尔积</strong>：始终在JOIN操作中使用明确的连接条件，以避免不必要的数据组合。</li><li><strong>只连接所需的表</strong>：避免不必要的表连接，只连接真正需要的表。</li><li><strong>使用EXPLAIN命令分析</strong></li></ol><p>笛卡尔积：简单的说就是两个集合相乘的结果。</p><p>假设集合A&#x3D;{a, b}，集合B&#x3D;{0, 1,2}，则两个集合的笛卡尔积为{(a, 0),(a, 1), (a, 2), (b, 0), (b, 1), (b, 2)}。</p><h2 id="分布式数据库与传统数据库的主要区别"><a href="#分布式数据库与传统数据库的主要区别" class="headerlink" title="分布式数据库与传统数据库的主要区别"></a>分布式数据库与传统数据库的主要区别</h2><table><thead><tr><th>区别点</th><th>分布式数据库</th><th>传统数据库</th></tr></thead><tbody><tr><td>数据存储位置</td><td>数据被分布在多个物理位置上。</td><td>数据通常存储在单一的物理位置上。</td></tr><tr><td>可扩展性</td><td>可以通过添加更多的节点来水平扩展，以支持更大的数据量和更高的查询负载。</td><td>通常依赖于垂直扩展，即增加单一服务器的硬件资源。</td></tr><tr><td>可用性和容错性</td><td>由于数据在多个节点上有多个副本，即使某些节点出现故障，数据仍然可用。</td><td>如果单一的数据库服务器出现故障，可能会导致数据不可用。</td></tr><tr><td>数据一致性</td><td>可能使用不同的数据一致性模型，如最终一致性，这意味着在某些情况下，不同的节点可能会看到数据的不同版本。</td><td>通常使用严格的ACID事务模型，确保数据的强一致性。</td></tr><tr><td>复杂性</td><td>由于需要处理节点之间的通信、数据同步和故障恢复等问题，所以通常比传统数据库更复杂。</td><td>由于所有数据都在一个地方，所以管理和维护相对简单。</td></tr><tr><td>查询性能</td><td>可以并行处理查询，因为数据分布在多个节点上。但跨节点的查询可能会受到网络延迟的影响。</td><td>查询性能取决于单一服务器的硬件和数据库的优化。</td></tr><tr><td>事务处理</td><td>处理跨多个节点的事务可能会更复杂，并可能需要特殊的协议，如两阶段提交。</td><td>事务处理通常更简单和直接，因为所有数据都在同一个地方。</td></tr></tbody></table><h2 id="Explain关键字详解"><a href="#Explain关键字详解" class="headerlink" title="Explain关键字详解"></a>Explain关键字详解</h2><p>EXPLAIN是MySQL中的一个关键字，用于显示MySQL如何执行SQL查询。通过Explain，可以了解查询的执行计划，从而找出可能的性能瓶颈并进行优化。</p><p><strong>使用方法</strong>：你只需在你的SELECT、INSERT、UPDATE或DELETE查询前加上EXPLAIN关键字：</p><p>EXPLAIN SELECT * FROM _table WHERE _column &#x3D; ‘some_value’;</p><h3 id="Explain-返回的参数及其意义："><a href="#Explain-返回的参数及其意义：" class="headerlink" title="Explain 返回的参数及其意义："></a>Explain 返回的参数及其意义：</h3><ol><li>id：查询的标识符。如果查询中包含子查询，每个子查询都会有一个不同的id。</li><li>select_type：查询的类型。常见的值有：<ul><li>SIMPLE：简单的SELECT查询，不包含子查询或JOIN。</li><li>PRIMARY：查询中最外层的SELECT。</li><li>SUBQUERY：在SELECT或WHERE子句中的子查询。</li><li>DERIVED：在FROM子句中的子查询。</li></ul></li><li>table：输出结果集的表。</li><li>type：连接类型。常见的值有：（自上到下，优化程度为从最优到最差）<ul><li>system：表只有一行（等于const）</li><li>const：通过主键或者唯一索引查找一行。</li><li>eq_ref：通过主键或者唯一索引查找多行。</li><li>ref：通过非唯一索引查找。</li><li>range：通过索引查找某个范围的行。</li><li>index：全索引扫描。</li><li>ALL：全表扫描。</li></ul></li><li>possible_keys：可能使用的索引。</li><li>key：实际使用的索引。</li><li>key_len：使用的索引的长度。</li><li>ref：显示索引的哪一列被使用。</li><li>rows：估计要检查的行数。</li><li>Extra：其他信息。常见的值有：<ol><li>Using index：表示只使用了索引，没有读取实际的行数据。</li><li>Using where：表示使用了WHERE子句来过滤结果。</li><li>Using temporary：表示使用了临时表来存储中间结果。</li><li>Using filesort：表示使用了外部排序。</li></ol></li></ol><p>通过理解EXPLAIN的输出，开发者可以更好地了解查询的执行方式，找出可能的性能瓶颈，并进行相应的优化。例如，如果type列显示为ALL，这意味着进行了全表扫描，这通常是一个性能瓶颈，可能需要添加或调整索引来改善性能。</p>]]></content>
      
      
      <categories>
          
          <category> 数据库 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> MySQL </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>SpringCloud Alibaba-Nacos</title>
      <link href="/2024/04/23/springcloud-alibaba-nacos/"/>
      <url>/2024/04/23/springcloud-alibaba-nacos/</url>
      
        <content type="html"><![CDATA[<h2 id="简要介绍"><a href="#简要介绍" class="headerlink" title="简要介绍"></a>简要介绍</h2><p>Nacos 是由阿里巴巴开源的一个<strong>动态服务发现</strong>、<strong>配置</strong>和<strong>服务管理平台</strong>，专为微服务架构设计。它帮助开发者实现云原生应用的动态服务发现和配置管理，提供了轻量级的服务注册和发现机制以及动态的服务配置功能。</p><h3 id="核心功能"><a href="#核心功能" class="headerlink" title="核心功能"></a>核心功能</h3><ol><li>服务发现与注册：<ul><li>Nacos 支持 DNS-based 和 RPC-based 服务发现，提供实时健康检查，确保服务的可用性。服务实例上线或下线时，Nacos 会自动处理服务列表，客户端通过订阅服务列表获取最新的服务实例信息。</li></ul></li><li>动态配置管理：<ul><li>Nacos 提供中心化的配置管理服务，允许动态地管理应用配置，而无需重启服务。它支持配置自动更新，服务在运行时可以根据配置变化进行自适应调整。</li></ul></li><li>服务元数据和流量管理：<ul><li>Nacos 支持存储服务的元数据，如权重、负载均衡策略等，这些元数据可以用于服务调度和流量管理。</li></ul></li><li>支持多种配置格式：<ul><li>Nacos 支持多种配置格式，包括但不限于 properties、YAML、JSON等。</li></ul></li><li>支持多种环境：<ul><li>Nacos 支持多环境、多租户的配置管理，助力于微服务的多环境隔离。</li></ul></li></ol><h2 id="存储结构"><a href="#存储结构" class="headerlink" title="存储结构"></a>存储结构</h2><p>服务注册信息主要存储在服务器的内存中，以便快速响应服务发现的请求。这部分是服务注册的核心存储机制。</p><p>对于配置管理，Nacos 提供了两种存储方式：</p><ul><li><strong>内存中</strong>：为了快速访问，配置数据也会被缓存于内存中。</li><li><strong>持久化存储</strong>：在持久化模式下，Nacos 支持使用外部数据库来存储配置数据。</li></ul><h3 id="常见问题"><a href="#常见问题" class="headerlink" title="常见问题"></a>常见问题</h3><h3 id="1、Nacos-是怎么发现新进来的微服务实例的？"><a href="#1、Nacos-是怎么发现新进来的微服务实例的？" class="headerlink" title="1、Nacos 是怎么发现新进来的微服务实例的？"></a>1、Nacos 是怎么发现新进来的微服务实例的？</h3><p>当一个微服务实例启动时，首先在 yml 文件中配置 Nacos 注册中心的地址，然后在启动类上添加服务发现 @EnableDiscoveryClient 注解。这样它会自动向 Nacos Server 注册当前服务实例。这个过程通常是通过调用 Nacos Server 的 API，将自己的服务名称、实例ID、IP地址、端口号等信息发送给 Nacos Server。注册成功之后，Nacos 并能感知到这个实例的存在。</p><h3 id="2、Nacos-是如何发现一个服务不可用的？"><a href="#2、Nacos-是如何发现一个服务不可用的？" class="headerlink" title="2、Nacos 是如何发现一个服务不可用的？"></a>2、Nacos 是如何发现一个服务不可用的？</h3><p>Nacos Server 会定时发送心跳检查请求到每一个已注册的服务实例，以确认它们是否还存活。如果在一定时间内（默认是30秒）没有收到某个服务实例的心跳响应，Nacos 会认为这个服务实例已经不可用，并将其从服务列表中剔除。</p><h3 id="3、当一个服务要调用另一个服务时，流程是哪样子的？"><a href="#3、当一个服务要调用另一个服务时，流程是哪样子的？" class="headerlink" title="3、当一个服务要调用另一个服务时，流程是哪样子的？"></a>3、当一个服务要调用另一个服务时，流程是哪样子的？</h3><ul><li>当服务 A 想要调用服务 B 时，服务 A 首先会向服务注册中心（Nacos）请求服务 B 的实例信息。</li><li>服务注册中心接收到响应，然后返回服务 B 所有可用实例列表给服务A。</li><li>服务 A 通过集成的客户端负载均衡器（如Ribbon），根据某种负载均衡策略（如轮询、随机、权重等）选择一个服务B的实例。</li><li>服务 A 通过选定的服务 B 实例的网络地址发起对服务 B 的调用。通常通过 HTTP 或其他 RPC 协议实现。</li><li>如果调用失败，服务A可以选择另一个服务B的实例进行重试。</li><li>被调用的服务 B 实例接收请求，处理业务逻辑，并返回响应给服务 A。</li></ul><h3 id="4、灰度发布和蓝绿部署是什么意思？"><a href="#4、灰度发布和蓝绿部署是什么意思？" class="headerlink" title="4、灰度发布和蓝绿部署是什么意思？"></a>4、灰度发布和蓝绿部署是什么意思？</h3><ul><li>灰度发布：是指新版本的服务逐渐替代旧版本的过程，初期只有少部分用户使用新版本，如果新版本稳定，再逐渐扩大到所有用户。这样可以确保新版本的稳定性，并减少因新版本引入的问题对所有用户的影响。</li><li>蓝绿部署：是指同时部署两个版本的服务，蓝色代表旧版本，绿色代表新版本。所有的流量首先路由到蓝色版本，当绿色版本准备好并经过测试后，流量可以切换到绿色版本。这样可以快速回滚到蓝色版本，如果绿色版本有问题。</li></ul><h3 id="5、Nacos-和-Gateway-之间是怎么样的关系？"><a href="#5、Nacos-和-Gateway-之间是怎么样的关系？" class="headerlink" title="5、Nacos 和 Gateway 之间是怎么样的关系？"></a>5、Nacos 和 Gateway 之间是怎么样的关系？</h3><ul><li>Nacos 主要负责<code>服务的注册与发现</code>以及<code>配置管理</code>。而Gateway 是<code>API网关</code>，负责处理外部请求并将其路由到相应的微服务。</li><li>当 Gateway 需要路由请求到某个服务时，它会向服务注册中心查询这个服务的实例列表，然后通过集成的负载均衡器，根据负载均衡策略选择一个实例进行调用。</li></ul><h3 id="6、Nacos-集群之间是怎么同步的？"><a href="#6、Nacos-集群之间是怎么同步的？" class="headerlink" title="6、Nacos 集群之间是怎么同步的？"></a>6、Nacos 集群之间是怎么同步的？</h3><p>Nacos 集群中的数据同步主要依靠 Raft 协议来保证一致性。这是一种分布式计算中用于实现多节点间一致性的协议，常用于多副本数据的一致性保障。</p><ol><li>领导选举（Leader Election）：<ul><li>当 Nacos 集群启动时，或者领导者节点失效时，集群会通过 Raft 协议进行新的领导者选举。</li><li>所有的写操作（比如更新配置信息或服务注册信息）都必须通过领导者来进行。</li></ul></li><li>日志复制（Log Replication）：<ul><li>当领导者节点接收到一个更新请求（比如配置更新或服务注册），它首先将这个请求作为一个新的日志条目添加到它的日志中。</li><li>然后，领导者将这个日志条目发送给其他的追随者节点。</li><li>追随者节点将该日志条目添加到它们各自的日志中，并向领导者确认接收成功。</li></ul></li><li>数据提交：<ul><li>一旦领导者节点从大多数追随者那里收到了确认，它就会提交该日志条目，并将更新应用到系统状态上。</li><li>领导者之后会通知追随者已经提交了哪些日志条目，追随者随后也会将这些条目提交并应用到各自的系统状态。</li></ul></li><li>读取操作：<ul><li>对于读操作，可以直接由任何一个节点处理，但为了保证读到的数据是最新的，通过读操作也会通过领导者节点来进行。</li></ul></li></ol><h3 id="CAP"><a href="#CAP" class="headerlink" title="CAP"></a>CAP</h3><p>CAP 理论指出，一个分布式系统不可能同时满足以下三点：</p><ul><li><strong>一致性（Consistency）</strong>：每次读取都能得到最新的写入或错误响应。</li><li><strong>可用性（Availability）</strong>：每次请求都能得到响应，无论成功或失败。</li><li><strong>分区容错性（Partition tolerance）</strong>：系统中任何信息的丢失或失败都不会影响系统的继续运行。</li></ul><h3 id="Nacos-的-CAP-配置"><a href="#Nacos-的-CAP-配置" class="headerlink" title="Nacos 的 CAP 配置"></a>Nacos 的 CAP 配置</h3><p>Nacos 提供了两种运行模式，可以根据需要在一致性和可用性之间进行选择，确保系统按需求正确运行：</p><p>在CAP理论中，Nacos可以配置为更偏向于“一致性（C）”和“分区容错性（P）”，也可以配置为更偏向于“可用性（A）”和“分区容错性（P）”，这取决于具体的使用场景和配置。</p><ul><li><p>不同的运行模式：</p><ul><li><p>AP 模式：</p><ul><li><p>当运行在 AP 模式下，Nacos 更偏向于高可用性和分区容错性。这在大多数服务发现场景是可取的，因为在这种情况下，即使在网络分区或部分系统故障的情况下，服务仍然需要被发现和消费。</p></li><li><p>在 AP 模式下，Nacos 可能会牺牲一致性来保证高可用性。也就是说，服务的注册和发现可能不会立即反映最新状态，但服务的发现和路由功能仍然是可用的。</p></li><li><p>作为服务注册中心：</p><ul><li>当Nacos用作服务注册中心时，它通常运行在AP模式。这是因为在服务发现的场景中，可用性和分区容错性通常被视为更重要。即使在网络分区或部分服务不可用的情况下，服务注册和发现功能仍然可以正常工作，尽管这可能会导致短暂的数据不一致。</li></ul></li></ul></li><li><p>CP 模式：</p><ul><li><p>当运行在 CP 模式下，Nacos 更注重一致性和分区容错性。这适用于配置管理场景，因为配置信息的正确性和一致性是非常重要的。</p></li><li><p>在 CP 模式下，Nacos 会确保配置的一致性，即使这可能意味着在网络分区或其他问题发生时，对配置的访问可能会受到影响。</p></li><li><p>作为配置中心：</p><ul><li>当Nacos用作配置中心时，它通常运行在CP模式。在配置管理场景下，一致性是非常关键的，因为配置信息需要在所有服务实例之间保持一致。Nacos 确保即使在网络分区或故障的情况下，所有服务实例也能获取到一致的配置信息。</li></ul></li></ul></li></ul></li></ul>]]></content>
      
      
      <categories>
          
          <category> 微服务 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> SpringCloud Alibaba </tag>
            
            <tag> Nacos </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>SpringCloud-Ribbon</title>
      <link href="/2024/04/23/springcloud-ribbon/"/>
      <url>/2024/04/23/springcloud-ribbon/</url>
      
        <content type="html"><![CDATA[<p>Ribbon 是一个客户端负载均衡器，它可以在调用微服务时提供<strong>负载均衡</strong>的功能。在Spring Cloud 中，Ribbon 通常与 Eureka、Nacos 等其他服务发现组件结合使用，以实现在客户端进行服务的动态查找和负载均衡。Ribbon <strong>主要用于控制 HTTP 和 TCP 客户端的行为</strong>。</p><h2 id="核心特性"><a href="#核心特性" class="headerlink" title="核心特性"></a>核心特性</h2><ol><li><strong>服务发现集成</strong>：当 Ribbon 客户端启动时，它会从服务组件（如Eureka、Nacos等）获取可用的服务实例列表，并对这些实例进行负载均衡策略。</li><li><strong>负载均衡策略</strong>：Ribbon 内置了多种负载均衡策略，如<strong>轮询</strong>、<strong>随机</strong>、<strong>权重</strong>等（默认是轮询）。用户可以选择合适的策略，也可以自定义策略。</li><li><strong>容错机制</strong>：Ribbon 提供了失败重试机制，可以在调用失败时自动重试其他实例。这增加了调用的健壮性。</li><li><strong>客户端缓存和批处理</strong>：Ribbon 可以缓存客户端请求，支持请求的批量发送，优化网络使用等。</li><li><strong>可配置性</strong>：Ribbon 允许开发者通过配置文件定制和调整其行为，包括超时设置、重试策略、连接池大小等。</li></ol><h3 id="工作流程"><a href="#工作流程" class="headerlink" title="工作流程"></a>工作流程</h3><ol><li><strong>服务发现</strong>：首先从服务注册中心获取可用的服务实例列表。</li><li><strong>选择服务实例</strong>：根据配置的负载均衡策略，从可用服务实例中选择一个。</li><li><strong>服务调用</strong>：对选定的服务实例进行网络请求。</li><li><strong>错误处理和重试</strong>：在发生错误时，根据配置的策略进行重试或失败回退。</li></ol><h3 id="使用场景"><a href="#使用场景" class="headerlink" title="使用场景"></a>使用场景</h3><ol><li><strong>微服务间的调用</strong>：在微服务架构中，服务实例可能会动态地上下线，Ribbon可以帮助客户端自动发现可用的服务实例，并进行负载均衡。</li><li><strong>消除单点故障</strong>：通过Ribbon的负载均衡，请求可以被分散到多个服务实例，从而消除单点故障。</li><li><strong>通过系统吞吐量</strong>：通过将请求均匀分配到多个服务实例，可以提高系统的整体吞吐量。</li></ol><h3 id="故障处理：使用-Ribbon-的失败重试和回退机制"><a href="#故障处理：使用-Ribbon-的失败重试和回退机制" class="headerlink" title="故障处理：使用 Ribbon 的失败重试和回退机制"></a>故障处理：使用 Ribbon 的失败重试和回退机制</h3><p><strong>失败重试</strong>：</p><p>Ribbon 允许配置自动重试机制，这意味着当服务调用失败时，Ribbon 可以自动重新发送请求到同一个或不同的服务实例。这在临时网络问题或服务瞬时故障时特别有用。</p><p><strong>配置示例</strong>：</p><p>在<code>application.properties</code>文件中，可以设置重试次数和条件:</p><pre><code>ribbon:  MaxAutoRetries=1                 # 同一个服务实例的最大重试次数  MaxAutoRetriesNextServer=2       # 尝试另一个服务实例的最大重试次数  OkToRetryOnAllOperations=true    # 允许对所有请求操作进行重试</code></pre><p><strong>回退策略</strong>：</p><p>回退策略允许在调用失败时提供一个默认的响应，这通常通过集成 Hystrix 来实现。Hystrix 提供了断路器功能，当服务不可用时可以自动切换到预定义的回退逻辑。</p><p><strong>实现示例</strong>：</p><p>使用Hystrix 在 Ribbon 调用中添加回退逻辑，例如在使用 <code>RestTemplate</code>进行服务调用时：</p><pre class="line-numbers language-language-java"><code class="language-language-java">@Servicepublic class MyService &#123;    @Autowired    private RestTemplate restTemplate;    @HystrixCommand(fallbackMethod = "reliable")    public String getData(String serviceId) &#123;        return restTemplate.getForObject("http://" + serviceId + "/data", String.class);    &#125;    public String reliable(String serviceId) &#123;        return "Default Data";    &#125;&#125;<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><h3 id="性能优化：调整-Ribbon-的性能设置"><a href="#性能优化：调整-Ribbon-的性能设置" class="headerlink" title="性能优化：调整 Ribbon 的性能设置"></a>性能优化：调整 Ribbon 的性能设置</h3><p>在使用 Ribbon 进行服务调用时，适当的性能优化可以提高响应速度和系统吞吐量。</p><p><strong>客户端超时设置</strong></p><p>调整请求超时设置可以防止服务调用过长时间等待，影响用户体验和资源使用效率。</p><pre><code>ribbon:  ReadTimeout=5000     # 读取超时时间（毫秒）  ConnectTimeout=1000  # 连接超时时间（毫秒）</code></pre><p><strong>请求批处理</strong></p><p>如果 Ribbon 用于大量的请求调用，可以采用请求批处理策略，合并短时间内的多个请求，减少网络往返次数，提高效率。</p><p><strong>连接池配置</strong></p><p>配置连接池可以重用 HTTP 连接，减少频繁建立连接的开销。</p><pre class="line-numbers language-language-java"><code class="language-language-java">@Beanpublic ClientHttpRequestFactory clientHttpRequestFactory() &#123;    HttpComponentsClientHttpRequestFactory factory = new HttpComponentsClientHttpRequestFactory();    factory.setReadTimeout(5000);    factory.setConnectTimeout(1000);    factory.setHttpClient(httpClient()); // 自定义配置 HttpClient    return factory;&#125;private HttpClient httpClient() &#123;    PoolingHttpClientConnectionManager connectionManager = new PoolingHttpClientConnectionManager();    connectionManager.setMaxTotal(200);    // 最大连接数    connectionManager.setDefaultMaxPerRoute(50); // 每个路由的默认最大连接数    return HttpClientBuilder.create().setConnectionManager(connectionManager).build();&#125;<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre>]]></content>
      
      
      <categories>
          
          <category> 微服务 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> SpringCloud </tag>
            
            <tag> Ribbon </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>SpringCloud Alibaba-Sentinel</title>
      <link href="/2024/04/23/springcloud-alibaba-sentinel/"/>
      <url>/2024/04/23/springcloud-alibaba-sentinel/</url>
      
        <content type="html"><![CDATA[<p>Sentinel 是一个开源的流量控制组件，由阿里巴巴开源。它主要用于微服务的<strong>稳定性</strong>和<strong>可靠性</strong>保障，提供了丰富的功能来应对各种服务和应用的高可用需求。Sentinel 特别适合用来处理微服务架构中的<strong>流量控制</strong>、<strong>熔断降级</strong>、<strong>系统自适应保护</strong>等问题。</p><h2 id="核心功能"><a href="#核心功能" class="headerlink" title="核心功能"></a>核心功能</h2><ol><li>流量控制：<ul><li>Sentinel 可以通过定义流量控制规则来限制访问频率，保护系统不被高流量压垮。这些规则可以基于QPS（每秒查询率）或并发线程数设置。</li></ul></li><li>熔断降级：<ul><li>在服务不稳定（如响应时间过长或异常率过高）时会自动进行熔断，快速返回错误响应或者调用回退逻辑，防止服务雪崩效应。</li></ul></li><li>系统自适应保护：<ul><li>根据系统的负载情况（如CPU使用率、总体平均响应时间等）自动调整流量控制规则，确保系统在安全的负载下运行。</li></ul></li><li>热点参数限流：<ul><li>支持对经常访问的“热点”数据进行流量控制，比如对热门商品的请求过于频繁时自动进行限流。</li></ul></li><li>实时监控和动态规则配置：<ul><li>Sentinel 提供了实时监控功能，可以实时观察系统的运行状态和规则的执行效果（流量、熔断、响应时间等信息）。同时，支持通过控制台动态修改流量控制规则，无需重启应用。</li></ul></li><li>规则的优先级：<ul><li>Sentinel 支持多种规则，如流量控制规则、降级规则、系统保护规则等。这些规则有不同的优先级，当多个规则同时触发时，高优先级的规则会先被执行。</li></ul></li></ol><h3 id="使用场景"><a href="#使用场景" class="headerlink" title="使用场景"></a>使用场景</h3><ol><li><strong>微服务流量控制</strong>：在微服务架构中，可以使用Sentinel对服务间的调用进行流量控制。</li><li><strong>API网关流量控制</strong>：在API网关中，可以使用Sentinel对外部的请求进行流量控制。</li><li><strong>分布式系统熔断降级</strong>：在分布式系统中，可以使用Sentinel对故障的服务进行熔断降级。</li><li><strong>系统负载保护</strong>：当系统的负载过高时，可以使用Sentinel进行流量控制，保护系统。</li></ol><h3 id="作用"><a href="#作用" class="headerlink" title="作用"></a>作用</h3><ol><li><strong>流量控制</strong>：保护系统免受恶意攻击和流量峰值。</li><li><strong>熔断控制</strong>：在服务出现问题时，自动进行熔断降级，保护系统。</li><li><strong>系统负载保护</strong>：在系统负载过高时，自动进行流量控制，保护系统。</li><li><strong>实时监控</strong>：提供实时的监控和统计功能，帮助运维人员了解系统的状态。</li></ol><h3 id="底层原理"><a href="#底层原理" class="headerlink" title="底层原理"></a>底层原理</h3><ul><li>Sentinel 使用<code>滑动窗口算法</code>来统计请求的数量和响应时间。这使得 Sentinel 可以实时地获取系统的运行状态，并根据这些状态做出限流、降级和熔断的决策。</li><li>Sentinel 的核心是一系列的处理器和规则。处理器负载统计数据和执行控制逻辑，而规则定义了何时触发控制逻辑。</li></ul>]]></content>
      
      
      <categories>
          
          <category> 微服务 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> SpringCloud Alibaba </tag>
            
            <tag> Sentinel </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>SpringCloud-Gateway</title>
      <link href="/2024/04/22/springcloud-gateway/"/>
      <url>/2024/04/22/springcloud-gateway/</url>
      
        <content type="html"><![CDATA[<p>Gateway是Spring Cloud的一个组件，用于构建API网关。API网关是微服务架构中的一个关键组件，它负责<strong>路由请求转发</strong>、<strong>负载均衡</strong>、<strong>断路器</strong>、<strong>安全</strong>、<strong>跨域</strong>、<strong>请求头</strong>和<strong>响应头的修改</strong>等。</p><h3 id="三大特性"><a href="#三大特性" class="headerlink" title="三大特性"></a>三大特性</h3><ul><li><strong>Routes</strong>：路由</li><li><strong>Filters</strong>：过滤器</li><li><strong>Predicates</strong>：断言</li></ul><h3 id="工作原理"><a href="#工作原理" class="headerlink" title="工作原理"></a>工作原理</h3><ul><li><p><strong>路由</strong>：客户端向 Spring Cloud Gateway 发出请求后，Gateway Handler Mapping 查找与请求相匹配的路由。</p></li><li><p>过滤器</p><p>：在请求达到实际服务之前，Gateway 可以使用过滤器来修改传入的 HTTP 请求；同理，返回的 HTTP 响应也可以被过滤器处理。</p><ul><li>有两种类型的过滤器，<code>pre 过滤器</code>和<code>post 过滤器</code>。pre 过滤器在路由请求之前执行，post 过滤器在路由请求之后执行。</li></ul></li><li><p><strong>转发</strong>：最后请求将被转发到实际的服务。</p></li></ul><h3 id="使用场景"><a href="#使用场景" class="headerlink" title="使用场景"></a>使用场景</h3><ul><li><strong>路由和负载均衡</strong>：将请求路由到合适的微服务实例。</li><li><strong>安全</strong>：如身份验证和授权。</li><li><strong>限流</strong>：限制请求的速率。</li><li><strong>缓存</strong>：缓存请求的响应。</li><li><strong>断路</strong>：在某个微服务实例出现问题时，快速失败。</li><li><strong>跨域</strong>：处理跨域资源共享（CORS）请求。</li><li><strong>请求和响应的修改</strong>：如添加、删除或修改头信息。</li></ul><h3 id="作用"><a href="#作用" class="headerlink" title="作用"></a>作用</h3><ul><li><strong>统一入口</strong>：为微服务提供一个统一的访问入口，简化客户端调用。</li><li><strong>安全防护</strong>：提供安全机制，如身份验证、授权和防止恶意攻击。</li><li><strong>性能优化</strong>：如负载均衡、缓存和限流。</li><li><strong>故障隔离</strong>：如断路和重试。</li></ul><h3 id="定义路由规则"><a href="#定义路由规则" class="headerlink" title="定义路由规则"></a>定义路由规则</h3><p>Gateway 使用一组路由规则来确定如何处理传入的 HTTP 请求。每条路由规则定义了一个<strong>目标</strong> URI 、一组<strong>断言</strong>和一组<strong>过滤器</strong>。当断言为真时，请求会被路由到目标 URI ，并在路由之前和之后应用过滤器。</p><p>在 application.yml 中：</p><pre><code>spring:  cloud:    gateway:      routes:      ## 路由规则的唯一标识符      - id: user-service        uri: lb://user-service        predicates:        - Path=/user/**        filters:        - AddRequestHeader=X-Request-Foo, Bar</code></pre><p>在 Spring Cloud Gateway 的路由定义中：</p><ul><li><p><strong>id</strong>：这是路由的唯一标识符。它用于区分和标识不同的路由规则。在管理、监控或日志中，这个<code>id</code>可以帮助我们快速识别和引用特定的路由。</p></li><li><p>uri</p><p>：这是路由的目标URI。当</p><p>请求满足某个路由的断言时，它会被转发到这个URI</p><p>。这个</p><pre><code>URI</code></pre><p>可以是一个具体的地址，也可以是一个服务的逻辑名称。</p><ul><li>当URI的前缀是 <code>lb://&#123;&#123;微服务名称&#125;&#125;</code> 时，表示这是一个逻辑地址，需要使用客户端负载均衡器（如 Ribbon）来解析。在这个例子中，<code>lb://user-service</code> 表示请求会被负载均衡到名为 <code>user-service</code> 的服务实例。</li><li>如果 URI 是一个 HTTP 或 HTTPS 地址，lb:&#x2F;&#x2F;<a href="https://www.baidu.com,那么请求会被直接转发到这个地/">https://www.baidu.com，那么请求会被直接转发到这个地</a></li></ul></li><li><p>predicates 路由谓词</p><p>：</p><ul><li><p>谓词用于匹配和过滤HTTP请求。</p></li><li><p>SpringCloud Gateway 提供了多种内置谓词，如：</p><ul><li><p>Path</p><p>：根据请求路径匹配。</p><ul><li><strong>Method</strong>：根据HTTP方法匹配。</li><li><strong>Header</strong>：根据请求头匹配。</li><li><strong>Query</strong>：根据查询参数匹配。</li></ul></li></ul></li></ul></li><li><p>filters 过滤器</p><p>：</p><ul><li>Gateway 提供了多种过滤器，这些过滤器分为全局过滤器和路由过滤器。全局过滤器对所有请求都有效，而路由过滤器只对特定的路由有效。</li><li>过滤器的执行顺序是由其 order 属性决定的。请求首先会经过所有的 pre 类型的过滤器，然后路由到下游服务，最后再经过所有的 post 类型的过滤器。</li></ul></li></ul><p>上述配置定义了一个路由规则，当请求的路径匹配 <code>/user/**</code> 断言时，它会被路由到名为 <code>user-service</code> 的微服务，并在请求头中添加一个名为 X-Request-Foo 的头信息。</p><h3 id="定义过滤器"><a href="#定义过滤器" class="headerlink" title="定义过滤器"></a>定义过滤器</h3><pre class="line-numbers language-language-java"><code class="language-language-java">@Beanpublic RouteLocator customRouteLocator(RouteLocatorBuilder builder) &#123;    return builder.routes()        .route("path_route", r -> r.path("/get")            .filters(f -> f.addRequestHeader("Hello", "World"))            .uri("<http://httpbin.org>"))        .build();&#125;<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><p>上述代码定义了一个路由规则，当请求的路径为 &#x2F;get 时，它会被路由到 <a href="http://httpbin.org/get">http://httpbin.org/get</a> ，并在请求头中添加一个名为 Hello 的头信息。</p><h3 id="SpringCloud-Gateway的应用"><a href="#SpringCloud-Gateway的应用" class="headerlink" title="SpringCloud Gateway的应用"></a>SpringCloud Gateway的应用</h3><h3 id="1-动态路由"><a href="#1-动态路由" class="headerlink" title="1. 动态路由"></a>1. 动态路由</h3><ul><li>Gateway 支持动态路由，允许您在运行时添加、修改或删除路由规则。</li><li>这是通过与Spring Cloud Config 或其他外部配置源的集成来实现的。</li><li>当路由配置发生变化时，Gateway 可以自动刷新路由规则，而无需重新启动应用。</li></ul><h3 id="2-API聚合"><a href="#2-API聚合" class="headerlink" title="2. API聚合"></a>2. API聚合</h3><p>网关可以用来聚合多个后端服务的API调用结果。例如，客户端可以只发送一个请求到网关，网关则分别向多个服务发请求，然后将结果聚合后返回给客户端。这可以减少客户端与服务间的通信次数，并简化客户端逻辑。</p><h3 id="3-全局过滤器"><a href="#3-全局过滤器" class="headerlink" title="3. 全局过滤器"></a>3. 全局过滤器</h3><p>除了标准的路由过滤器外，Spring Cloud Gateway 还提供全局过滤器，它对所有的路由有效。这些全局过滤器可以用来实现跨服务的逻辑，如权限校验、日志跟踪记录、安全检查等。</p><h3 id="4-断路器集成"><a href="#4-断路器集成" class="headerlink" title="4. 断路器集成"></a>4. 断路器集成</h3><ul><li>Spring Cloud GateWay 支持与 Hystrix 断路器的集成。当某个下游服务出现问题时，断路器可以防止请求继续传递给服务，从而防止系统雪崩。</li><li>通过配置，你可以为特定的路由定义断路器的行为，例如失败的阈值和回退的响应。</li></ul><h3 id="5-重试机制"><a href="#5-重试机制" class="headerlink" title="5. 重试机制"></a>5. 重试机制</h3><ul><li>如果某个微服务实例失败，Gateway 可以配置为自动重试其他实例。</li><li>重试可以基于不同的策略，如固定延迟、指数退避等。</li><li>这增加了系统的弹性和可用性。</li></ul><h3 id="6-请求速率限制"><a href="#6-请求速率限制" class="headerlink" title="6. 请求速率限制"></a>6. 请求速率限制</h3><p>通过与Redis等技术的集成，Spring Cloud Gateway 支持对客户端请求进行速率限制，这有助于防止API滥用并保护后端服务免受过载。</p><ul><li>例如，你可以为特定的用户或IP设置每秒的请求限制。</li><li>限流可以帮助您保护系统免受恶意攻击和意外的流量峰值。</li></ul><h3 id="7-集成与第三方服务发现"><a href="#7-集成与第三方服务发现" class="headerlink" title="7. 集成与第三方服务发现"></a>7. 集成与第三方服务发现</h3><ul><li>Gateway 可以与Eureka、Consul、Zookeeper等服务发现组件集成。</li><li>当使用 <code>lb://&#123;&#123;微服务名称&#125;&#125;</code> 前缀的逻辑地址时，Gateway 会从服务发现组件中自动获取可用的服务实例，并进行负载均衡。</li></ul><h2 id="关于底层的负载均衡器"><a href="#关于底层的负载均衡器" class="headerlink" title="关于底层的负载均衡器"></a>关于底层的负载均衡器</h2><p>在Spring Cloud的较早版本中，<strong>Ribbon</strong>是默认的客户端负载均衡器。但从Spring Cloud Greenwich版本开始，官方推荐使用<strong>Spring Cloud LoadBalancer</strong>，这是一个基于Spring Reactor的新的轻量级、反应式负载均衡器。</p><p>Spring Cloud LoadBalancer的特点：</p><ul><li>它是一个反应式的负载均衡器，并且完全集成在WebFlux环境中。</li><li>提供了一个简单的轮询和随机负载均衡策略的默认实现，也支持自定义策略。</li><li>它使用了Spring Boot 2.x中引入的HttpClient或WebClient来进行实际的服务调用。</li></ul><p>虽然Ribbon项目现在处于维护模式，不再建议用于新的项目，但现有项目可以继续使用Ribbon而无需迁移到Spring Cloud LoadBalancer。</p><p>在实际的Spring Cloud项目中，你应该确保使用的是兼容的Spring Cloud版本，并且对应地选择使用Ribbon还是Spring Cloud LoadBalancer。如果你的Spring Cloud版本较新（比如Hoxton版本及以后），应该使用Spring Cloud LoadBalancer作为客户端负载均衡器。</p><p>总的来说，SpringCloud Gateway 是一个功能强大的API网关，它提供了一系列的工具和特性，使得开发者可以轻松地构建和管理微服务应用的API网关。</p>]]></content>
      
      
      <categories>
          
          <category> 微服务 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> SpringCloud </tag>
            
            <tag> Gateway </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>SpringBoot基础巩固</title>
      <link href="/2024/04/10/springboot/"/>
      <url>/2024/04/10/springboot/</url>
      
        <content type="html"><![CDATA[<h2 id="约定大于配置、自动配置"><a href="#约定大于配置、自动配置" class="headerlink" title="约定大于配置、自动配置"></a>约定大于配置、自动配置</h2><h3 id="约定大于配置"><a href="#约定大于配置" class="headerlink" title="约定大于配置"></a>约定大于配置</h3><p>SpringBoot采用了<strong>约定大于配置</strong>的原则，这意味着如果你遵循某些默认的约定（例如，将数据库配置放在特定的位置），SpringBoot 会为你自动配置大部分的应用设置。这大大减少了配置的需求和可能出错的地方。</p><h3 id="自动配置"><a href="#自动配置" class="headerlink" title="自动配置"></a><strong>自动配置</strong></h3><p>SpringBoot可以根据你的项目中的jar依赖自动配置你的应用。例如，如果你的项目中有<strong>spring-boot-start-web</strong>依赖，SpringBoot会认为你想创建一个Web应用，并自动为你配置 Tomcat 和 SpringMVC。</p><h3 id="工作流程简述"><a href="#工作流程简述" class="headerlink" title="工作流程简述"></a><strong>工作流程简述</strong></h3><ol><li><p>应用启动时，</p><pre><code>@SpringBootApplication</code></pre><p>注解中的</p><pre><code>@EnableAutoConfiguration</code></pre><p>注解激活自动配置机制。</p><ol><li>SpringBootApplication 是一个组合注解，里面包含了 <code>@Configuration</code>、<code>@ComponentScan</code>、<code>@EnableAutoConfiguration</code>。</li></ol></li><li><p>Spring Boot会读取所有<code>META-INF/spring.factories</code>文件，查找并加载所有指定的自动配置类。</p></li><li><p>自动配置类会根据条件注解（如<code>@ConditionalOnClass</code>等）判断条件是否满足，决定是否执行相应的自动配置逻辑。</p></li><li><p>自动配置类会被加载到Spring容器中，提供所需要的bean实例，完成自动配置。</p></li></ol><h3 id="SpringBoot-中常用的注解"><a href="#SpringBoot-中常用的注解" class="headerlink" title="SpringBoot 中常用的注解"></a><strong>SpringBoot 中常用的注解</strong></h3><ol><li><p>@SpringBootApplication</p><p>：复合注解，包括 @SpringBootConfiguration、@EnableAutoConfiguration 和 @ComponentScan。</p><ul><li>它标记一个类作为 SpringBoot 应用的主配置类。</li></ul></li><li><p>@EnableAutoConfiguration</p><p>：告诉 SpringBoot 启动自动配置</p><ul><li>它会尝试根据添加的 jar 依赖自动配置应用。</li></ul></li><li><p>@ConfigurationProperties</p><p>：用于配置文件中的属性绑定到一个 Java 对象</p><ul><li>例如，可以将 application.properties 或 application.yml 中的属性绑定到一个 Bean。</li></ul></li><li><p>@ComponentScan</p><p>：Spring 会自动扫描指定包下的所有组件、配置类和服务。</p><ul><li>通常与 @SpringBootApplication 搭配使用</li></ul></li><li><p>@Bean</p><p>：用于标记一个方法为 Bean 的生产者。</p><ul><li>该方法的返回值会被添加到 Spring 上下文中。</li></ul></li><li><p><strong>@Value</strong>：用于将配置文件中的一个属性值注入到Bean属性中。</p></li><li><p>@RestController</p><p>：是一个复合注解，它包括 @Controller 和 @ResponseBody。</p><ul><li>用于创建 RESTful Web 服务。</li></ul></li><li><p>@RequestMapping</p><p>：用于定义 URL 映射和 HTTP 操作类型（如GET、POST）。</p><ul><li>可以在类或方法上使用。</li></ul></li><li><p><strong>@GetMapping, @PostMapping, @PutMapping, @DeleteMapping</strong>：这些是@RequestMapping的特定快捷方式，用于处理特定的HTTP操作。</p></li><li><p>@PathVariable</p><p>：用于从 URL 模板中提取值。</p><ul><li>例如，在 @GetMapping(“&#x2F;users&#x2F;{id}”) 中提取 id。</li></ul></li><li><p>@RequestParam</p><p>：用于从请求参数中提取值。</p><ul><li>例如，在查询参数 ?name&#x3D;value 中提取 name。</li></ul></li><li><p>@Autowired</p><p>：用于自动注入 Bean。</p><ul><li>Spring 会查找并注入匹配的 Bean。</li></ul></li><li><p>@Service, @Repository, @Controller, @Component</p><p>：这些注解用于定义 Bean，并告诉 Spring 这些类是 Spring 组件。</p><ul><li>Spring 会自动检测并注册这些组件。</li></ul></li></ol>]]></content>
      
      
      <categories>
          
          <category> 微服务 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> SpringBoot </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>Spring基础巩固</title>
      <link href="/2024/04/08/spring/"/>
      <url>/2024/04/08/spring/</url>
      
        <content type="html"><![CDATA[<p>Spring 框架是 Java 开发中最流行的框架之一，它提供了全面的基础设施支持，使得开发者可以轻松构建企业级应用程序。</p><h2 id="IOC（Inversion-of-Control）"><a href="#IOC（Inversion-of-Control）" class="headerlink" title="IOC（Inversion of Control）"></a>IOC（Inversion of Control）</h2><h3 id="定义"><a href="#定义" class="headerlink" title="定义"></a>定义</h3><p>IoC 即控制反转，是一种设计原则，它将应用程序的控制权从程序代码本身转移到外部容器或框架中。传统的程序设计中，程序内部直接控制程序流程和对象的创建与销毁，而在IoC中，对象的创建和管理由容器来完成，应用程序只需要描述组件之间的依赖关系，而不需要负责对象的创建和销毁。</p><h3 id="作用"><a href="#作用" class="headerlink" title="作用"></a>作用</h3><p>IoC 的主要作用在于降低了组件之间的耦合度，使得应用程序更加灵活、可扩展和易于维护。通过将对象的创建和管理交给容器，我们可以更容易地替换、扩展和重用组件，同时也能更好地实现面向接口编程。</p><h3 id="实现原理"><a href="#实现原理" class="headerlink" title="实现原理"></a>实现原理</h3><p>IoC的实现原理主要通过依赖注入（Dependency Injection）来实现。依赖注入是IoC的一种具体实现方式，它通过容器来动态地将组件之间的依赖关系注入到组件中，从而实现控制反转。</p><p>依赖注入有三种主要的方式：</p><p>构造器注入(需要结合@Configuration来使用)</p><ul><li>通过构造函数来注入依赖对象。</li><li><strong>优势</strong>：明确表明了类的依赖关系，使得类的依赖关系更加明确和可见。</li><li><strong>劣势</strong>：当类有多个依赖关系时，构造函数的参数列表可能变得很长，增加了代码的复杂性。</li></ul><pre class="line-numbers language-language-java"><code class="language-language-java"> private final UserRepository userRepository;    // 构造器注入    public UserService(UserRepository userRepository) &#123;        this.userRepository = userRepository;    &#125;        ...        @Configuration    public class AppConfig &#123;    @Bean    public UserRepository userRepository() &#123;        return new UserRepository();    &#125;    @Bean    public UserService userService(UserRepository userRepository) &#123;        return new UserService(userRepository);    &#125;&#125;<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><p>Setter注入（需要结合**@Autowired来使用**）</p><ul><li>通过Setter方法来注入依赖对象。</li><li>优劣势：同上</li></ul><pre class="line-numbers language-language-java"><code class="language-language-java">    private UserRepository userRepository;    // Setter注入    public void setUserRepository(UserRepository userRepository) &#123;        this.userRepository = userRepository;    &#125;<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><p>字段注入</p><ul><li>通过字段直接注入依赖对象。</li><li><strong>优势</strong>：简洁明了，不需要额外的构造函数或Setter方法。</li><li><strong>劣势</strong>：对象的依赖关系被直接暴露在类的字段中，降低了类的封装性。</li></ul><pre class="line-numbers language-language-java"><code class="language-language-java">    @Autowired    private UserRepository userRepository;<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span></span></code></pre><h3 id="应用场景"><a href="#应用场景" class="headerlink" title="应用场景"></a>应用场景</h3><ul><li>控制层&#x2F;服务层的依赖注入</li><li>数据访问层与业务逻辑层的解耦</li><li>组件的替换和扩展</li></ul><h2 id="AOP（Aspect-Oriented-Programming）"><a href="#AOP（Aspect-Oriented-Programming）" class="headerlink" title="AOP（Aspect-Oriented Programming）"></a>AOP（Aspect-Oriented Programming）</h2><h3 id="定义-1"><a href="#定义-1" class="headerlink" title="定义"></a>定义</h3><p>AOP 即面向横面编程，是一种编程范式，它允许将横切关注点（cross-cutting concerns）从业务逻辑中分离出来，将它们定义为独立的模块，然后以声明的方式将这些模块应用到多个不同的组件中。这样做的目的是提高代码的重用性、可维护性和可扩展性。</p><h3 id="作用-1"><a href="#作用-1" class="headerlink" title="作用"></a>作用</h3><p>AOP 的作用在于解决了重复性代码的问题，将横切关注点（如日志记录、事务管理、安全检查等）与核心业务逻辑分离开来，使得代码更加模块化、清晰可读。</p><h3 id="实现原理-1"><a href="#实现原理-1" class="headerlink" title="实现原理"></a>实现原理</h3><p>在Spring中，AOP主要通过动态代理实现，具体而言有两种主要的实现方式：JDK动态代理和CGLIB动态代理。</p><ol><li><p><strong>JDK 动态代理：</strong></p><ul><li>JDK 动态代理是基于接口（UserService）的代理，它要求目标类（UserServiceImpl）必须实现一个接口。</li><li>当目标类实现了接口时，Spring 容器会自动使用 JDK 动态代理生成一个实现了该接口（UserService）的代理类，并在代理类中织入切面逻辑。</li><li>JDK 动态代理通过  <strong><code>java.lang.reflect.Proxy</code></strong> 类和 <strong><code>java.lang.reflect.InvocationHandler</code></strong> 接口来实现。</li></ul><pre class="line-numbers language-language-java"><code class="language-language-java">public interface UserService &#123;    void addUser(String username);&#125;public class UserServiceImpl implements UserService &#123;    @Override    public void addUser(String username) &#123;        // 添加用户逻辑...        System.out.println("User added: " + username);    &#125;&#125;public class LoggingAspect implements InvocationHandler &#123;    private Object target;    public LoggingAspect(Object target) &#123;        this.target = target;    &#125;    @Override    public Object invoke(Object proxy, Method method, Object[] args) throws Throwable &#123;        System.out.println("Before calling method: " + method.getName());        Object result = method.invoke(target, args);        System.out.println("After calling method: " + method.getName());        return result;    &#125;&#125;public class Main &#123;    public static void main(String[] args) &#123;        UserService target = new UserServiceImpl();        LoggingAspect loggingAspect = new LoggingAspect(target);        UserService proxy = (UserService) Proxy.newProxyInstance(                target.getClass().getClassLoader(),                target.getClass().getInterfaces(),                loggingAspect);        proxy.addUser("Alice");    &#125;&#125;<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><p>首先定义了一个 <strong><code>UserService</code></strong> 接口，其中包含了一个 <strong><code>addUser</code></strong> 方法用于添加用户。然后，我们创建了一个 <strong><code>UserServiceImpl</code></strong> 类来实现这个接口，其中实现了 <strong><code>addUser</code></strong> 方法。</p><p>接着，我们创建了一个名为 <strong><code>LoggingAspect</code></strong> 的日志记录类，实现了 <strong><code>InvocationHandler</code></strong> 接口。在这个类中，我们实现了 <strong><code>invoke</code></strong> 方法，该方法会在代理对象调用任何方法时被调用。在 <strong><code>invoke</code></strong> 方法中，我们首先记录了目标方法调用前的日志，然后调用目标方法，最后记录了目标方法调用后的日志。</p><p>在 <strong><code>Main</code></strong> 类中，我们首先创建了一个 <strong><code>UserService</code></strong> 的实例 <strong><code>target</code></strong>，然后将这个实例传递给 <strong><code>LoggingAspect</code></strong> 的构造函数创建了一个 <strong><code>LoggingAspect</code></strong> 的实例 <strong><code>loggingAspect</code></strong>。接着，我们使用 <strong><code>Proxy.newProxyInstance</code></strong> 方法为 <strong><code>UserService</code></strong> 接口创建了一个代理对象 <strong><code>proxy</code></strong>，并将 <strong><code>loggingAspect</code></strong> 设置为代理对象的调用处理器。最后，我们调用了 <strong><code>proxy</code></strong> 的 <strong><code>addUser</code></strong> 方法。</p></li><li><p>CGLIB 动态代理：</p><ul><li>CGLIB 动态代理是基于继承的代理，它不要求目标必须实现接口。</li><li>当目标类没有实现接口时，Spring 容器会自动使用CGLIB动态代理生成一个目标类的子类，并在子类中织入切面逻辑。</li><li>CGLIB 动态代理通过字节码增强技术来实现。</li></ul><pre class="line-numbers language-language-java"><code class="language-language-java">public class UserService &#123;    public void addUser(String username) &#123;        // 添加用户逻辑...        System.out.println("User added: " + username);    &#125;&#125;public class LoggingAspect implements MethodInterceptor &#123;    @Override    public Object intercept(Object obj, Method method, Object[] args, MethodProxy proxy) throws Throwable &#123;        System.out.println("Before calling method: " + method.getName());        Object result = proxy.invokeSuper(obj, args);        System.out.println("After calling method: " + method.getName());        return result;    &#125;&#125;public class Main &#123;    public static void main(String[] args) &#123;        Enhancer enhancer = new Enhancer();        enhancer.setSuperclass(UserService.class);        enhancer.setCallback(new LoggingAspect());        UserService proxy = (UserService) enhancer.create();        proxy.addUser("Alice");    &#125;&#125;<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre></li></ol><p>在Spring中，@Aspect 注解标记一个类后，Spring 会将其视为<strong>切面类</strong>，并在运行时自动为该类创建代理类对象，并将切面逻辑织入到代理对象中。就可以实现手动创建代理对象相似的功能，但更加简介和方便。</p><p>通过使用注解 @Aspect ，Spring 提供了一种声明式的方式来定义切面，并在AOP中应用它们，而无需手动编写代理逻辑和切面逻辑的代码。</p><ul><li><strong>@Before</strong>：在目标方法执行前执行切面逻辑。</li><li><strong>@After</strong>：在目标方法执行后（无论是否发生异常）执行切面逻辑。</li><li>@AfterReturing：在目标方法正常返回后执行切面逻辑。</li><li>@AfterThrowing：在目标方法抛出异常后执行切面逻辑。</li><li>@Around：在目标方法执行前后，控制目标方法的执行过程，可以自定义是否执行目标方法、执行前后的额外逻辑等。</li></ul><h3 id="应用场景-1"><a href="#应用场景-1" class="headerlink" title="应用场景"></a>应用场景</h3><ul><li><strong>访问控制</strong>：通过 AOP，可以很容易地实现安全性控制功能，如登录认证和权限检查、IP黑名单。</li><li><strong>监控和日志记录</strong>：AOP 可以用于监控应用程序允许状况，如统计访问次数、计算执行时间开销等等。</li><li><strong>全局异常处理</strong>：通过 AOP 可以轻松捕获和处理全局异常，而不是单独在每个方法中进行处理。</li><li><strong>数据校验</strong>：AOP 可以用于在数据进入应用程序之前对其进行校验，确保输入的有效性。</li></ul><p><strong>题外话</strong>：</p><p><strong><code>@ExceptionHandler</code></strong> 和 <strong><code>@ControllerAdvice</code></strong> 并不是严格意义上的 AOP（面向切面编程）的一部分，而是 Spring MVC 中的一种异常处理机制。虽然它们在某种程度上类似于 AOP，但它们更多地是关于异常处理的技术，而不是切面的概念。</p><p><strong><code>@ExceptionHandler</code></strong> 用于在控制器内部处理单个请求处理方法中抛出的异常，而 <strong><code>@ControllerAdvice</code></strong> 则用于集中处理应用程序中的异常，它通常与 <strong><code>@ExceptionHandler</code></strong> 结合使用来处理全局异常。</p><p>虽然 <strong><code>@ExceptionHandler</code></strong> 和 <strong><code>@ControllerAdvice</code></strong> 可以看作是一种通过注解来实现的切面功能，但它们更多地是针对异常处理的，而不是通常意义上的 AOP，它们不是通过动态代理来实现的。</p><h2 id="Spring-的启动流程"><a href="#Spring-的启动流程" class="headerlink" title="Spring 的启动流程"></a>Spring 的启动流程</h2><h3 id="启动Spring应用加载上下文"><a href="#启动Spring应用加载上下文" class="headerlink" title="启动Spring应用加载上下文"></a>启动Spring应用加载上下文</h3><ul><li><strong>初始化 SpringApplication 对象</strong>：运行 SpringApplication(…)，加载 Application 应用上下文。</li></ul><h3 id="加载配置"><a href="#加载配置" class="headerlink" title="加载配置"></a>加载配置</h3><ul><li><strong>加载配置文件</strong>：读取配置文件，如 <a href="http://application.properties/">application.properties</a> 或 application.yml</li></ul><h3 id="注册和加载Bean"><a href="#注册和加载Bean" class="headerlink" title="注册和加载Bean"></a>注册和加载Bean</h3><ul><li><strong>注册和加载Bean</strong>：通过@ComponentScan 注解扫描类路径下的组件，如 @Service、@Repository、@Controller 等注解，将它们作为 Bean 注册并加载到 Bean 容器中。</li></ul><h3 id="BeanFactory-准备"><a href="#BeanFactory-准备" class="headerlink" title="BeanFactory 准备"></a>BeanFactory 准备</h3><ul><li><strong>初始化 BeanFactory</strong>：配置 Bean 工厂，并加载 Bean 定义。</li></ul><h3 id="初始化-Bean"><a href="#初始化-Bean" class="headerlink" title="初始化 Bean"></a>初始化 Bean</h3><ul><li>对于每个 Bean 进行实例化、依赖注入、属性配置，并调用初始化方法等。</li></ul><h3 id="启动应用"><a href="#启动应用" class="headerlink" title="启动应用"></a>启动应用</h3><ul><li><strong>完成Bean 初始化</strong>：确保所有相关的 Bean 都已经创建并初始化。</li></ul><h3 id="就绪运行"><a href="#就绪运行" class="headerlink" title="就绪运行"></a>就绪运行</h3><ul><li>应用完全启动并就绪，可以接收服务请求。</li></ul><h2 id="Bean-的生命周期"><a href="#Bean-的生命周期" class="headerlink" title="Bean 的生命周期"></a>Bean 的生命周期</h2><h3 id="实例化-Bean"><a href="#实例化-Bean" class="headerlink" title="实例化 Bean"></a>实例化 Bean</h3><ul><li><strong>通过构造器创建 Bean 实例（尚未填充属性）</strong>。</li></ul><h3 id="设置属性值"><a href="#设置属性值" class="headerlink" title="设置属性值"></a>设置属性值</h3><ul><li><strong>Spring 注入属性值和 Bean 引用</strong>。</li></ul><h3 id="调用-Bean-名称感知方法"><a href="#调用-Bean-名称感知方法" class="headerlink" title="调用 Bean 名称感知方法"></a>调用 Bean 名称感知方法</h3><ul><li><strong>如果 Bean 实现了 BeanNameAware 接口，Spring 将 Bean 的 ID 传递给 setBeanName 方法</strong>。</li></ul><h3 id="调用-Bean-工厂感知方法"><a href="#调用-Bean-工厂感知方法" class="headerlink" title="调用 Bean 工厂感知方法"></a>调用 Bean 工厂感知方法</h3><ul><li><strong>如果 Bean 实现了 BeanFactoryAware 接口，Spring 调用 setBeanFactory 方法，传入 BeanFactory</strong>。</li></ul><h3 id="调用-ApplicationContext-感知"><a href="#调用-ApplicationContext-感知" class="headerlink" title="调用 ApplicationContext 感知"></a>调用 ApplicationContext 感知</h3><ul><li><strong>对于实现了 ApplicationContextAware 的 Bean，调用 setApplicationContext 方法</strong></li></ul><h3 id="前置处理器"><a href="#前置处理器" class="headerlink" title="前置处理器"></a>前置处理器</h3><ul><li><strong>BeanPostProcessor 的 postProcessBeforeInitialization 方法被调用</strong></li></ul><h3 id="初始化方法"><a href="#初始化方法" class="headerlink" title="初始化方法"></a>初始化方法</h3><ul><li><strong>如果 Bean 实现了 InitializingBean 接口，调用 afterPropertiesSet 方法</strong></li><li><strong>如果 Bean 在 XML 中声明了 init-method，调用指定的方法</strong></li></ul><h3 id="后置处理器"><a href="#后置处理器" class="headerlink" title="后置处理器"></a>后置处理器</h3><ul><li><strong>BeanPostProcessor 的 postProcessAfterInitialization 方法被调用</strong></li></ul><h3 id="Bean准备就绪"><a href="#Bean准备就绪" class="headerlink" title="Bean准备就绪"></a>Bean准备就绪</h3><ul><li><strong>此时 Bean 已经准备好并可以被应用程序使用了</strong>。</li></ul><h3 id="销毁-Bean"><a href="#销毁-Bean" class="headerlink" title="销毁 Bean"></a>销毁 Bean</h3><ul><li><strong>如果 Bean 实现了 DisposableBean 接口，调用 destroy 方法</strong>。</li><li><strong>如果 Bean 在 XML 中声明了 destroy-method，调用指定的方法</strong>。</li></ul><h2 id="Spring-加载-Bean的-方式"><a href="#Spring-加载-Bean的-方式" class="headerlink" title="Spring 加载 Bean的 方式"></a>Spring 加载 Bean的 方式</h2><ol><li>基于 XML 的配置</li><li>基于注解的配置</li><li>配置类（@Configuration + @Bean）</li><li>通过 FactoryBean</li></ol><h2 id="Spring-的-bean-为什么是单例的呢，并且除了单例以外还有什么形式，如果是多例的话，会有什么影响"><a href="#Spring-的-bean-为什么是单例的呢，并且除了单例以外还有什么形式，如果是多例的话，会有什么影响" class="headerlink" title="Spring 的 bean 为什么是单例的呢，并且除了单例以外还有什么形式，如果是多例的话，会有什么影响"></a>Spring 的 bean 为什么是单例的呢，并且除了单例以外还有什么形式，如果是多例的话，会有什么影响</h2><p>Spring 框架中Bean的默认作用域是<code>单例（singleton）</code>，这是出于以下几个原因：</p><ol><li><strong>性能优化</strong>：创建对象通常是一个昂贵的过程，尤其是涉及到 I&#x2F;O 操作（如数据库连接）时。使用单例可以减少对象创建的次数，节省资源和提升性能。</li><li><strong>状态共享</strong>：单例模式允许在应用的不同部分共享同一个 Bean 实例，这对于状态共享和管理非常有用。</li><li><strong>资源管理</strong>：许多 Bean ，如数据源、会话工厂等，是自然的单例，因为它们封装了共享资源，如数据库连接池。</li></ol><p>除了单例模式，Spring 还提供其他几种 Bean 的作用域：</p><ul><li><strong>单例（Singleton）</strong>：在 Spring IoC 容器仅存在一个 Bean 实例，Bean 以单例方式存在。</li><li><strong>原型（prototype）</strong>：每次注入或通过 Spring 容器的 getBean() 请求时，都会创建一个新的Bean实例（这种模式就是多例）。</li><li><strong>请求（request）</strong>：每个 HTTP 请求都会创建一个新的 Bean ，该作用域仅在请求的处理过程中有效。</li><li><strong>会话（session）</strong>：在一个 HTTP 会话中，一个 Bean 定义对应一个 Bean 实例，该作用域同样仅在会话期间中有效。</li><li><strong>应用（application）</strong>：在一个 ServletContext 的生命周期内，一个 Bean 定义对应一个 Bean 实例，同样仅在 Web 应用的生命周期中有效。</li></ul><p>如果将 Bean 定义为多例（prototype）作用域，将会有以下影响：</p><ol><li><strong>资源使用增加</strong>：每次请求 Bean 时都会创建新实例，会增加内存和资源的使用。</li><li><strong>状态管理</strong>：多例 Bean 不会共享状态，每个 Bean 实例都有自己的状态。</li><li><strong>生命周期管理</strong>：Spring 不会管理 prototype Bean 的完整生命周期，也就是说，Spring 不会调用 prototype Bean 的销毁方法。</li><li><strong>复杂性增加</strong>：在使用多例 Bean 时，需要更加小心地管理其生命周期和依赖关系。</li></ol><p>总的来说，选择正确的作用域取决于具体的应用需求。单例作用域适合于<strong>需要共享状态的全局资源</strong>，而原型作用域<strong>适合于那些具有独立状态、生命周期较短或需要隔离的Bean、每次都需要一个新实例的情况</strong>。</p><h2 id="Spring-循环依赖"><a href="#Spring-循环依赖" class="headerlink" title="Spring 循环依赖"></a>Spring 循环依赖</h2><p>循环依赖是指两个或多个Bean相互依赖对方，形成了一个闭环。在Spring中，循环依赖主要发生在单例Bean之间。Spring通过<code>三级缓存机制</code> 来解决Bean的循环依赖问题，Spring 的三级缓存是 <code>为了处理Bean对象在不同状态下的存储</code> 。</p><h3 id="三级缓存机制"><a href="#三级缓存机制" class="headerlink" title="三级缓存机制"></a>三级缓存机制</h3><p><strong>一级缓存（Singleton Objects）：</strong></p><ul><li>用于存储完全初始化好的Bean实例，这些Bean已经被创建且注入了依赖，可以直接使用。</li></ul><p><strong>二级缓存（Early Singleton Objects）：</strong></p><ul><li>存储已经实例化好但还没有完全初始化的 Bean，这些 Bean 实例已经存在，但还没有完全依赖注入和初始化。</li></ul><p><strong>三级缓存（Singleton Factories）：</strong></p><ul><li>存储用于生成 Bean 的工厂对象，这些工厂对象可以生成 Bean 的早期引用，以解决循环依赖问题。</li></ul><p><strong>三级缓存的联系</strong></p><p>三级缓存是相互关联的，特别是在处理循环依赖的时候。当创建一个 Bean 时，Spring 可能需要从这些缓存中检索或移动 Bean，以确保正确的创建和初始化。</p><p><strong>Bean 的初始化与三级缓存的作用</strong></p><ol><li><p>实例化 Bean：</p><ul><li>首先，Spring 容器创建bean的实例。这一步通常是通过调用构造函数完成的。</li></ul></li><li><p>三级缓存（Singleton Factories）的使用：</p><ul><li>如果在bean的创建过程中检测到潜在的循环依赖，Spring会将一个能够生成bean的工厂对象放入三级缓存中。</li></ul></li><li><p>二级缓存（Early Singleton Objects）的使用：</p><ul><li>通过工厂对象生成的早期对象bean，在bean的进一步初始化（如依赖注入）之前，将bean被放入二级缓存中。此时，bean还未完全配置（如依赖注入和初始化回调可能尚未应用）。</li></ul></li><li><p>完成依赖注入和初始化：</p><ul><li>接下来，Spring 容器对bean进行依赖注入，并执行相关的初始化方法（如那些标注了**<code>@PostConstruct</code><strong>的方法或实现了</strong><code>InitializingBean</code><strong>接口的</strong><code>afterPropertiesSet</code>**方法）。</li></ul></li><li><p>移动到一级缓存（Singleton Objects）：</p><ul><li>一旦bean被完全初始化，它就从二级缓存中移除，并存放到一级缓存中。此时，bean已经完全准备好，可以被应用中的其他部分使用。</li></ul><h3 id="BeanFactory-和-ApplicationContext-的区别"><a href="#BeanFactory-和-ApplicationContext-的区别" class="headerlink" title="BeanFactory 和 ApplicationContext 的区别"></a>BeanFactory 和 ApplicationContext 的区别</h3><p>BeanFactory 和 ApplicationContext 是 Spring 两个核心接口，都可以用来获取 Bean 实例，但在功能上有所不同。</p><ul><li>BeanFactory<ul><li><strong>提供了基本的依赖注入支持</strong>。</li><li><strong>延迟加载，只有在明确请求时才初始化Bean</strong>。</li></ul></li><li>ApplicationContext<ul><li><strong>完全初始化所有单例Bean</strong>。</li><li><strong>支持国际化（i18n）、事件传播、资源加载等</strong>。</li><li><strong>提供了AOP功能</strong>。</li><li><strong>通常在应用程序中使用 ApplicationContext</strong>。</li></ul></li></ul><h3 id="为什么在对应的-service-和-controller-标注了-Service-和-RestController-注解之后，Spring-容器就能够扫描到呢"><a href="#为什么在对应的-service-和-controller-标注了-Service-和-RestController-注解之后，Spring-容器就能够扫描到呢" class="headerlink" title="为什么在对应的 service 和 controller 标注了 @Service 和 @RestController 注解之后，Spring 容器就能够扫描到呢?"></a><strong>为什么在对应的 service 和 controller 标注了 @Service 和 @RestController 注解之后，Spring 容器就能够扫描到呢?</strong></h3><blockquote><p>答：之所以Spring容器能够扫描到这些容器，是因为@ComponentScan注解，该注解会扫描所有带有 @Component、@Service、@Repository、@Controller等注解的类，并未它们创建相对应的 Spring bean，随后这些 bean 可以通过依赖注入被其他部分所使用。所以当标注了@Service、@Controller等注解之后，Spring容器就会自动注册这些类，并在需要时创建它们的bean实例。</p></blockquote><p><strong>为什么在 service 的实现类 serviceimpl 标记了 @service 注解，在 controller 层只要注入 service 就可以引用serviceimpl 里面实现的功能呢？</strong></p><p>答：这里面涉及到了 入**<code>自动装配</code>**的知识点。</p><h3 id="自动装配的过程"><a href="#自动装配的过程" class="headerlink" title="自动装配的过程"></a><strong>自动装配的过程</strong></h3><ul><li><strong>搜索过程</strong>：当**<code>@Autowired</code><strong>用于注入</strong><code>Service</code><strong>接口时，Spring查找所有可用的</strong><code>Service</code><strong>类型的Bean。如果找到了与依赖类型兼容的Bean（实现了Service接口的impl类），Spring就会自动将其注入到声明了</strong><code>@Autowired</code>**的地方。</li><li><strong>冲突解决</strong>：如果存在多个匹配的Bean，Spring将需要额外的配置来选择使用哪一个，例如通过**<code>@Primary</code><strong>注解标注首选的Bean，或者使用</strong><code>@Qualifier</code>**注解指定注入哪一个特定的Bean。</li></ul><h3 id="By-Type-和-By-Name-的区别"><a href="#By-Type-和-By-Name-的区别" class="headerlink" title="By Type 和 By Name 的区别"></a>By Type 和 By Name 的区别</h3><p><strong>@Autowired 基于类型的依赖注入（By Type）</strong>：</p><ul><li><p><strong>定义</strong>：在基于类型的注入中，Spring 容器使用要注入的属性或构造函数参数的类型来在容器中查找匹配的 Bean。</p></li><li><p>代码示例：</p><pre class="line-numbers language-language-java"><code class="language-language-java">@Autowiredprivate MyService myService;<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span></span></code></pre><p>在这个例子中，Spring 会在其容器中查找 MyService 类型的 Bean，并进行注入。</p><p><strong>多个候选 Bean</strong>：如果存在多个同类型的 Bean，而没有其他限定信息，Spring 将无法决定使用哪一个，从而导致异常。这种情况下，可以使用 @Qualifier 注解来指定 Bean 的名称。</p></li></ul><p><strong>@Autowired基于名称的依赖注入（By Name）</strong>：</p><p><strong>定义</strong>：虽然**<code>@Autowired</code><strong>本身不提供直接的基于名称的注入，通过与</strong><code>@Qualifier</code><strong>结合使用，它可以非常灵活地实现</strong><code>基于名称的注入</code>**相似的功能。</p><p><strong>代码示例</strong>：</p><pre class="line-numbers language-language-java"><code class="language-language-java">@Autowired@Qualifier("mySpecificService")private MyService myService;<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span></span></code></pre><pre class="line-numbers language-language-java"><code class="language-language-java">@Service("mySpecificService")public class MyServiceImpl implements MyService &#123;    // 实现细节&#125;<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span></span></code></pre><p>在这个例子中，Spring 会在其容器中查找名为 <code>mySpecificService</code> 的Bean来注入。</p><p><strong>@Resource 基于名称的依赖注入（By Name）（默认）</strong></p><p><strong>定义</strong>：**<code>@Resource</code>**注解是基于 JSR-250 标准，它可以根据名称或类型来注入依赖。 <strong>代码示例</strong>：</p><pre class="line-numbers language-language-java"><code class="language-language-java">@Resource(name = "mySpecificService")private MyService myService;<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span></span></code></pre><p>在这个例子中，**<code>@Resource</code><strong>注解通过</strong><code>name</code>**属性直接指定了要注入的 Bean 名称，从而实现了基于名称的注入。 <strong>@Resource 基于类型的依赖注入（By Type）</strong></p><pre class="line-numbers language-language-java"><code class="language-language-java">@Resourceprivate MyService myService;<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span></span></code></pre><h3 id="总结："><a href="#总结：" class="headerlink" title="总结："></a>总结：</h3><ul><li><strong>基于类型</strong>的注入更常见，它强调了类型的兼容性和接口编程的原则，适用于大多数情况，尤其是当每个类型只有一个Bean实例时。</li><li><strong>基于名称</strong>的注入在需要从多个同类型的Bean中选择特定一个时非常有用，它提供了更精确的控制，但牺牲了一些类型安全性。</li></ul><p>在Spring中，事务管理是非常关键的一部分，但是在使用过程中，有时候事务会失效。事务失效的原因可能有很多，以下是一些常见的原因：</p><p>确保方法是public的。 确保使用了Spring管理的事务注解或配置。 确保正确配置了事务管理器和数据源。 避免在同一个类中进行内部方法调用。 确保异常处理符合事务管理的要求。</p><ul><li>方法不是public的：Spring的事务管理默认是基于AOP（Aspect-Oriented Programming）的，只有public方法才能被代理。因此，如果事务方法不是public的，事务将不会生效。</li><li>方法内部调用：如果在同一个类中，一个非事务方法调用了一个事务方法，事务将不会生效。这是因为Spring AOP代理机制在内部方法调用时不会创建代理对象。解决方法是将事务方法提取到另一个类中，或者使用AspectJ进行事务管理。</li><li>没有使用Spring管理的事务注解或配置：确保你在配置文件或类中正确使用了@Transactional注解，或者在XML配置中正确定义了事务管理。</li><li>异常未被捕获或未被正确抛出：默认情况下，Spring只会在RuntimeException和Error子类异常时回滚事务。如果你捕获了异常或者抛出了检查异常（Checked Exception），事务可能不会回滚。可以通过rollbackFor属性指定需要回滚的异常类型。</li></ul></li></ol>]]></content>
      
      
      <categories>
          
          <category> 微服务 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> Spring </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>电商系统核心技术问题与解决方案</title>
      <link href="/2023/12/26/dian-shang-xi-tong-he-xin-ji-zhu-wen-ti-yu-jie-jue-fang-an/"/>
      <url>/2023/12/26/dian-shang-xi-tong-he-xin-ji-zhu-wen-ti-yu-jie-jue-fang-an/</url>
      
        <content type="html"><![CDATA[<h1 id><a href="#" class="headerlink" title></a></h1><h2 id="一、引言：电商系统的技术挑战"><a href="#一、引言：电商系统的技术挑战" class="headerlink" title="一、引言：电商系统的技术挑战"></a>一、引言：电商系统的技术挑战</h2><p>电商系统是典型的高并发、大数据量应用场景，面临着订单处理、库存管理、数据一致性、系统性能等多方面的挑战。本文整合了常见的电商系统技术问题及其解决方案，旨在为电商系统的设计与实现提供技术参考。</p><h2 id="二、高并发场景下的订单处理"><a href="#二、高并发场景下的订单处理" class="headerlink" title="二、高并发场景下的订单处理"></a>二、高并发场景下的订单处理</h2><h3 id="1-大量订单快速拉取方案"><a href="#1-大量订单快速拉取方案" class="headerlink" title="1. 大量订单快速拉取方案"></a>1. 大量订单快速拉取方案</h3><p>双11等大促期间存在大量订单需要拉取，如何保证系统可用性？</p><p><strong>解决方案</strong>：</p><ul><li><strong>线程池批量处理</strong>：采用Java语言中的线程池进行批量拉取，设置为异步操作</li><li><strong>读写分离</strong>：将数据库设置为主从同步，查询操作转发到从库，写操作转发到主库</li><li><strong>引入缓存中间件</strong>：使用Redis缓存热点数据，减轻数据库压力</li><li><strong>异步消息队列</strong>：使用Kafka或RabbitMQ等消息队列，将订单处理异步化</li></ul><h3 id="2-订单修改与取消的高效处理"><a href="#2-订单修改与取消的高效处理" class="headerlink" title="2. 订单修改与取消的高效处理"></a>2. 订单修改与取消的高效处理</h3><p>订单取消或修改频繁时，如何快速响应并准确更新相关数据？</p><p><strong>解决方案</strong>：</p><ul><li><p><strong>消息队列</strong>：利用消息队列异步处理订单的取消或修改请求，解耦请求和实际处理逻辑</p></li><li><p><strong>幂等性处理</strong>：确保订单的取消和修改操作具有幂等性，通过添加唯一标识符实现</p></li><li><p>前端防抖和节流</p><p>：</p><ul><li>防抖技术：确保在一定时间内多次触发只执行一次操作</li><li>节流技术：限制一个函数在一定时间内只能执行一次</li></ul></li><li><p><strong>后端限流措施</strong>：使用令牌桶或漏桶算法控制请求频率</p></li><li><p><strong>合理设置修改频率限制</strong>：对敏感信息设定合理的修改间隔或次数限制</p></li></ul><h3 id="3-订单数据一致性保证"><a href="#3-订单数据一致性保证" class="headerlink" title="3. 订单数据一致性保证"></a>3. 订单数据一致性保证</h3><p>在订单处理过程中，如何保证订单数据的一致性和准确性？</p><p><strong>解决方案</strong>：</p><ul><li><strong>数据库事务(ACID)</strong>：确保订单操作的原子性、一致性、隔离性和持久性</li><li><strong>接口幂等性</strong>：通过唯一标识、Token机制等确保重复请求不会导致数据异常</li><li><strong>乐观锁和悲观锁</strong>：根据场景选择合适的锁机制处理并发修改</li><li><strong>最终一致性</strong>：对于非关键操作，可采用最终一致性模型，通过异步补偿机制保证数据最终一致</li></ul><h2 id="三、库存管理系统设计"><a href="#三、库存管理系统设计" class="headerlink" title="三、库存管理系统设计"></a>三、库存管理系统设计</h2><h3 id="1-大批量库存调整方案"><a href="#1-大批量库存调整方案" class="headerlink" title="1. 大批量库存调整方案"></a>1. 大批量库存调整方案</h3><p><strong>场景</strong>：需要一次性调整1万个商品的库存，要求不出现负库存，任一失败则全部回滚。</p><p><strong>解决方案</strong>：</p><ul><li><strong>事务范围控制</strong>：将整个库存调整过程控制在一个事务内</li><li><strong>锁定库存记录</strong>：使用数据库行锁或表锁确保并发安全</li><li><strong>批量操作</strong>：使用批处理技术提高效率</li><li><strong>完整的错误处理</strong>：捕获异常并进行回滚</li></ul><p>示例代码：</p><pre class="line-numbers language-language-java"><code class="language-language-java">import java.sql.Connection;import java.sql.PreparedStatement;import java.sql.ResultSet;import java.sql.SQLException;import java.util.List;public class InventoryAdjustment &#123;    private Connection connection;    public InventoryAdjustment(Connection connection) &#123;        this.connection = connection;    &#125;    /**     * 调整多个商品的库存。     * @param adjustments 商品的库存调整数据（商品ID和调整数量）     * @return 是否调整成功     */    public boolean adjustInventory(List<InventoryData> adjustments) &#123;        try &#123;            // 启动事务            connection.setAutoCommit(false);            // 锁定库存记录并检查库存            for (InventoryData data : adjustments) &#123;                if (!checkAndLockInventory(data.productId, data.adjustmentQuantity)) &#123;                    // 库存不足，回滚事务                    connection.rollback();                    return false;                &#125;            &#125;            // 提交事务            connection.commit();            return true;        &#125; catch (SQLException e) &#123;            e.printStackTrace();            try &#123;                // 发生异常，回滚事务                connection.rollback();            &#125; catch (SQLException ex) &#123;                ex.printStackTrace();            &#125;            return false;        &#125; finally &#123;            try &#123;                // 恢复自动提交                connection.setAutoCommit(true);            &#125; catch (SQLException e) &#123;                e.printStackTrace();            &#125;        &#125;    &#125;    private boolean checkAndLockInventory(int productId, int adjustmentQuantity) throws SQLException &#123;        String sql = "SELECT stock FROM inventory WHERE product_id = ? FOR UPDATE";        try (PreparedStatement stmt = connection.prepareStatement(sql)) &#123;            stmt.setInt(1, productId);            ResultSet rs = stmt.executeQuery();            if (rs.next()) &#123;                int currentStock = rs.getInt("stock");                if (currentStock + adjustmentQuantity < 0) &#123;                    return false; // 库存不足                &#125; else &#123;                    // 更新库存                    updateInventory(productId, currentStock + adjustmentQuantity);                    return true;                &#125;            &#125;        &#125;        return false;    &#125;    private void updateInventory(int productId, int newStock) throws SQLException &#123;        String updateSql = "UPDATE inventory SET stock = ? WHERE product_id = ?";        try (PreparedStatement stmt = connection.prepareStatement(updateSql)) &#123;            stmt.setInt(1, newStock);            stmt.setInt(2, productId);            stmt.executeUpdate();        &#125;    &#125;&#125;class InventoryData &#123;    int productId;    int adjustmentQuantity;    public InventoryData(int productId, int adjustmentQuantity) &#123;        this.productId = productId;        this.adjustmentQuantity = adjustmentQuantity;    &#125;&#125;<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><h3 id="2-实时库存更新策略"><a href="#2-实时库存更新策略" class="headerlink" title="2. 实时库存更新策略"></a>2. 实时库存更新策略</h3><p>如何实现实时库存更新，减少超卖或缺货情况？</p><p><strong>解决方案</strong>：</p><ul><li><strong>分布式锁</strong>：使用Redis或Zookeeper实现分布式锁，确保同一时间只有一个请求能修改库存</li><li><strong>预扣库存</strong>：下单时先预扣库存，支付成功后再实际扣减</li><li><strong>库存缓存</strong>：热点商品库存放入缓存，减少数据库访问</li><li><strong>定时补偿</strong>：定期检查库存与订单数据一致性，发现不一致时进行补偿</li></ul><h2 id="四、数据库优化与管理"><a href="#四、数据库优化与管理" class="headerlink" title="四、数据库优化与管理"></a>四、数据库优化与管理</h2><h3 id="1-慢查询优化方案"><a href="#1-慢查询优化方案" class="headerlink" title="1. 慢查询优化方案"></a>1. 慢查询优化方案</h3><p><strong>常见问题</strong>：项目中的数据库慢查询问题及解决方法。</p><p><strong>解决方案</strong>：</p><ul><li><p><strong>使用EXPLAIN分析</strong>：使用EXPLAIN关键字分析SQL执行计划，找出性能瓶颈</p></li><li><p><strong>限制返回行数</strong>：在代码中先统计查询返回行数，超出阈值时提示用户调整查询条件</p></li><li><p><strong>异步处理大数据量查询</strong>：对确实需要大量数据的场景，通过异步方式处理，处理完后统一返回或生成文件下载</p></li><li><p>分库分表</p><p>：将大表拆分成多个小表，减少单次查询的数据量</p><ul><li><strong>技术工具</strong>：Sharding-JDBC（应用层分片）、MyCat（数据库中间件）</li></ul></li></ul><h3 id="2-实时报表数据更新策略"><a href="#2-实时报表数据更新策略" class="headerlink" title="2. 实时报表数据更新策略"></a>2. 实时报表数据更新策略</h3><p><strong>场景</strong>：实时报表需要表的实时更新，如果采取先删除后更新策略，当数据量大时会出现数据暂时不完整的情况。</p><p><strong>解决方案</strong>：</p><ul><li><strong>增加临时表</strong>：更新数据时写入临时表，数据准备完成后切换表引用</li><li><strong>版本控制</strong>：为数据添加版本号，更新时增加版本而不是直接删除旧数据，报表始终展示最新版本</li><li><strong>增量更新</strong>：只对变更的数据进行更新，避免全量更新</li><li><strong>引入缓存</strong>：更新过程中使用缓存存储旧数据，新数据准备就绪后再更新缓存</li></ul><h3 id="3-大数据量导出方案"><a href="#3-大数据量导出方案" class="headerlink" title="3. 大数据量导出方案"></a>3. 大数据量导出方案</h3><p>如何导出500W的数据？</p><p><strong>解决方案</strong>：</p><ul><li><strong>分批次导出</strong>：将500W数据分割成多个小批次（如每批5万条）进行导出</li><li><strong>异步导出</strong>：将导出任务放入后台，用户可以继续其他操作，导出完成后通知用户</li><li><strong>使用专业工具</strong>：如DataX、Sqoop等ETL工具进行大数据量导出</li><li><strong>多线程并行导出</strong>：使用多线程技术并行处理多个数据分片</li><li><strong>导出格式优化</strong>：根据需求选择合适的导出格式（CSV、Excel、JSON等）</li></ul><h2 id="五、系统性能优化策略"><a href="#五、系统性能优化策略" class="headerlink" title="五、系统性能优化策略"></a>五、系统性能优化策略</h2><h3 id="1-高峰期系统性能保障"><a href="#1-高峰期系统性能保障" class="headerlink" title="1. 高峰期系统性能保障"></a>1. 高峰期系统性能保障</h3><p>用户请求高峰时，如何优化系统性能保证快速响应？</p><p><strong>解决方案</strong>：</p><ol><li><p><strong>负载均衡</strong>：使用Nginx等负载均衡器分散流量到多个服务器</p></li><li><p>缓存机制</p><p>：</p><ul><li><strong>应用级缓存</strong>：使用Redis、Memcached缓存热点数据</li><li><strong>数据库缓存</strong>：利用数据库内建缓存机制</li><li><strong>前端缓存</strong>：缓存静态资源减少重复请求</li></ul></li><li><p>数据库优化</p><p>：</p><ul><li><strong>索引优化</strong>：确保表使用合适的索引</li><li><strong>查询优化</strong>：优化SQL语句，避免复杂联接和全表扫描</li><li><strong>读写分离</strong>：查询和更新操作分布到不同服务器</li></ul></li><li><p><strong>异步处理</strong>：使用RabbitMQ、Kafka等消息队列处理非实时任务</p></li><li><p>扩展策略</p><p>：</p><ul><li><strong>水平扩展</strong>：增加更多服务器分散负载</li><li><strong>垂直扩展</strong>：提升单服务器处理能力</li></ul></li><li><p><strong>代码优化</strong>：优化循环、条件语句，使用高效算法和数据结构</p></li><li><p><strong>服务微服务化</strong>：将大型应用拆分为多个微服务，灵活管理负载并独立扩展</p></li></ol><h3 id="2-线程池满载处理策略"><a href="#2-线程池满载处理策略" class="headerlink" title="2. 线程池满载处理策略"></a>2. 线程池满载处理策略</h3><p>线程池队列满后任务失败或丢弃，如何解决？</p><p><strong>解决方案</strong>：</p><ul><li><p>自定义拒绝策略</p><p>：实现RejectedExecutionHandler接口</p><ol><li><strong>拒绝任务入库</strong>：将被拒绝的任务持久化到数据库中，保证不丢失任务</li><li><strong>任务重回队列</strong>：尝试将任务重新放回队列或等待有可用线程</li></ol></li></ul><p>示例代码：</p><pre class="line-numbers language-language-java"><code class="language-language-java">public class MyRejectedExecutionHandler implements RejectedExecutionHandler &#123;    @Override    public void rejectedExecution(Runnable r, ThreadPoolExecutor executor) &#123;        System.out.println("任务被拒绝执行: " + r.toString());        // 这里可以添加更多的处理逻辑，比如保存任务信息到数据库        // 或尝试将任务重新加入到某个队列中    &#125;&#125;// 使用自定义拒绝策略创建线程池RejectedExecutionHandler handler = new MyRejectedExecutionHandler();ThreadPoolExecutor executor =     new ThreadPoolExecutor(corePoolSize, maxPoolSize, keepAliveTime, unit, workQueue, handler);<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><h2 id="六、接口设计与幂等性保证"><a href="#六、接口设计与幂等性保证" class="headerlink" title="六、接口设计与幂等性保证"></a>六、接口设计与幂等性保证</h2><h3 id="1-接口幂等性实现方法"><a href="#1-接口幂等性实现方法" class="headerlink" title="1. 接口幂等性实现方法"></a>1. 接口幂等性实现方法</h3><p>如何保证接口的幂等性？</p><p><strong>实现方法</strong>：</p><ol><li><p>唯一事务标识</p><p>：</p><ul><li>客户端生成唯一标识（如订单ID+用户ID+时间戳）</li><li>服务器根据标识判断操作是否已执行</li></ul></li><li><p>Token机制</p><p>：</p><ul><li>服务器向客户端发放唯一Token</li><li>客户端随请求发送Token，服务器执行后废弃该Token</li><li>重复请求到达时，Token已不存在，拒绝操作</li></ul></li><li><p>乐观锁</p><p>：</p><ul><li>通过版本号或时间戳确保数据未被其他操作修改</li><li>发现冲突时放弃当前操作</li></ul></li><li><p>悲观锁</p><p>：</p><ul><li>使用synchronized或ReentrantLock实现</li><li>确保同一时间只有一个请求处理，保证原子性</li></ul></li><li><p>数据库约束</p><p>：</p><ul><li>利用唯一约束和主键约束防止重复记录插入</li></ul></li></ol><h2 id="七、总结与最佳实践"><a href="#七、总结与最佳实践" class="headerlink" title="七、总结与最佳实践"></a>七、总结与最佳实践</h2><p>电商系统设计需要综合考虑高并发、大数据量、实时性等多方面因素，核心技术挑战包括：</p><ol><li><strong>高并发请求处理</strong>：通过负载均衡、缓存机制、异步处理等提高系统吞吐量</li><li><strong>数据一致性保证</strong>：合理使用事务、锁机制和幂等设计确保数据准确性</li><li><strong>实时性与性能平衡</strong>：在保证数据实时性的同时优化系统性能，如合理使用缓存、预计算等</li><li><strong>系统可扩展性</strong>：采用微服务架构、水平扩展等方式提高系统可扩展性</li><li><strong>异常情况处理</strong>：完善的异常处理机制，包括补偿机制、降级策略等</li></ol><p>通过合理的技术选型和架构设计，电商系统可以更好地应对各种复杂场景，提供稳定、高效的服务。</p>]]></content>
      
      
      <categories>
          
          <category> 消息队列 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> Kafka </tag>
            
        </tags>
      
    </entry>
    
    
  
  
</search>
